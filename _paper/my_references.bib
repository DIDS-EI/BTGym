@inproceedings{2020understanding,
  title = {Understanding {{Architectures Learnt}} by {{Cell-based Neural Architecture Search}}},
  booktitle = ICLR,
  year = {2020},
  keywords = {cell-based,understanding},
  annotation = {ICLR},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\UK7VS8VJ\\2020 - ICLR - Understanding Architectures Learnt by Cell-based Neural Architecture Search.pptx;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@2020understanding-Understanding Architectures Learnt by Cell-based Neural Architecture Search.pdf}
}

@inproceedings{2021evolving,
  title = {Evolving {{BT-Driven Embodied Intelligence}} with {{Morphology-Behavior Mapping}}},
  booktitle = {{{AAAI2022}}},
  year = {2021},
  keywords = {ObsCite},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\7Q2NDCNT\\Technical Appendix.pdf;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@2021evolving-Evolving BT-Driven Embodied Intelligence with Morphology-Behavior Mapping.pdf}
}

@inproceedings{2021speedy,
  title = {Speedy {{Performance Estimation}} for {{Neural Architecture Search}}},
  booktitle = NeurIPS,
  year = {2021},
  keywords = {traning trajectory},
  annotation = {NeurIPS},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@2021speedy-Speedy Performance Estimation for Neural Architecture Search.pdf}
}

@inproceedings{2022enhancing,
  title = {Enhancing {{Joint Adaption}} of {{Morphology}} and {{Control}} by {{Instinct-driven Reinforcement Learning}}},
  booktitle = {{{ICRA2023}}},
  year = {2022},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\AH55F75U\\ICRA23_2354_VI_i.mp4;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@2022enhancing-Enhancing Joint Adaption of Morphology and Control by Instinct-driven.pdf}
}

@inproceedings{2022mapping,
  title = {Mapping {{Componentized Body}} to {{Modular Behaviors}}: {{Embodied Intelligence}} via {{Hierarchical Grammatical Evolution}}},
  booktitle = {{{IJCAI2022}}},
  year = {2022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@2022mapping-Mapping Componentized Body to Modular Behaviors - Embodied Intelligence via.pdf}
}

@article{academic,
  title = {Academic {{Phrasebank Navigable}}},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@academic-Academic Phrasebank Navigable.pdf}
}

@article{aeronautiques1998pddl,
  title = {{{PDDL}}: The Planning Domain Definition Language},
  author = {Aeronautiques, Constructions and Howe, Adele and Knoblock, Craig and McDermott, ISI Drew and Ram, Ashwin and Veloso, Manuela and Weld, Daniel and Sri, David Wilkins and Barrett, Anthony and Christianson, Dave and others},
  year = {1998},
  journal = {Technical Report, Tech. Rep.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@aeronautiques1998pddl-PDDL - the planning domain definition language.pdf}
}

@inproceedings{agarwal2022reincarnating,
  title = {Reincarnating {{Reinforcement Learning}}: {{Reusing Prior Computation}} to {{Accelerate Progress}}},
  booktitle = NeurIPS,
  author = {Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron C and Bellemare, Marc},
  editor = {Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
  year = {2022},
  volume = {35},
  pages = {28955--28971},
  publisher = {Curran Associates, Inc.},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@agarwal2022reincarnating-Reincarnating Reinforcement Learning - Reusing Prior Computation to Accelerate.pdf}
}

@article{agis2020eventdriven,
  title = {An Event-Driven Behavior Trees Extension to Facilitate Non-Player Multi-Agent Coordination in Video Games},
  author = {Agis, Ramiro A and Gottifredi, Sebastian and Garc{\'i}a, Alejandro J},
  year = {2020},
  journal = {Expert Systems with Applications},
  volume = {155},
  pages = {113457},
  publisher = {Elsevier},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@agis2020eventdriven-An event-driven behavior trees extension to facilitate non-player multi-agent.pdf}
}

@inproceedings{ahmad2020marginal,
  title = {Marginal Utility for Planning in Continuous or Large Discrete Action Spaces},
  booktitle = NeurIPS,
  author = {Ahmad, Zaheen and Lelis, Levi and Bowling, Michael},
  year = {2020},
  volume = {33},
  pages = {1937--1946},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ahmad2020marginal-Marginal utility for planning in continuous or large discrete action spaces.pdf}
}

@article{ahn2022can,
  title = {Do as i Can, Not as i Say: {{Grounding}} Language in Robotic Affordances},
  author = {Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and others},
  year = {2022},
  journal = {arXiv preprint arXiv:2204.01691},
  eprint = {2204.01691},
  abstract = {Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model's ``hands and eyes,'' while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project's website, the video, and open sourced code in a tabletop domain can be found at say-can.github.io.},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ahn2022can-Do as i can, not as i say - Grounding language in robotic affordances.pdf}
}

@inproceedings{aineto2018learning,
  title = {Learning {{STRIPS}} Action Models with Classical Planning},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}}},
  author = {Aineto, Diego and Jim{\'e}nez, Sergio and Onaindia, Eva},
  year = {2018},
  volume = {28},
  pages = {399--407},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@aineto2018learning-Learning STRIPS action models with classical planning.pdf}
}

@inproceedings{aineto2023actionfailure,
  title = {Action-Failure Resilient Planning},
  booktitle = {{{ECAI}}},
  author = {Aineto, Diego and Gaudenzi, Alessandro and Gerevini, Alfonso and Rovetta, Alberto and Scala, Enrico and Serina, Ivan},
  year = {2023},
  pages = {44--51},
  publisher = {IOS Press},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@aineto2023actionfailure-Action-failure resilient planning.pdf}
}

@article{akakzia2020grounding,
  title = {Grounding Language to Autonomously-Acquired Skills via Goal Generation},
  author = {Akakzia, Ahmed and Colas, C{\'e}dric and Oudeyer, Pierre-Yves and Chetouani, Mohamed and Sigaud, Olivier},
  year = {2020},
  journal = {arXiv preprint arXiv:2006.07185},
  eprint = {2006.07185},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@akakzia2020grounding-Grounding language to autonomously-acquired skills via goal generation.pdf}
}

@inproceedings{albrecht2022avalon,
  title = {Avalon: {{A Benchmark}} for {{RL Generalization Using Procedurally Generated Worlds}}},
  booktitle = NeurIPS,
  author = {Albrecht, Joshua and Fetterman, Abraham J. and Fogelman, Bryden and Kitanidis, Ellie and Wr{\'o}blewski, Bartosz and Seo, Nicole and Rosenthal, Michael and Knutins, Maksis and Polizzi, Zachary and Simon, James B. and Qiu, Kanjun},
  year = {2022},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@albrecht2022avalon-Avalon - A Benchmark for RL Generalization Using Procedurally Generated Worlds.pdf}
}

@article{alexandredolgui2022design,
  title = {Design and Management of Assembly Systems 4.0: Systematic Literature Review and Research Agenda},
  author = {Alexandre Dolgui, Fabio Sgarbossa and Simonetto, Marco},
  year = {2022},
  journal = {International Journal of Production Research},
  volume = {60},
  number = {1},
  pages = {184--210},
  publisher = {Taylor \& Francis},
  doi = {10.1080/00207543.2021.1990433},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@alexandredolgui2022design-Design and management of assembly systems 4.0 - systematic literature review and.pdf}
}

@article{algorithm2e,
  title = {Algorithm2e},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@algorithm2e-algorithm2e.pdf}
}

@article{ameertamoorkhan2022human,
  title = {Human Guided Cooperative Robotic Agents in Smart Home Using Beetle Antennae Search},
  author = {Ameer Tamoor KHAN, Shuai LI, Xinwei CAO},
  year = {2022},
  journal = {SCIENCE CHINA Information Sciences},
  volume = {65},
  number = {2},
  pages = {122204-},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ameertamoorkhan2022human-Human guided cooperative robotic agents in smart home using beetle antennae.pdf}
}

@book{amigoni2024autonomous,
  title = {Autonomous {{Agents}} and {{Multiagent Systems}}. {{Best}} and {{Visionary Papers}}},
  author = {Amigoni, Francesco and Sinha, Arunesh},
  year = {2024},
  volume = {14456},
  publisher = {Springer Nature},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@amigoni2024autonomous-Autonomous Agents and Multiagent Systems. Best and Visionary Papers.pdf}
}

@misc{anokhin2024arigraph,
  title = {{{AriGraph}}: {{Learning Knowledge Graph World Models}} with {{Episodic Memory}} for {{LLM Agents}}},
  shorttitle = {{{AriGraph}}},
  author = {Anokhin, Petr and Semenov, Nikita and Sorokin, Artyom and Evseev, Dmitry and Burtsev, Mikhail and Burnaev, Evgeny},
  year = {2024},
  month = sep,
  number = {arXiv:2407.04363},
  eprint = {2407.04363},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-09-19},
  abstract = {Advancements in the capabilities of Large Language Models (LLMs) have created a promising foundation for developing autonomous agents. With the right tools, these agents could learn to solve tasks in new environments by accumulating and updating their knowledge. Current LLM-based agents process past experiences using a full history of observations, summarization, retrieval augmentation. However, these unstructured memory representations do not facilitate the reasoning and planning essential for complex decisionmaking. In our study, we introduce AriGraph, a novel method wherein the agent constructs and updates a memory graph that integrates semantic and episodic memories while exploring the environment. We demonstrate that our Ariadne LLM agent, consisting of the proposed memory architecture augmented with planning and decision-making, effectively handles complex tasks within interactive text game environments difficult even for human players. Results show that our approach markedly outperforms other established memory methods and strong RL baselines in a range of problems of varying complexity. Additionally, AriGraph demonstrates competitive performance compared to dedicated knowledge graph-based methods in static multi-hop question-answering.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@anokhin2024arigraph-AriGraph - Learning Knowledge Graph World Models with Episodic Memory for LLM.pdf}
}

@inproceedings{antakli2023ajan,
  title = {{{AJAN}}: {{An Engineering Framework}} for {{Semantic Web-Enabled Agents}} and {{Multi-Agent Systems}}},
  booktitle = {International {{Conference}} on {{Practical Applications}} of {{Agents}} and {{Multi-Agent Systems}}},
  author = {Antakli, Andr{\'e} and Kazimov, Akbar and Spieldenner, Daniel and Rojas, Gloria Elena Jaramillo and Zinnikus, Ingo and Klusch, Matthias},
  year = {2023},
  pages = {15--27},
  publisher = {Springer},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@antakli2023ajan-AJAN - An Engineering Framework for Semantic Web-Enabled Agents and Multi-Agent.pdf}
}

@inproceedings{antunes2016human,
  title = {From Human Instructions to Robot Actions: {{Formulation}} of Goals, Affordances and Probabilistic Planning},
  booktitle = {2016 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Antunes, Alexandre and Jamone, Lorenzo and Saponaro, Giovanni and Bernardino, Alexandre and Ventura, Rodrigo},
  year = {2016},
  pages = {5449--5454},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@antunes2016human-From human instructions to robot actions - Formulation of goals, affordances and.pdf}
}

@article{arora2018review,
  title = {A Review of Learning Planning Action Models},
  author = {Arora, Ankuj and Fiorino, Humbert and Pellier, Damien and M{\'e}tivier, Marc and Pesty, Sylvie},
  year = {2018},
  journal = {The Knowledge Engineering Review},
  volume = {33},
  pages = {e20},
  doi = {10.1017/S0269888918000188},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@arora2018review-A review of learning planning action models.pdf}
}

@article{athey2016recursive,
  title = {Recursive Partitioning for Heterogeneous Causal Effects},
  author = {Athey, Susan and Imbens, Guido},
  year = {2016},
  month = jul,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {113},
  number = {27},
  pages = {7353--7360},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1510489113},
  urldate = {2024-09-29},
  abstract = {In this paper we propose methods for estimating heterogeneity in causal effects in experimental and observational studies and for conducting hypothesis tests about the magnitude of differences in treatment effects across subsets of the population. We provide a data-driven approach to partition the data into subpopulations that differ in the magnitude of their treatment effects. The approach enables the construction of valid confidence intervals for treatment effects, even with many covariates relative to the sample size, and without ``sparsity'' assumptions. We propose an ``honest'' approach to estimation, whereby one sample is used to construct the partition and another to estimate treatment effects for each subpopulation. Our approach builds on regression tree methods, modified to optimize for goodness of fit in treatment effects and to account for honest estimation. Our model selection criterion anticipates that bias will be eliminated by honest estimation and also accounts for the effect of making additional splits on the variance of treatment effect estimates within each subpopulation. We address the challenge that the ``ground truth'' for a causal effect is not observed for any individual unit, so that standard approaches to cross-validation must be modified. Through a simulation study, we show that for our preferred method honest estimation results in nominal coverage for 90\% confidence intervals, whereas coverage ranges between 74\% and 84\% for nonhonest approaches. Honest estimation requires estimating the model with a smaller sample size; the cost in terms of mean squared error of treatment effects for our preferred method ranges between 7--22\%.},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@athey2016recursive-Recursive partitioning for heterogeneous causal effects.pdf}
}

@misc{athey2018generalized,
  title = {Generalized {{Random Forests}}},
  author = {Athey, Susan and Tibshirani, Julie and Wager, Stefan},
  year = {2018},
  month = apr,
  number = {arXiv:1610.01271},
  eprint = {1610.01271},
  primaryclass = {econ, stat},
  publisher = {arXiv},
  urldate = {2024-09-29},
  abstract = {We propose generalized random forests, a method for non-parametric statistical estimation based on random forests (Breiman, 2001) that can be used to fit any quantity of interest identified as the solution to a set of local moment equations. Following the literature on local maximum likelihood estimation, our method considers a weighted set of nearby training examples; however, instead of using classical kernel weighting functions that are prone to a strong curse of dimensionality, we use an adaptive weighting function derived from a forest designed to express heterogeneity in the specified quantity of interest. We propose a flexible, computationally efficient algorithm for growing generalized random forests, develop a large sample theory for our method showing that our estimates are consistent and asymptotically Gaussian, and provide an estimator for their asymptotic variance that enables valid confidence intervals. We use our approach to develop new methods for three statistical tasks: non-parametric quantile regression, conditional average partial effect estimation, and heterogeneous treatment effect estimation via instrumental variables. A software implementation, grf for R and C++, is available from CRAN.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Economics - Econometrics,Statistics - Machine Learning,Statistics - Methodology},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@athey2018generalized-Generalized Random Forests.pdf}
}

@article{athey2019estimating,
  title = {Estimating Treatment Effects with Causal Forests: {{An}} Application},
  author = {Athey, Susan and Wager, Stefan},
  year = {2019},
  journal = {Observational studies},
  volume = {5},
  number = {2},
  pages = {37--51},
  publisher = {University of Pennsylvania Press},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@athey2019estimating-Estimating treatment effects with causal forests - An application.pdf}
}

@inproceedings{auerbach2010dynamic,
  title = {Dynamic Resolution in the Co-Evolution of Morphology and Control},
  booktitle = {Artificial {{Life XII}}},
  author = {Auerbach, Joshua E and Bongard, Josh C},
  year = {2010},
  pages = {451--458},
  publisher = {MIT Press},
  keywords = {ObsCite},
  annotation = {利用 CPPN 设计了间接编码策略, 有效实现多分辨率形态生成，和形态与控制的协同进化},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@auerbach2010dynamic-Dynamic resolution in the co-evolution of morphology and control.pdf}
}

@inproceedings{auerbach2012relationship,
  title = {On the Relationship between Environmental and Morphological Complexity in Evolved Robots},
  booktitle = GECCO,
  author = {Auerbach, Joshua E and Bongard, Joshua C},
  year = {2012},
  pages = {521--528},
  keywords = {ObsCite},
  annotation = {研究了随着任务环境复杂度变化情况下的机器人形态进化策略, 验证了环境复杂性对形态复杂性的作用, 并利用基于三角网格的体素方法构建了更为复杂的形态},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@auerbach2012relationship-On the relationship between environmental and morphological complexity in.pdf}
}

@article{auerbach2014environmental,
  title = {Environmental Influence on the Evolution of Morphological Complexity in Machines},
  author = {Auerbach, Joshua E and Bongard, Josh C},
  year = {2014},
  journal = {PLoS computational biology},
  volume = {10},
  number = {1},
  pages = {e1003399},
  publisher = {Public Library of Science San Francisco, USA},
  keywords = {ObsCite}
}

@inproceedings{auerbach2014robogen,
  title = {Robogen: {{Robot}} Generation through Artificial Evolution},
  booktitle = {{{ALIFE}} 14: {{The Fourteenth International Conference}} on the {{Synthesis}} and {{Simulation}} of {{Living Systems}}},
  author = {Auerbach, Joshua and Aydin, Deniz and Maesani, Andrea and Kornatowski, Przemyslaw and Cieslewski, Titus and Heitz, Gr{\'e}goire and Fernando, Pradeep and Loshchilov, Ilya and Daler, Ludovic and Floreano, Dario},
  year = {2014},
  pages = {136--137},
  publisher = {MIT Press}
}

@inproceedings{bachor2024learning,
  title = {Learning {{Planning Domains}} from {{Non-Redundant Fully-Observed Traces}}: {{Theoretical Foundations}} and {{Complexity Analysis}}},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Bachor, Pascal and Behnke, Gregor},
  year = {2024},
  volume = {38},
  pages = {20028--20035},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bachor2024learning-Learning Planning Domains from Non-Redundant Fully-Observed Traces - Theoretical.pdf}
}

@inproceedings{bagaria2021skill,
  title = {Skill {{Discovery}} for {{Exploration}} and {{Planning}} Using {{Deep Skill Graphs}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  author = {Bagaria, Akhil and Senthil, Jason K and Konidaris, George},
  editor = {Meila, Marina and Zhang, Tong},
  year = {2021},
  month = jul,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {139},
  pages = {521--531},
  publisher = {PMLR},
  abstract = {We introduce a new skill-discovery algorithm that builds a discrete graph representation of large continuous MDPs, where nodes correspond to skill subgoals and the edges to skill policies. The agent constructs this graph during an unsupervised training phase where it interleaves discovering skills and planning using them to gain coverage over ever-increasing portions of the state-space. Given a novel goal at test time, the agent plans with the acquired skill graph to reach a nearby state, then switches to learning to reach the goal. We show that the resulting algorithm, Deep Skill Graphs, outperforms both flat and existing hierarchical reinforcement learning methods on four difficult continuous control tasks.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bagaria2021skill-Skill Discovery for Exploration and Planning using Deep Skill Graphs.pdf}
}

@inproceedings{bahl2023affordances,
  title = {Affordances {{From Human Videos}} as a {{Versatile Representation}} for {{Robotics}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Bahl, Shikhar and Mendonca, Russell and Chen, Lili and Jain, Unnat and Pathak, Deepak},
  year = {2023},
  month = jun,
  pages = {13778--13790},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bahl2023affordances-Affordances From Human Videos as a Versatile Representation for Robotics.pdf}
}

@inproceedings{bai2017efficient,
  title = {Efficient {{Reinforcement Learning}} with {{Hierarchies}} of {{Machines}} by {{Leveraging Internal Transitions}}},
  booktitle = IJCAI,
  author = {Bai, Aijun and Russell, Stuart},
  year = {2017},
  pages = {1418--1424},
  doi = {10.24963/ijcai.2017/196},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bai2017efficient-Efficient Reinforcement Learning with Hierarchies of Machines by Leveraging.pdf}
}

@inproceedings{baker2018accelerating,
  title = {Accelerating {{Neural Architecture Search}} Using {{Performance Prediction}}},
  booktitle = ICLR,
  author = {Baker, Bowen and Gupta, Otkrist and Raskar, Ramesh and Naik, Nikhil},
  year = {2018},
  pages = {7},
  abstract = {Methods for neural network meta-modeling are computationally expensive due to the need to train a large number of model configurations. In this paper, we propose a method for accelerating meta-modeling using a method for predicting final performance of neural networks using a frequentist regression models trained using features based on network architectures, hyperparameters, and time-series validation performance data of partially-trained networks. Our method obtains state-of-the-art performance in predicting the final accuracy of models in both visual classification and language modeling domains, is effective for predicting performance of drastically varying model architectures, and even generalizes between model classes. Our early stopping scheme, based on this prediction method, obtains a speedup of up to 6x on reinforcement learning-based neural architecture search, while still identifying the optimal model configurations.},
  langid = {english},
  annotation = {ICLR},
  file = {D:\Workspace\BaiduSyncdisk\CXL_Storage\SoftwareData\zotfile\ICLR2018_Accelerating Neural Architecture Search using Performance Prediction @baker2018accelerating2.pdf}
}

@article{ball2023efficient,
  title = {Efficient Online Reinforcement Learning with Offline Data},
  author = {Ball, Philip J and Smith, Laura and Kostrikov, Ilya and Levine, Sergey},
  year = {2023},
  journal = {arXiv preprint arXiv:2302.02948},
  eprint = {2302.02948},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ball2023efficient-Efficient online reinforcement learning with offline data.pdf}
}

@inproceedings{bamford2022griddlyjs,
  title = {{{GriddlyJS}}: {{A Web IDE}} for {{Reinforcement Learning}}},
  booktitle = NeurIPS,
  author = {Bamford, Christopher and Jiang, Minqi and Samvelyan, Mikayel and Rockt{\"a}schel, Tim},
  year = {2022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bamford2022griddlyjs-GriddlyJS - A Web IDE for Reinforcement Learning.pdf}
}

@inproceedings{banerjee2018autonomous,
  title = {Autonomous {{Acquisition}} of {{Behavior Trees}} for {{Robot Control}}},
  booktitle = IROS,
  author = {Banerjee, Bikramjit},
  year = {2018},
  pages = {3460--3467},
  doi = {10.1109/IROS.2018.8594083},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@banerjee2018autonomous-Autonomous Acquisition of Behavior Trees for Robot Control.pdf}
}

@article{bartolozzi2022embodied,
  title = {Embodied Neuromorphic Intelligence},
  author = {Bartolozzi, Chiara and Indiveri, Giacomo and Donati, Elisa},
  year = {2022},
  month = dec,
  journal = NC,
  volume = {13},
  number = {1},
  pages = {1024},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-28487-2},
  urldate = {2022-05-03},
  abstract = {Abstract             The design of robots that interact autonomously with the environment and exhibit complex behaviours is an open challenge that can benefit from understanding what makes living beings fit to act in the world. Neuromorphic engineering studies neural computational principles to develop technologies that can provide a computing substrate for building compact and low-power processing systems. We discuss why endowing robots with neuromorphic technologies -- from perception to motor control -- represents a promising approach for the creation of robots which can seamlessly integrate in society. We present initial attempts in this direction, highlight open challenges, and propose actions required to overcome current limitations.},
  langid = {english},
  keywords = {ObsCite},
  file = {C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@bartolozzi2022embodied-Embodied neuromorphic intelligence.pdf;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@bartolozzi2022embodied-Embodied neuromorphic intelligence2.pdf}
}

@article{bastani2017synthesizing,
  title = {Synthesizing Program Input Grammars},
  author = {Bastani, Osbert and Sharma, Rahul and Aiken, Alex and Liang, Percy},
  year = {2017},
  journal = {ACM SIGPLAN Notices},
  volume = {52},
  number = {6},
  pages = {95--110},
  publisher = {ACM New York, NY, USA},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bastani2017synthesizing-Synthesizing program input grammars.pdf}
}

@inproceedings{baykal2017asymptotically,
  title = {Asymptotically {{Optimal Design}} of {{Piecewise Cylindrical Robots}} Using {{Motion Planning}}.},
  booktitle = {Robotics: {{Science}} and {{Systems}}},
  author = {Baykal, Cenk and Alterovitz, Ron},
  year = {2017},
  volume = {2017},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@baykal2017asymptotically-Asymptotically Optimal Design of Piecewise Cylindrical Robots using Motion.pdf}
}

@article{bekiroglu2020benchmarking,
  title = {Benchmarking {{Protocol}} for {{Grasp Planning Algorithms}}},
  author = {Bekiroglu, Yasemin and Marturi, Naresh and Roa, M{\'a}ximo A. and Adjigble, Komlan Jean Maxime and Pardi, Tommaso and Grimm, Cindy and Balasubramanian, Ravi and Hang, Kaiyu and Stolkin, Rustam},
  year = {2020},
  journal = {IEEE Robotics and Automation Letters},
  volume = {5},
  number = {2},
  pages = {315--322},
  doi = {10.1109/LRA.2019.2956411},
  keywords = {Benchmark testing,grasping,Grasping,performance evaluation,Planning,Protocols,Robot kinematics,Task analysis}
}

@inproceedings{belle2024neurosymbolic,
  title = {Neuro-{{Symbolic AI}} + {{Agent Systems}}: {{A First Reflection}} on┬{{{\'a}Trends}}, {{Opportunities}} and┬{{{\'a}Challenges}}},
  booktitle = {Autonomous {{Agents}} and {{Multiagent Systems}}. {{Best}} and {{Visionary Papers}}},
  author = {Belle, Vaishak and Fisher, Michael and Russo, Alessandra and Komendantskaya, Ekaterina and Nottle, Alistair},
  editor = {Amigoni, Francesco and Sinha, Arunesh},
  year = {2024},
  pages = {180--200},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  abstract = {To get one step closer to ``human-like'' intelligence, we need systems capable of seamlessly combining the neural learning power of symbolic feature extraction from raw data with sophisticated symbolic inference mechanisms for reasoning about ``high-level'' concepts. It is important to also incorporate existing prior knowledge about a given problem domain, especially since modern machine learning frameworks are typically data-hungry. Recently the field of neuro-symbolic AI has emerged as a promising paradigm for precisely such an integration.},
  isbn = {978-3-031-56255-6},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@belle2024neurosymbolic-Neuro-Symbolic AI + Agent Systems - A First Reflection on┬áTrends, Opportunities.pdf}
}

@incollection{ben-ari2018finite,
  title = {Finite {{State Machines}}},
  booktitle = {Elements of {{Robotics}}},
  author = {{Ben-Ari}, Mordechai and Mondada, Francesco},
  year = {2018},
  pages = {55--61},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-62533-1_4},
  abstract = {Robots have embedded computers with memory that can be used to store the current state of an algorithm. Finite state machines specify the conditions under which the state of the robot changes and the actions taken when the state changes. Finite state machines are demonstrated first by Braitenberg vehicles and then by an algorithm that causes the robot to search for an object and then approach it.},
  isbn = {978-3-319-62533-1},
  file = {C:\Users\lenovo\Zotero\storage\2W5FUS4S\Ben-Ari_Mondada_2018_Finite State Machines.pdf}
}

@inproceedings{berkenkamp2016safe,
  title = {Safe Learning of Regions of Attraction for Uncertain, Nonlinear Systems with Gaussian Processes},
  booktitle = {2016 {{IEEE}} 55th {{Conference}} on {{Decision}} and {{Control}} ({{CDC}})},
  author = {Berkenkamp, Felix and Moriconi, Riccardo and Schoellig, Angela P and Krause, Andreas},
  year = {2016},
  pages = {4661--4666},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@berkenkamp2016safe-Safe learning of regions of attraction for uncertain, nonlinear systems with.pdf}
}

@article{bernardo2023novel,
  title = {A {{Novel Control Architecture Based}} on {{Behavior Trees}} for an {{Omni-Directional Mobile Robot}}},
  author = {Bernardo, Rodrigo and Sousa, Jo{\~a}o MC and Botto, Miguel Ayala and Gon{\c c}alves, Paulo JS},
  year = {2023},
  journal = {Robotics},
  volume = {12},
  number = {6},
  pages = {170},
  publisher = {MDPI},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bernardo2023novel-A Novel Control Architecture Based on Behavior Trees for an Omni-Directional.pdf}
}

@article{bernstein1966coordination,
  title = {The Co-Ordination and Regulation of Movements},
  author = {Bernstein, Nikolai},
  year = {1966},
  journal = {The co-ordination and regulation of movements},
  publisher = {Pergamon press},
  keywords = {ObsCite}
}

@article{berrueta2024maximum,
  title = {Maximum Diffusion Reinforcement Learning},
  author = {Berrueta, Thomas A and Pinosky, Allison and Murphey, Todd D},
  year = {2024},
  journal = {Nature Machine Intelligence},
  pages = {1--11},
  publisher = {Nature Publishing Group UK London},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@berrueta2024maximum-Maximum diffusion reinforcement learning.pdf}
}

@incollection{besold2021neuralsymbolic,
  title = {Neural-Symbolic Learning and Reasoning: {{A}} Survey and Interpretation 1},
  booktitle = {Neuro-{{Symbolic Artificial Intelligence}}: {{The State}} of the {{Art}}},
  author = {Besold, Tarek R and {d'Avila Garcez}, Artur and Bader, Sebastian and Bowman, Howard and Domingos, Pedro and Hitzler, Pascal and K{\"u}hnberger, Kai-Uwe and Lamb, Luis C and Lima, Priscila Machado Vieira and {de Penning}, Leo and others},
  year = {2021},
  pages = {1--51},
  publisher = {IOS press},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@besold2021neuralsymbolic-Neural-symbolic learning and reasoning - A survey and interpretation 1.pdf}
}

@inproceedings{besta2024graph,
  title = {Graph of Thoughts: {{Solving}} Elaborate Problems with Large Language Models},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and others},
  year = {2024},
  volume = {38},
  pages = {17682--17690},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@besta2024graph-Graph of thoughts - Solving elaborate problems with large language models.pdf}
}

@article{bharadhwaj2024track2act,
  title = {{{Track2Act}}: {{Predicting Point Tracks}} from {{Internet Videos}} Enables {{Generalizable Robot Manipulation}}},
  author = {Bharadhwaj, Homanga and Mottaghi, Roozbeh and Gupta, Abhinav and Tulsiani, Shubham},
  year = {2024},
  journal = {arXiv preprint arXiv:2405.01527},
  eprint = {2405.01527},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bharadhwaj2024track2act-Track2Act - Predicting Point Tracks from Internet Videos enables Generalizable.pdf}
}

@inproceedings{bhatia2021evolution,
  title = {Evolution {{Gym}}: {{A Large-Scale Benchmark}} for {{Evolving Soft Robots}}},
  booktitle = NeurIPS,
  author = {Bhatia, Jagdeep Singh and Jackson, Holly and Tian, Yunsheng and Xu, Jie and Matusik, Wojciech},
  year = {2021},
  pages = {14},
  abstract = {Both the design and control of a robot play equally important roles in its task performance. However, while optimal control is well studied in the machine learning and robotics community, less attention is placed on finding the optimal robot design. This is mainly because co-optimizing design and control in robotics is characterized as a challenging problem, and more importantly, a comprehensive evaluation benchmark for co-optimization does not exist. In this paper, we propose Evolution Gym, the first large-scale benchmark for co-optimizing the design and control of soft robots. In our benchmark, each robot is composed of different types of voxels (e.g., soft, rigid, actuators), resulting in a modular and expressive robot design space. Our benchmark environments span a wide range of tasks, including locomotion on various types of terrains and manipulation. Furthermore, we develop several robot co-evolution algorithms by combining state-of-the-art design optimization methods and deep reinforcement learning techniques. Evaluating the algorithms on our benchmark platform, we observe robots exhibiting increasingly complex behaviors as evolution progresses, with the best evolved designs solving many of our proposed tasks. Additionally, even though robot designs are evolved autonomously from scratch without prior knowledge, they often grow to resemble existing natural creatures while outperforming hand-designed robots. Nevertheless, all tested algorithms fail to find robots that succeed in our hardest environments. This suggests that more advanced algorithms are required to explore the high-dimensional design space and evolve increasingly intelligent robots -- an area of research in which we hope Evolution Gym will accelerate progress. Our website with code, environments, documentation, and tutorials is available at http://evogym.csail.mit.edu.},
  langid = {english},
  keywords = {ObsCite},
  annotation = {NeurIPS},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bhatia2021evolution-Evolution Gym - A Large-Scale Benchmark for Evolving Soft Robots.pdf}
}

@article{bhuyan2024neurosymbolic,
  title = {Neuro-Symbolic Artificial Intelligence: A Survey},
  author = {Bhuyan, Bikram Pratim and {Ramdane-Cherif}, Amar and Tomar, Ravi and Singh, T. P.},
  year = {2024},
  month = jul,
  journal = {Neural Computing and Applications},
  volume = {36},
  number = {21},
  pages = {12809--12844},
  issn = {1433-3058},
  doi = {10.1007/s00521-024-09960-z},
  abstract = {The goal of the growing discipline of neuro-symbolic artificial intelligence (AI) is to develop AI systems with more human-like reasoning capabilities by combining symbolic reasoning with connectionist learning. We survey the literature on neuro-symbolic AI during the last two decades, including books, monographs, review papers, contribution pieces, opinion articles, foundational workshops/talks, and related PhD theses. Four main features of neuro-symbolic AI are discussed, including representation, learning, reasoning, and decision-making. Finally, we discuss the many applications of neuro-symbolic AI, including question answering, robotics, computer vision, healthcare, and more. Scalability, explainability, and ethical considerations are also covered, as well as other difficulties and limits of neuro-symbolic AI. This study summarizes the current state of the art in neuro-symbolic artificial intelligence.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bhuyan2024neurosymbolic-Neuro-symbolic artificial intelligence - a survey.pdf}
}

@article{biedenkapp2022learning,
  title = {Learning {{Domain-Independent Policies}} for {{Open List Selection}}},
  author = {Biedenkapp, Andr{\'e} and Speck, David and Sievers, Silvan and Hutter, Frank and Lindauer, Marius and Seipp, Jendrik},
  year = {2022},
  publisher = {University\_of\_Basel},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@biedenkapp2022learning-Learning Domain-Independent Policies for Open List Selection.pdf}
}

@inproceedings{bisson1992learning,
  title = {Learning in {{FOL}} with a Similarity Measure},
  booktitle = {Proceedings of the {{National Conference}} on {{Artificial Intelligence}}},
  author = {Bisson, Gilles},
  year = {1992},
  pages = {82--82},
  publisher = {JOHN WILEY \& SONS LTD},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bisson1992learning-Learning in FOL with a similarity measure.pdf}
}

@misc{biyemingpingbiao,
  title = {毕业明评标准},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@biyemingpingbiao-毕业明评标准.pdf}
}

@article{blake2021snowflake,
  title = {Snowflake: {{Scaling GNNs}} to High-Dimensional Continuous Control via Parameter Freezing},
  author = {Blake, Charles and Kurin, Vitaly and Igl, Maximilian and Whiteson, Shimon},
  year = {2021},
  journal = NeurIPS,
  volume = {34},
  pages = {23983--23992},
  keywords = {ObsCite},
  annotation = {在 NerveNet 基础上引入参数冻结技术训练图神经网络以解决高维连续控制问题},
  file = {C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@blake2021snowflake-Snowflake - Scaling GNNs to high-dimensional continuous control via parameter.pdf;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@blake2021snowflake-Snowflake - Scaling GNNs to high-dimensional continuous control via parameter2.pdf}
}

@inproceedings{blubaum2024causal,
  title = {Causal {{Question Answering}} with {{Reinforcement Learning}}},
  booktitle = {Proceedings of the {{ACM}} on {{Web Conference}} 2024},
  author = {Bl{\"u}baum, Lukas and Heindorf, Stefan},
  year = {2024},
  pages = {2204--2215},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@blubaum2024causal-Causal Question Answering with Reinforcement Learning.pdf}
}

@article{bonander2021using,
  title = {Using Causal Forests to Assess Heterogeneity in Cost-effectiveness Analysis},
  author = {Bonander, Carl and Svensson, Mikael},
  year = {2021},
  month = aug,
  journal = {Health Economics},
  volume = {30},
  number = {8},
  pages = {1818--1832},
  issn = {1057-9230, 1099-1050},
  doi = {10.1002/hec.4263},
  urldate = {2024-09-29},
  abstract = {We develop a method for data-driven estimation and analysis of heterogeneity in cost-effectiveness analyses (CEA) with experimental or observational individual-level data. Our implementation uses causal forests and cross-fitted augmented inverse probability weighted learning to estimate heterogeneity in incremental outcomes, costs and net monetary benefits, as well as other parameters relevant to CEA. We also show how the results can be visualized in relevant ways for the analysis of heterogeneity in CEA, such as using individual-level cost effectiveness planes. Using a simulated dataset and an R package implementing our methods, we show how the approach can be used to estimate the average cost-effectiveness in the entire sample or in subpopulations, explore and analyze the heterogeneity in incremental outcomes, costs and net monetary benefits (and their determinants), and learn policy rules from the data.},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bonander2021using-Using causal forests to assess heterogeneity in cost‐effectiveness analysis.pdf}
}

@inproceedings{bonet1997robust,
  title = {A Robust and Fast Action Selection Mechanism for Planning},
  booktitle = AAAI,
  author = {Bonet, Blai and Loerincs, G{\'a}bor and Geffner, H{\'e}ctor},
  year = {1997},
  pages = {714--719},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bonet1997robust-A robust and fast action selection mechanism for planning.pdf}
}

@article{bonet2001planning,
  title = {Planning as Heuristic Search},
  author = {Bonet, Blai and Geffner, H{\'e}ctor},
  year = {2001},
  journal = {Artificial Intelligence},
  volume = {129},
  number = {1-2},
  pages = {5--33},
  publisher = {Elsevier},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bonet2001planning-Planning as heuristic search.pdf}
}

@article{bonet2001planninga,
  title = {Planning as Heuristic Search},
  author = {Bonet, Blai and Geffner, H{\'e}ctor},
  year = {2001},
  journal = {Artificial Intelligence},
  volume = {129},
  number = {1-2},
  pages = {5--33},
  publisher = {Elsevier}
}

@article{bonet2001planningb,
  title = {Planning as Heuristic Search},
  author = {Bonet, Blai and Geffner, H{\'e}ctor},
  year = {2001},
  journal = {Artificial Intelligence},
  volume = {129},
  number = {1-2},
  pages = {5--33},
  publisher = {Elsevier}
}

@inproceedings{bongard2009impact,
  title = {The Impact of Jointly Evolving Robot Morphology and Control on Adaptation Rate},
  booktitle = GECCO,
  author = {Bongard, Josh C},
  year = {2009},
  pages = {1769--1770}
}

@article{bongard2013evolutionary,
  title = {Evolutionary {{Robotics}}},
  author = {Bongard, Josh C.},
  year = {2013},
  month = aug,
  journal = {Commun. ACM},
  volume = {56},
  number = {8},
  pages = {74--83},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {0001-0782},
  doi = {10.1145/2493883},
  abstract = {Taking a biologically inspired approach to the design of autonomous, adaptive machines.},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bongard2013evolutionary-Evolutionary Robotics.pdf}
}

@article{bonyadi2017particle,
  title = {Particle {{Swarm Optimization}} for {{Single Objective Continuous Space Problems}}: {{A Review}}},
  author = {Bonyadi, Mohammad Reza and Michalewicz, Zbigniew},
  year = {2017},
  journal = {Evolutionary Computation},
  volume = {25},
  number = {1},
  pages = {1--54},
  doi = {10.1162/EVCO_r_00180},
  keywords = {ObsCite}
}

@article{borno2017domain,
  title = {Domain of {{Attraction Expansion}} for {{Physics-Based Character Control}}},
  author = {Borno, Mazen Al and Panne, Michiel Van De and Fiume, Eugene},
  year = {2017},
  month = mar,
  journal = {ACM Trans. Graph.},
  volume = {36},
  number = {2},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {0730-0301},
  doi = {10.1145/3009907},
  abstract = {Determining effective control strategies and solutions for high-degree-of-freedom humanoid characters has been a difficult, ongoing problem. A controller is only valid for a subset of the states of the character, known as the domain of attraction (DOA). This article shows how many states that are initially outside the DOA can be brought inside it. Our first contribution is to show how DOA expansion can be performed for a high-dimensional simulated character. Our second contribution is to present an algorithm that efficiently increases the DOA using random trees that provide denser coverage than the trees produced by typical sampling-based motion-planning algorithms. The trees are constructed offline but can be queried fast enough for near-real-time control. We show the effect of DOA expansion on getting up, crouch-to-stand, jumping, and standing-twist controllers. We also show how DOA expansion can be used to connect controllers together.},
  keywords = {character animation,Computer animation,physics simulation},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@borno2017domain-Domain of Attraction Expansion for Physics-Based Character Control.pdf}
}

@article{bornstein1986frames,
  title = {Frames of {{Mind}}: {{The Theory}} of {{Multiple Intelligences Howard Gardner}}},
  author = {Bornstein, Marc H.},
  year = {1986},
  journal = {Journal of Aesthetic Education},
  volume = {20},
  number = {2},
  eprint = {3332707},
  eprinttype = {jstor},
  pages = {120--122},
  publisher = {University of Illinois Press},
  issn = {00218510, 15437809},
  urldate = {2024-09-10}
}

@article{botea2005macroff,
  title = {Macro-{{FF}}: {{Improving AI}} Planning with Automatically Learned Macro-Operators},
  author = {Botea, Adi and Enzenberger, Markus and M{\"u}ller, Martin and Schaeffer, Jonathan},
  year = {2005},
  journal = {Journal of Artificial Intelligence Research},
  volume = {24},
  pages = {581--621},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@botea2005macroff-Macro-FF - Improving AI planning with automatically learned macro-operators.pdf}
}

@article{bretan2016survey,
  title = {A Survey of Robotic Musicianship},
  author = {Bretan, Mason and Weinberg, Gil},
  year = {2016},
  month = apr,
  journal = {Communications of the ACM},
  volume = {59},
  number = {5},
  pages = {100--109},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/2818994},
  urldate = {2022-10-31},
  abstract = {Reviewing the technologies that enable robot musicians to jam.},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bretan2016survey-A survey of robotic musicianship.pdf}
}

@article{broering2021embodied,
  title = {Toward {{Embodied Intelligence}}: {{Smart Things}} on the {{Rise}}},
  shorttitle = {Toward {{Embodied Intelligence}}},
  author = {Broering, Arne and Niedermeier, Christoph and Olaru, Ioana and Schopp, Ulrich and Telschig, Kilian and Villnow, Michael},
  year = {2021},
  month = jul,
  journal = {Computer},
  volume = {54},
  number = {7},
  pages = {57--68},
  issn = {0018-9162, 1558-0814},
  doi = {10.1109/MC.2021.3074749},
  urldate = {2022-05-06},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\6VXI7EMU\Broering_2021_Toward Embodied Intelligence.pdf}
}

@article{brohan2022rt1,
  title = {Rt-1: {{Robotics}} Transformer for Real-World Control at Scale},
  author = {Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Dabis, Joseph and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Hsu, Jasmine and others},
  year = {2022},
  journal = {arXiv preprint arXiv:2212.06817},
  eprint = {2212.06817},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@brohan2022rt1-Rt-1 - Robotics transformer for real-world control at scale.pdf}
}

@article{brohan2023rt2,
  title = {Rt-2: {{Vision-language-action}} Models Transfer Web Knowledge to Robotic Control},
  author = {Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2307.15818},
  eprint = {2307.15818},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@brohan2023rt2-Rt-2 - Vision-language-action models transfer web knowledge to robotic control.pdf}
}

@book{bronshtein2015handbook,
  title = {Handbook of {{Mathematics}}},
  author = {Bronshtein, I.N. and Semendyayev, K.A. and Musiol, Gerhard and M{\"u}hlig, Heiner},
  year = {2015},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-46221-8},
  urldate = {2022-04-30},
  isbn = {978-3-662-46220-1 978-3-662-46221-8},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bronshtein2015handbook-Handbook of Mathematics.pdf}
}

@article{brooks1991intelligence,
  title = {Intelligence without Reason},
  author = {Brooks, Rodney A and others},
  year = {1991},
  journal = {Artificial intelligence: critical concepts},
  volume = {3},
  pages = {107--63}
}

@inproceedings{brown2020language,
  title = {Language Models Are Few-Shot Learners},
  booktitle = NeurIPS,
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and {Herbert-Voss}, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  editor = {Larochelle, Hugo and Ranzato, Marc'Aurelio and Hadsell, Raia and Balcan, Maria-Florina and Lin, Hsuan-Tien},
  year = {2020},
  annotation = {NeurIPS},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@brown2020language-Language models are few-shot learners.pdf}
}

@incollection{buchanan1981dendral,
  title = {{{DENDRAL}} and {{Meta-DENDRAL}}: {{Their}} Applications Dimension},
  booktitle = {Readings in Artificial Intelligence},
  author = {Buchanan, Bruce G and Feigenbaum, Edward A},
  year = {1981},
  pages = {313--322},
  publisher = {Elsevier}
}

@inproceedings{burfoot2006rrtplan,
  title = {{{RRT-Plan}}: {{A Randomized Algorithm}} for {{STRIPS Planning}}.},
  booktitle = {{{ICAPS}}},
  author = {Burfoot, Daniel and Pineau, Joelle and Dudek, Gregory},
  year = {2006},
  pages = {362--365},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@burfoot2006rrtplan-RRT-Plan - A Randomized Algorithm for STRIPS Planning.pdf}
}

@article{bylander1994computational,
  title = {The Computational Complexity of Propositional {{STRIPS}} Planning},
  author = {Bylander, Tom},
  year = {1994},
  journal = {Artificial Intelligence},
  volume = {69},
  number = {1-2},
  pages = {165--204},
  publisher = {Elsevier},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@bylander1994computational-The computational complexity of propositional STRIPS planning.pdf}
}

@inproceedings{cai2021bt,
  title = {{{BT Expansion}}: A {{Sound}} and {{Complete Algorithm}} for {{Behavior Planning}} of {{Intelligent Robots}} with {{Behavior Trees}}},
  booktitle = AAAI,
  author = {Cai, Zhongxuan and Li, Minglong and Huang, Wanrong and Yang, Wenjing},
  year = {2021},
  pages = {6058--6065},
  publisher = {AAAI Press},
  langid = {english},
  keywords = {ObsCite,team paper},
  annotation = {AAAI},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@cai2021bt-BT Expansion - a Sound and Complete Algorithm for Behavior Planning of.pdf}
}

@phdthesis{Cai2022jiyuxingweishud,
  title = {基于行为树的机器人自主行为规划方法研究},
  author = {蔡, 中轩},
  year = {2022},
  address = {长沙},
  school = {国防科技大学},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@Cai2022jiyuxingweishud-基于行为树的机器人自主行为规划方法研究.pdf}
}

@article{cai2023groot,
  title = {Groot: {{Learning}} to Follow Instructions by Watching Gameplay Videos},
  author = {Cai, Shaofei and Zhang, Bowei and Wang, Zihao and Ma, Xiaojian and Liu, Anji and Liang, Yitao},
  year = {2023},
  journal = {arXiv preprint arXiv:2310.08235},
  eprint = {2310.08235},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@cai2023groot-Groot - Learning to follow instructions by watching gameplay videos.pdf}
}

@inproceedings{cai2023task2morph,
  title = {{{Task2Morph}}: {{Differentiable Task-Inspired Framework}} for {{Contact-Aware Robot Design}}},
  booktitle = {2023 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Cai, Yishuai and Yang, Shaowu and Li, Minglong and Chen, Xinglin and Mao, Yunxin and Yi, Xiaodong and Yang, Wenjing},
  year = {2023},
  pages = {452--459},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@cai2023task2morph-Task2Morph - Differentiable Task-Inspired Framework for Contact-Aware Robot.pdf}
}

@article{cai2024rocket1,
  title = {{{ROCKET-1}}: {{Master Open-World Interaction}} with {{Visual-Temporal Context Prompting}}},
  author = {Cai, Shaofei and Wang, Zihao and Lian, Kewei and Mu, Zhancun and Ma, Xiaojian and Liu, Anji and Liang, Yitao},
  year = {2024},
  journal = {arXiv preprint arXiv:2410.17856},
  eprint = {2410.17856},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@cai2024rocket1-ROCKET-1 - Master Open-World Interaction with Visual-Temporal Context Prompting.pdf}
}

@inproceedings{cai2025mrbtp,
  title = {{{MRBTP}}: {{Efficient Multi-Robot Behavior Tree Planning}} and {{Collaboration}}},
  booktitle = AAAI,
  author = {Cai, Yishuai and Chen, Xinglin and Cai, Zhongxuan},
  year = {2025},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@cai2025mrbtp-MRBTP - Efficient Multi-Robot Behavior Tree Planning and Collaboration.pdf}
}

@article{calli2015benchmarking,
  title = {Benchmarking in {{Manipulation Research}}: {{The YCB Object}} and {{Model Set}} and {{Benchmarking Protocols}}},
  author = {Calli, Berk and Singh, Arjun and Walsman, Aaron and Srinivasa, Siddhartha S. and Abbeel, Pieter and Dollar, Aaron M.},
  year = {2015},
  journal = {IEEE Robotics \& Automation Magazine},
  volume = {22},
  pages = {36--52},
  doi = {10.1109/MRA.2015.2448951},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@calli2015benchmarking-Benchmarking in Manipulation Research - The YCB Object and Model Set and.pdf}
}

@incollection{cangelosi2015embodied,
  title = {Embodied Intelligence},
  booktitle = {Springer Handbook of Computational Intelligence},
  author = {Cangelosi, Angelo and Bongard, Josh and Fischer, Martin H. and Nolfi, Stefano},
  editor = {Kacprzyk, Janusz and Pedrycz, Witold},
  year = {2015},
  pages = {697--714},
  publisher = {Springer Berlin Heidelberg},
  keywords = {embodied intelligence},
  annotation = {Springer},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@cangelosi2015embodied-Embodied intelligence.pdf}
}

@inproceedings{cao2021more,
  title = {Towards a More Practical Data-Driven Biped Walking Control},
  booktitle = {International {{Conference}} on {{Robotics}} and {{Biomimetics}} ({{ROBIO}})},
  author = {Cao, Zhiyan and Bao, Tianxu and Jia, Wenchuan and Ma, Shugen and Yuan, Jianjun},
  year = {2021},
  month = dec,
  pages = {1058--1064},
  doi = {10.1109/ROBIO54168.2021.9739501},
  abstract = {Walking motion is a fundamental skill involved in daily bipedal activities. Generating the walking motion from mocap data requires a controllable and responsive character in both animation and robotics. The physic-based data-driven technologies nowadays have shown great value in the motion imitation of captured walking data. In this paper, we propose a new data-driven bipedal control framework by adjusting the mocap data with physics-based model to achieve a robust and natural performance while keeps the style of the data as complete as possible. In our framework, the desired bipedal action is designed from the balance strategy and a cascaded position-velocity control with gravity compensation is proposed for joint tracking control of the desired action. We demonstrate the effectiveness of this framework through different external perturbation tests. This framework more fully integrates the original data into desired-action design while keeps a robust and stable performance in the simulation.},
  keywords = {Animation,Data models,Humanoid robots,Legged locomotion,Perturbation methods,Simulation,Tracking}
}

@inproceedings{cao2022behaviortree,
  title = {Behavior-Tree Embeddings for Robot Task-Level Knowledge},
  booktitle = {2022 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Cao, Yue and Lee, CS George},
  year = {2022},
  pages = {12074--12080},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@cao2022behaviortree-Behavior-tree embeddings for robot task-level knowledge.pdf}
}

@inproceedings{cao2023robot,
  title = {Robot {{Behavior-Tree-Based Task Generation}} with {{Large Language Models}}},
  booktitle = {Proceedings of {{AAAI Spring Symp}}. {{Challenges Requiring}} the {{Combination}} of {{Machine Learning}} and {{Knowledge Engineering}}},
  author = {Cao, Yue and Lee, {\relax CS}},
  year = {2023},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@cao2023robot-Robot Behavior-Tree-Based Task Generation with Large Language Models.pdf}
}

@book{carroll2013dna,
  title = {From {{DNA}} to Diversity: Molecular Genetics and the Evolution of Animal Design},
  author = {Carroll, Sean B and Grenier, Jennifer K and Weatherbee, Scott D},
  year = {2013},
  publisher = {John Wiley \& Sons}
}

@inproceedings{carta2023grounding,
  title = {Grounding Large Language Models in Interactive Environments with Online Reinforcement Learning},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Carta, Thomas and Romac, Cl{\'e}ment and Wolf, Thomas and Lamprier, Sylvain and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  year = {2023},
  pages = {3676--3713},
  publisher = {PMLR},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@carta2023grounding-Grounding large language models in interactive environments with online.pdf}
}

@article{cavrel2022efficient,
  title = {An {{Efficient HTN}} to {{STRIPS Encoding}} for {{Concurrent Plans}}},
  author = {Cavrel, Nicolas and Pellier, Damien and Fiorino, Humbert},
  year = {2022},
  journal = {arXiv preprint arXiv:2206.07084},
  eprint = {2206.07084},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@cavrel2022efficient-An Efficient HTN to STRIPS Encoding for Concurrent Plans.pdf}
}

@misc{ccftuijianyingwen,
  title = {{{CCF推荐英文}}},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ccftuijianyingwen-CCF推荐英文.pdf}
}

@misc{ccftuijianzhongwe,
  title = {{{CCF推荐中文}}},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ccftuijianzhongwe-CCF推荐中文.pdf}
}

@book{celuesiwei,
  title = {策略思维},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@celuesiwei-策略思维.pdf}
}

@article{censi2019class,
  title = {A Class of Co-Design Problems with Cyclic Constraints and Their Solution},
  author = {Censi, A.},
  year = {2019},
  journal = RA-L,
  volume = {2},
  number = {1},
  pages = {96--103},
  abstract = {Co-design problems in the field of robotics involve the tradeoff of "resources" usage, such as cost, execution time, and energy, with mission performance, under recursive constraints that involve energetics, mechanics, computation, and communication. This letter shows that a large class of codesign problems have a common structure, as they are described by two posets, representing functionality, and resources. The codesign constraints can be expressed as two maps in opposite directions between the two posets. Finding the most resource-economical feasible solution is equivalent to finding the least fixed point of the composition of those two maps. If the two maps are monotone, results from order theory allow concluding uniqueness and systematically deriving an optimal design or a certificate for infeasibility.}
}

@article{chamzas2022motionbenchmaker,
  title = {{{MotionBenchMaker}}: {{A Tool}} to {{Generate}} and {{Benchmark Motion Planning Datasets}}},
  author = {Chamzas, Constantinos and {Quintero-Pe{\~n}a}, Carlos and Kingston, Zachary and Orthey, Andreas and Rakita, Daniel and Gleicher, Michael and Toussaint, Marc and Kavraki, Lydia E.},
  year = {2022},
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {882--889},
  doi = {10.1109/LRA.2021.3133603},
  keywords = {Benchmark testing,Data sets for robot learning,Generators,manipulation planning,motion and path planning,Planning,Robot sensing systems,Robots,Task analysis,Tools}
}

@article{chang2023survey,
  title = {A {{Survey}} on {{Evaluation}} of {{Large Language Models}}},
  author = {Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Zhu, Kaijie and Chen, Hao and Yang, Linyi and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2307.03109},
  eprint = {2307.03109},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chang2023survey-A Survey on Evaluation of Large Language Models.pdf}
}

@article{chaudhuri2021neurosymbolic,
  title = {Neurosymbolic Programming},
  author = {Chaudhuri, Swarat and Ellis, Kevin and Polozov, Oleksandr and Singh, Rishabh and {Solar-Lezama}, Armando and Yue, Yisong and others},
  year = {2021},
  journal = {Foundations and Trends{\textregistered} in Programming Languages},
  volume = {7},
  number = {3},
  pages = {158--243},
  publisher = {Now Publishers, Inc.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chaudhuri2021neurosymbolic-Neurosymbolic programming.pdf}
}

@article{Chen2003jisuanjidonghua,
  title = {计算机动画的人工生命方法研究--人工鱼的自繁衍模型},
  author = {陈, 泓娟 and 班, 晓娟 and 涂, 序彦 and 卢, 汉清},
  year = {2003},
  journal = {自动化学报},
  volume = {29},
  number = {6},
  pages = {986},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@Chen2003jisuanjidonghua-计算机动画的人工生命方法研究--人工鱼的自繁衍模型.pdf}
}

@inproceedings{chen2018hardware,
  title = {Hardware {{Conditioned Policies}} for {{Multi-Robot Transfer Learning}}},
  booktitle = NeurIPS,
  author = {Chen, Tao and Murali, Adithyavairavan and Gupta, Abhinav},
  editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and {Cesa-Bianchi}, N. and Garnett, R.},
  year = {2018},
  volume = {31},
  publisher = {Curran Associates, Inc.},
  keywords = {ObsCite},
  annotation = {介绍了基于形态参数的通用控制器，进一步还介绍了学习形态嵌入表征的方法},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2018hardware-Hardware Conditioned Policies for Multi-Robot Transfer Learning.pdf}
}

@inproceedings{chen2020hardware,
  title = {Hardware as {{Policy}}: {{Mechanical}} and {{Computational Co-Optimization}} Using {{Deep Reinforcement Learning}}},
  shorttitle = {Hardware as {{Policy}}},
  booktitle = CoRL,
  author = {Chen, Tianjian and He, Zhanpeng and Ciocarlie, Matei},
  year = {2020},
  month = nov,
  number = {arXiv:2008.04460},
  eprint = {2008.04460},
  primaryclass = {cs},
  urldate = {2022-05-24},
  abstract = {Deep Reinforcement Learning (RL) has shown great success in learning complex control policies for a variety of applications in robotics. However, in most such cases, the hardware of the robot has been considered immutable, modeled as part of the environment. In this study, we explore the problem of learning hardware and control parameters together in a unified RL framework. To achieve this, we propose to model the robot body as a ``hardware policy'', analogous to and optimized jointly with its computational counterpart. We show that, by modeling such hardware policies as auto-differentiable computational graphs, the ensuing optimization problem can be solved efficiently by gradient-based algorithms from the Policy Optimization family. We present two such design examples: a toy mass-spring problem, and a real-world problem of designing an underactuated hand. We compare our method against traditional co-optimization approaches, and also demonstrate its effectiveness by building a physical prototype based on the learned hardware parameters. Videos and more details are available at https://roamlab.github.io/hwasp/ .},
  archiveprefix = {arXiv},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2020hardware-Hardware as Policy - Mechanical and Computational Co-Optimization using Deep.pdf}
}

@article{chen2021codesigning,
  title = {Co-Designing Hardware and Control for Robot Hands},
  author = {Chen, Tianjian and He, Zhanpeng and Ciocarlie, Matei},
  year = {2021},
  journal = {Science Robotics},
  volume = {6},
  number = {54},
  pages = {eabg2133},
  doi = {10.1126/scirobotics.abg2133},
  abstract = {Policy gradient methods can be used for mechanical and computational co-design of robot manipulators. Policy gradient methods can be used for mechanical and computational co-design of robot manipulators.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2021codesigning-Co-designing hardware and control for robot hands.pdf}
}

@article{chen2021evaluating,
  title = {Evaluating Large Language Models Trained on Code},
  author = {Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  year = {2021},
  journal = {arXiv preprint arXiv:2107.03374},
  eprint = {2107.03374},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2021evaluating-Evaluating large language models trained on code.pdf}
}

@inproceedings{chen2021unsupervised,
  title = {Unsupervised {{Learning}} of {{Visual 3D Keypoints}} for {{Control}}},
  booktitle = ICML,
  author = {Chen, Boyuan and Abbeel, Pieter and Pathak, Deepak},
  editor = {Meila, Marina and Zhang, Tong},
  year = {2021},
  month = jul,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {139},
  pages = {1539--1549},
  publisher = {PMLR},
  abstract = {Learning sensorimotor control policies from high-dimensional images crucially relies on the quality of the underlying visual representations. Prior works show that structured latent space such as visual keypoints often outperforms unstructured representations for robotic control. However, most of these representations, whether structured or unstructured are learned in a 2D space even though the control tasks are usually performed in a 3D environment. In this work, we propose a framework to learn such a 3D geometric structure directly from images in an end-to-end unsupervised manner. The input images are embedded into latent 3D keypoints via a differentiable encoder which is trained to optimize both a multi-view consistency loss and downstream task objective. These discovered 3D keypoints tend to meaningfully capture robot joints as well as object movements in a consistent manner across both time and 3D space. The proposed approach outperforms prior state-of-art methods across a variety of reinforcement learning benchmarks. Code and videos at https://buoyancy99.github.io/unsup-3d-keypoints/.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2021unsupervised-Unsupervised Learning of Visual 3D Keypoints for Control.pdf}
}

@inproceedings{chen2022humanlevel,
  title = {Towards {{Human-Level Bimanual Dexterous Manipulation}} with {{Reinforcement Learning}}},
  booktitle = NeurIPS,
  author = {Chen, Yuanpei and Wu, Tianhao and Wang, Shengjie and Feng, Xidong and Jiang, Jiechuan and Lu, Zongqing and McAleer, Stephen Marcus and Dong, Hao and Zhu, Song-Chun and Yang, Yaodong},
  year = {2022},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2022humanlevel-Towards Human-Level Bimanual Dexterous Manipulation with Reinforcement Learning.pdf}
}

@article{chen2023bidexhands,
  title = {Bi-Dexhands: {{Towards}} Human-Level Bimanual Dexterous Manipulation},
  author = {Chen, Yuanpei and Geng, Yiran and Zhong, Fangwei and Ji, Jiaming and Jiang, Jiechuang and Lu, Zongqing and Dong, Hao and Yang, Yaodong},
  year = {2023},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2023bidexhands-Bi-dexhands - Towards human-level bimanual dexterous manipulation.pdf}
}

@inproceedings{chen2023codesigning,
  title = {Co-{{Designing Body}} and {{Behavior}} via {{Planning-based Hierarchical Grammatical Evolution}}},
  booktitle = {2023 3rd {{International Conference}} on {{Robotics}}, {{Automation}} and {{Intelligent Control}} ({{ICRAIC}})},
  author = {Chen, Xinglin and Huang, Da and Li, Minglong and Cai, Yishuai and Cai, Zhongxuan and Yang, Wenjing},
  year = {2023},
  pages = {102--109},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2023codesigning-Co-Designing Body and Behavior via Planning-based Hierarchical Grammatical.pdf}
}

@inproceedings{chen2023evolving,
  title = {Evolving {{Physical Instinct}} for  {{Morphology}} and {{Control Co-Adaption}}},
  booktitle = IROS,
  author = {Chen, Xinglin},
  year = {2023},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2023evolving-Evolving Physical Instinct for Morphology and Control Co-Adaption.pdf}
}

@article{chen2023robogpt,
  title = {{{RoboGPT}}: An Intelligent Agent of Making Embodied Long-Term Decisions for Daily Instruction Tasks},
  author = {Chen, Yaran and Cui, Wenbo and Chen, Yuanwen and Tan, Mining and Zhang, Xinyao and Zhao, Dongbin and Wang, He},
  year = {2023},
  journal = {arXiv preprint arXiv:2311.15649},
  eprint = {2311.15649},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2023robogpt-RoboGPT - an intelligent agent of making embodied long-term decisions for daily.pdf}
}

@article{chen2023scalable,
  title = {Scalable Multi-Robot Collaboration with Large Language Models: {{Centralized}} or Decentralized Systems?},
  author = {Chen, Yongchao and Arkin, Jacob and Zhang, Yang and Roy, Nicholas and Fan, Chuchu},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.15943},
  eprint = {2309.15943},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2023scalable-Scalable multi-robot collaboration with large language models - Centralized or.pdf}
}

@article{chen2023sequential,
  title = {Sequential Dexterity: {{Chaining}} Dexterous Policies for Long-Horizon Manipulation},
  author = {Chen, Yuanpei and Wang, Chen and {Fei-Fei}, Li and Liu, C Karen},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.00987},
  eprint = {2309.00987},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2023sequential-Sequential dexterity - Chaining dexterous policies for long-horizon manipulation.pdf}
}

@article{chen2023taskoriented,
  title = {Task-{{Oriented Dexterous Grasp Synthesis}} via {{Differentiable Grasp Wrench Boundary Estimator}}},
  author = {Chen, Jiayi and Chen, Yuxing and Zhang, Jialiang and Wang, He},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.13586},
  eprint = {2309.13586},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2023taskoriented-Task-Oriented Dexterous Grasp Synthesis via Differentiable Grasp Wrench.pdf}
}

@inproceedings{chen2024btpg,
  title = {{{BTPG}}: {{A Platform}} and {{Benchmark}} for {{Behavior Tree Planning}} in {{Everyday Service Robots}}},
  booktitle = NeurIPS,
  author = {Chen, Xinglin},
  year = {2024},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2024btpg-BTPG - A Platform and Benchmark for Behavior Tree Planning in Everyday Service.pdf}
}

@article{chen2024efficient,
  title = {Efficient {{Behavior Tree Planning}} with {{Commonsense Pruning}} and {{Heuristic}}},
  author = {Chen, Xinglin and Cai, Yishuai and Mao, Yunxin and Li, Minglong and Yang, Zhou and Shanghua, Wen and Yang, Wenjing and Xu, Weixia and Wang, Ji},
  year = {2024},
  journal = {arXiv preprint arXiv:2406.00965},
  eprint = {2406.00965},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2024efficient-Efficient Behavior Tree Planning with Commonsense Pruning and Heuristic.pdf}
}

@inproceedings{chen2024integrating,
  title = {Integrating {{Intent Understanding}} and {{Optimal Behavior Planning}} for {{Behavior Tree Generation}} from {{Human Instructions}}},
  booktitle = IJCAI,
  author = {Chen, Xinglin and Cai, Yishuai and Mao, Yunxin and Li, Minglong and Yang, Wenjing and Xu, Weixia and Wang, Ji},
  year = {2024},
  file = {C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@chen2024integrating-Integrating Intent Understanding and Optimal Behavior Planning for Behavior.zip;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@chen2024integrating-Integrating Intent Understanding and Optimal Behavior Planning for Behavior3.pdf}
}

@inproceedings{chen2024learning,
  title = {Learning {{Domain-Independent Heuristics}} for {{Grounded}} and {{Lifted Planning}}},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Chen, Dillon Z and Thi{\'e}baux, Sylvie and Trevizan, Felipe},
  year = {2024},
  volume = {38},
  pages = {20078--20086},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2024learning-Learning Domain-Independent Heuristics for Grounded and Lifted Planning.pdf}
}

@inproceedings{chen2024objectcentric,
  title = {Object-Centric Dexterous Manipulation from Human Motion Data},
  booktitle = CoRL,
  author = {Chen, Yuanpei and Wang, Chen and Yang, Yaodong and Liu, C Karen},
  year = {2024},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2024objectcentric-Object-centric dexterous manipulation from human motion data.pdf}
}

@article{chen2024when,
  title = {When Is Tree Search Useful for Llm Planning? It Depends on the Discriminator},
  author = {Chen, Ziru and White, Michael and Mooney, Raymond and Payani, Ali and Su, Yu and Sun, Huan},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.10890},
  eprint = {2402.10890},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chen2024when-When is tree search useful for llm planning - it depends on the discriminator.pdf}
}

@article{cheney2018scalable,
  title = {Scalable Co-Optimization of Morphology and Control in Embodied Machines},
  author = {Cheney, Nick and Bongard, Josh and SunSpiral, Vytas and Lipson, Hod},
  year = {2018},
  journal = {Journal of The Royal Society Interface},
  volume = {15},
  number = {143},
  pages = {20170937},
  publisher = {The Royal Society},
  keywords = {evolution}
}

@inproceedings{cheng2021heuristicguided,
  title = {Heuristic-{{Guided Reinforcement Learning}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Cheng, Ching-An and Kolobov, Andrey and Swaminathan, Adith},
  editor = {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and Liang, P. S. and Vaughan, J. Wortman},
  year = {2021},
  volume = {34},
  pages = {13550--13563},
  publisher = {Curran Associates, Inc.},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@cheng2021heuristicguided-Heuristic-Guided Reinforcement Learning.pdf}
}

@inproceedings{cheng2021nasgem,
  title = {{{NASGEM}}: {{Neural}} Architecture Search via Graph Embedding Method},
  booktitle = AAAI,
  author = {Cheng, Hsin-Pai and Zhang, Tunhou and Zhang, Yixing and Li, Shiyu and Liang, Feng and Yan, Feng and Li, Meng and Chandra, Vikas and Li, Hai and Chen, Yiran},
  year = {2021},
  pages = {7090--7098},
  publisher = {AAAI Press},
  keywords = {architecture encoding,graph embedding},
  annotation = {AAAI},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\MIFDZ2XL\\2021 - AAAI - NASGEM.pptx;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@cheng2021nasgem-NASGEM - Neural architecture search via graph embedding method.pdf}
}

@article{chenjiabai2024embodiedai,
  title = {Embodied-{{AI}} with Large Models: Research and Challenges},
  author = {Chenjia BAI, Huazhe XU, Xuelong LI},
  year = {2024},
  journal = {SCIENTIA SINICA Informationis},
  volume = {54},
  number = {9},
  pages = {2035-},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chenjiabai2024embodiedai-Embodied-AI with large models - research and challenges.pdf}
}

@inproceedings{chentanez2018physicsbased,
  title = {Physics-Based Motion Capture Imitation with Deep Reinforcement Learning},
  booktitle = SIGGRAPH,
  author = {Chentanez, Nuttapong and M{\"u}ller, Matthias and Macklin, Miles and Makoviychuk, Viktor and Jeschke, Stefan},
  year = {2018},
  pages = {1--10},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chentanez2018physicsbased-Physics-based motion capture imitation with deep reinforcement learning.pdf}
}

@article{chevalier-boisvert2023minigrid,
  title = {Minigrid \& {{Miniworld}}: {{Modular}} \& {{Customizable Reinforcement Learning Environments}} for {{Goal-Oriented Tasks}}},
  author = {{Chevalier-Boisvert}, Maxime and Dai, Bolun and Towers, Mark and de Lazcano, Rodrigo and Willems, Lucas and Lahlou, Salem and Pal, Suman and Castro, Pablo Samuel and Terry, Jordan},
  year = {2023},
  journal = {CoRR},
  volume = {abs/2306.13831}
}

@inproceedings{chi2021tohan,
  title = {{{TOHAN}}: {{A One-step Approach}} towards {{Few-shot Hypothesis Adaptation}}},
  shorttitle = {{{TOHAN}}},
  booktitle = NeurIPS,
  author = {Chi, Haoang and Liu, Feng and Yang, Wenjing and Lan, Long and Liu, Tongliang and Han, Bo and Cheung, William K. and Kwok, James T.},
  year = {2021},
  month = jun,
  urldate = {2022-03-03},
  langid = {english},
  keywords = {ObsCite,team paper},
  annotation = {NeurIPS},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chi2021tohan-TOHAN - A One-step Approach towards Few-shot Hypothesis Adaptation.pdf}
}

@article{chia2024cando,
  title = {Can-{{Do}}! {{A Dataset}} and {{Neuro-Symbolic Grounded Framework}} for {{Embodied Planning}} with {{Large Multimodal Models}}},
  author = {Chia, Yew Ken and Sun, Qi and Bing, Lidong and Poria, Soujanya},
  year = {2024},
  journal = {arXiv preprint arXiv:2409.14277},
  eprint = {2409.14277},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chia2024cando-Can-Do! A Dataset and Neuro-Symbolic Grounded Framework for Embodied Planning.pdf}
}

@inproceedings{chiang2020factor,
  title = {Factor Graph Grammars},
  booktitle = NeurIPS,
  author = {Chiang, David and Riley, Darcey},
  editor = {Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M.F. and Lin, H.},
  year = {2020},
  volume = {33},
  pages = {6648--6658},
  publisher = {Curran Associates, Inc.},
  keywords = {ObsCite,TBD},
  annotation = {NeurIPS},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chiang2020factor-Factor graph grammars.pdf}
}

@article{chiang2024mobility,
  title = {Mobility Vla: {{Multimodal}} Instruction Navigation with Long-Context Vlms and Topological Graphs},
  author = {Chiang, Hao-Tien Lewis and Xu, Zhuo and Fu, Zipeng and Jacob, Mithun George and Zhang, Tingnan and Lee, Tsang-Wei Edward and Yu, Wenhao and Schenck, Connor and Rendleman, David and Shah, Dhruv and others},
  year = {2024},
  journal = {arXiv preprint arXiv:2407.07775},
  eprint = {2407.07775},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chiang2024mobility-Mobility vla - Multimodal instruction navigation with long-context vlms and.pdf}
}

@inproceedings{chiappa2022dmap,
  title = {{{DMAP}}: A {{Distributed Morphological Attention Policy}} for Learning to Locomote with a Changing Body},
  booktitle = NeurIPS,
  author = {Chiappa, Alberto and Vargas, Alessandro Marin and Mathis, Alexander},
  editor = {Oh, Alice H. and Agarwal, Alekh and Belgrave, Danielle and Cho, Kyunghyun},
  year = {2022},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chiappa2022dmap-DMAP - a Distributed Morphological Attention Policy for learning to locomote.pdf}
}

@inproceedings{childs2008transpositions,
  title = {Transpositions and Move Groups in Monte Carlo Tree Search},
  booktitle = {2008 {{IEEE Symposium On Computational Intelligence}} and {{Games}}},
  author = {Childs, Benjamin E and Brodeur, James H and Kocsis, Levente},
  year = {2008},
  pages = {389--395},
  publisher = {IEEE}
}

@article{cho2022unsupervised,
  title = {Unsupervised Reinforcement Learning for Transferable Manipulation Skill Discovery},
  author = {Cho, Daesol and Kim, Jigang and Kim, H Jin},
  year = {2022},
  journal = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {3},
  pages = {7455--7462},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@cho2022unsupervised-Unsupervised reinforcement learning for transferable manipulation skill.pdf}
}

@inproceedings{choi2018learning,
  title = {Learning to Compose Task-Specific Tree Structures},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Choi, Jihun and Yoo, Kang Min and Lee, Sang-goo},
  year = {2018},
  volume = {32},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@choi2018learning-Learning to compose task-specific tree structures.pdf}
}

@inproceedings{chouhan2016multiagent,
  title = {A {{Multiagent Planning Algorithm}} with {{Joint Actions}}},
  booktitle = {Proceedings of the 4th {{International Conference}} on {{Frontiers}} in {{Intelligent Computing}}: {{Theory}} and {{Applications}} ({{FICTA}}) 2015},
  author = {Chouhan, Satyendra Singh and Niyogi, Rajdeep},
  editor = {Das, Swagatam and Pal, Tandra and Kar, Samarjit and Satapathy, Suresh Chandra and Mandal, Jyotsna Kumar},
  year = {2016},
  pages = {691--699},
  publisher = {Springer India},
  address = {New Delhi},
  abstract = {In this paper, we consider multiagent planning with joint actions----that refer to the same action being performed concurrently by a group of agents. There are few works that study specification of joint actions by extending PDDL. Since there are no multiagent planners that can handle joint actions, we propose a multiagent planning algorithm, which is capable of handling joint actions. In a multiagent setting, each agent has a different capability. The proposed algorithm obtains the number of agents involved in a joint action based on the capability of the individual agents. We have implemented our algorithm and compared its efficiency with some state-of-the-art classical planners. The results show that when the problem size increases, our algorithm can solve such problems whereas it cannot be solved by the classical planners.},
  isbn = {978-81-322-2695-6},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@chouhan2016multiagent-A Multiagent Planning Algorithm with Joint Actions.pdf}
}

@inproceedings{cisneros-velarde2023one,
  title = {One {{Policy}} Is {{Enough}}: {{Parallel Exploration}} with a {{Single Policy}} Is {{Near-Optimal}} for {{Reward-Free Reinforcement Learning}}},
  booktitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {{Cisneros-Velarde}, Pedro and Lyu, Boxiang and Koyejo, Sanmi and Kolar, Mladen},
  year = {2023},
  pages = {1965--2001},
  publisher = {PMLR},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@cisneros-velarde2023one-One Policy is Enough - Parallel Exploration with a Single Policy is Near-Optimal.pdf}
}

@book{clean,
  title = {Clean {{Architecture}}},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@clean-Clean Architecture.pdf}
}

@inproceedings{colledanchise2016advantages,
  title = {The Advantages of Using Behavior Trees in Mult-Robot Systems},
  booktitle = {Proceedings of {{ISR}} 2016: 47st {{International Symposium}} on {{Robotics}}},
  author = {Colledanchise, Michele and Marzinotto, Alejandro and Dimarogonas, Dimos V and Oegren, Petter},
  year = {2016},
  pages = {1--8},
  publisher = {VDE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@colledanchise2016advantages-The advantages of using behavior trees in mult-robot systems.pdf}
}

@article{colledanchise2016how,
  title = {How Behavior Trees Modularize Hybrid Control Systems and Generalize Sequential Behavior Compositions, the Subsumption Architecture, and Decision Trees},
  author = {Colledanchise, Michele and {\"O}gren, Petter},
  year = {2016},
  journal = {IEEE Transactions on robotics},
  volume = {33},
  number = {2},
  pages = {372--389},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@colledanchise2016how-How behavior trees modularize hybrid control systems and generalize sequential.pdf}
}

@book{colledanchise2018behavior,
  title = {Behavior {{Trees}} in {{Robotics}} and {{AI}}: {{An Introduction}}},
  author = {Colledanchise, Michele and {\"O}gren, Petter},
  year = {2018},
  publisher = {CRC Press},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@colledanchise2018behavior-Behavior Trees in Robotics and AI - An Introduction.pdf}
}

@inproceedings{colledanchise2019blended,
  title = {Towards {{Blended Reactive Planning}} and {{Acting}} Using {{Behavior Trees}}},
  booktitle = ICRA,
  author = {Colledanchise, Michele and Almeida, Diogo and Ogren, Petter},
  year = {2019},
  month = may,
  pages = {8839--8845},
  publisher = {IEEE},
  address = {Montreal, QC, Canada},
  doi = {10.1109/ICRA.2019.8794128},
  urldate = {2022-05-22},
  abstract = {In this paper, we show how a planning algorithm can be used to automatically create and update a Behavior Tree (BT), controlling a robot in a dynamic environment. The planning part of the algorithm is based on the idea of back chaining. Starting from a goal condition we iteratively select actions to achieve that goal, and if those actions have unmet preconditions, they are extended with actions to achieve them in the same way. The fact that BTs are inherently modular and reactive makes the proposed solution blend acting and planning in a way that enables the robot to effectively react to external disturbances. If an external agent undoes an action the robot reexecutes it without re-planning, and if an external agent helps the robot, it skips the corresponding actions, again without replanning. We illustrate our approach in two different robotics scenarios.},
  isbn = {978-1-5386-6027-0},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@colledanchise2019blended-Towards Blended Reactive Planning and Acting using Behavior Trees.pdf}
}

@article{colledanchise2019learning,
  title = {Learning of {{Behavior Trees}} for {{Autonomous Agents}}},
  author = {Colledanchise, Michele and Parasuraman, Ramviyas and {\"O}gren, Petter},
  year = {2019},
  journal = {IEEE Transactions on Games},
  volume = {11},
  number = {2},
  pages = {183--189},
  doi = {10.1109/TG.2018.2816806},
  annotation = {TOGames},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@colledanchise2019learning-Learning of Behavior Trees for Autonomous Agents.pdf}
}

@article{colledanchise2021implementation,
  title = {On the Implementation of Behavior Trees in Robotics},
  author = {Colledanchise, Michele and Natale, Lorenzo},
  year = {2021},
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {3},
  pages = {5929--5936},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@colledanchise2021implementation-On the implementation of behavior trees in robotics.pdf}
}

@article{collins2001threedimensional,
  title = {A Three-Dimensional Passive-Dynamic Walking Robot with Two Legs and Knees},
  author = {Collins, Steven H and Wisse, Martijn and Ruina, Andy},
  year = {2001},
  journal = {The International Journal of Robotics Research},
  volume = {20},
  number = {7},
  pages = {607--615},
  publisher = {SAGE Publications}
}

@article{collins2024probabilistically,
  title = {Probabilistically {{Informed Robot Object Search}} with {{Multiple Regions}}},
  author = {Collins, Matthew and Beard, Jared J and Ohi, Nicholas and Gu, Yu},
  year = {2024},
  journal = {arXiv preprint arXiv:2404.04186},
  eprint = {2404.04186},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@collins2024probabilistically-Probabilistically Informed Robot Object Search with Multiple Regions.pdf}
}

@article{coros2011locomotion,
  title = {Locomotion {{Skills}} for {{Simulated Quadrupeds}}},
  author = {Coros, Stelian and Karpathy, Andrej and Jones, Ben and Reveret, Lionel and Panne, Michiel},
  year = {2011},
  month = jul,
  journal = TOG,
  volume = {30},
  pages = {59},
  doi = {10.1145/2010324.1964954},
  abstract = {We develop an integrated set of gaits and skills for a physics-based simulation of a quadruped. The motion repertoire for our simulated dog includes walk, trot, pace, canter, transverse gallop, rotary gallop, leaps capable of jumping on-and-off platforms and over obstacles, sitting, lying down, standing up, and getting up from a fall. The controllers use a representation based on gait graphs, a dual leg frame model, a flexible spine model, and the extensive use of internal virtual forces applied via the Jacobian transpose. Optimizations are applied to these control abstractions in order to achieve robust gaits and leaps with desired motion styles. The resulting gaits are evaluated for robustness with respect to push disturbances and the traversal of variable terrain. The simulated motions are also compared to motion data captured from a filmed dog.},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@coros2011locomotion-Locomotion Skills for Simulated Quadrupeds.pdf}
}

@inproceedings{correa2021deleterelaxation,
  title = {Delete-Relaxation Heuristics for Lifted Classical Planning},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}}},
  author = {Corr{\^e}a, Augusto B and Franc{\`e}s, Guillem and Pommerening, Florian and Helmert, Malte},
  year = {2021},
  volume = {31},
  pages = {94--102},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@correa2021deleterelaxation-Delete-relaxation heuristics for lifted classical planning.pdf}
}

@inproceedings{correa2022ff,
  title = {The {{FF}} Heuristic for Lifted Classical Planning},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Corr{\^e}a, Augusto B and Pommerening, Florian and Helmert, Malte and Frances, Guillem},
  year = {2022},
  volume = {36},
  pages = {9716--9723},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@correa2022ff-The FF heuristic for lifted classical planning.pdf}
}

@inproceedings{cote2019textworld,
  title = {Textworld: {{A}} Learning Environment for Text-Based Games},
  booktitle = {Computer {{Games}}: 7th {{Workshop}}, {{CGW}} 2018, {{Held}} in {{Conjunction}} with the 27th {{International Conference}} on {{Artificial Intelligence}}, {{IJCAI}} 2018, {{Stockholm}}, {{Sweden}}, {{July}} 13, 2018, {{Revised Selected Papers}} 7},
  author = {C{\^o}t{\'e}, Marc-Alexandre and K{\'a}d{\'a}r, Akos and Yuan, Xingdi and Kybartas, Ben and Barnes, Tavian and Fine, Emery and Moore, James and Hausknecht, Matthew and El Asri, Layla and Adada, Mahmoud and others},
  year = {2019},
  pages = {41--75},
  publisher = {Springer},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@cote2019textworld-Textworld - A learning environment for text-based games.pdf}
}

@misc{coumans2016pybullet,
  title = {{{PyBullet}}, a {{Python}} Module for Physics Simulation for Games, Robotics and Machine Learning},
  author = {Coumans, Erwin and Bai, Yunfei},
  year = {2016},
  keywords = {ObsCite}
}

@inproceedings{cresswell2009acquisition,
  title = {Acquisition of Object-Centred Domain Models from Planning Examples},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}}},
  author = {Cresswell, Stephen and McCluskey, Thomas and West, Margaret},
  year = {2009},
  volume = {19},
  pages = {338--341},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@cresswell2009acquisition-Acquisition of object-centred domain models from planning examples.pdf}
}

@inproceedings{dahlquist2023reactive,
  title = {Reactive {{Multi-agent Coordination}} Using {{Auction-based Task Allocation}} and {{Behavior Trees}}},
  booktitle = {2023 {{IEEE Conference}} on {{Control Technology}} and {{Applications}} ({{CCTA}})},
  author = {Dahlquist, Niklas and Lindqvist, Bj{\"o}rn and Saradagi, Akshit and Nikolakopoulos, George},
  year = {2023},
  pages = {829--834},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@dahlquist2023reactive-Reactive Multi-agent Coordination using Auction-based Task Allocation and.pdf}
}

@article{dai2023optimal,
  title = {Optimal Scene Graph Planning with Large Language Model Guidance},
  author = {Dai, Zhirui and Asgharivaskasi, Arash and Duong, Thai and Lin, Shusen and Tzes, Maria-Elizabeth and Pappas, George and Atanasov, Nikolay},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.09182},
  eprint = {2309.09182},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@dai2023optimal-Optimal scene graph planning with large language model guidance.pdf}
}

@article{DaiYe2021zichonggoumokuai,
  title = {{自重构模块化机器人模块设计综述}},
  author = {{戴野} and {张启昊} and {高语斐} and {齐云杉} and {王建辉}},
  year = {2021},
  journal = {哈尔滨理工大学学报},
  number = {5},
  pages = {34--43},
  langid = {chinese},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@DaiYe2021zichonggoumokuai-自重构模块化机器人模块设计综述.pdf}
}

@article{daniele2022deep,
  title = {Deep Symbolic Learning: {{Discovering}} Symbols and Rules from Perceptions},
  author = {Daniele, Alessandro and Campari, Tommaso and Malhotra, Sagar and Serafini, Luciano},
  year = {2022},
  journal = {arXiv preprint arXiv:2208.11561},
  eprint = {2208.11561},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@daniele2022deep-Deep symbolic learning - Discovering symbols and rules from perceptions.pdf}
}

@article{darvariu2023tree,
  title = {Tree Search in {{DAG}} Space with Model-Based Reinforcement Learning for Causal Discovery},
  author = {Darvariu, Victor-Alexandru and Hailes, Stephen and Musolesi, Mirco},
  year = {2023},
  journal = {arXiv preprint arXiv:2310.13576},
  eprint = {2310.13576},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@darvariu2023tree-Tree search in DAG space with model-based reinforcement learning for causal.pdf}
}

@book{darwin1859origin,
  title = {On the Origin of Species by Means of Natural Selection},
  author = {Darwin, Charles},
  year = {1859},
  publisher = {John Murray},
  address = {London}
}

@article{dave2024investigating,
  title = {Investigating {{Symbolic Capabilities}} of {{Large Language Models}}},
  author = {Dave, Neisarg and Kifer, Daniel and Giles, C Lee and Mali, Ankur},
  year = {2024},
  journal = {arXiv preprint arXiv:2405.13209},
  eprint = {2405.13209},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@dave2024investigating-Investigating Symbolic Capabilities of Large Language Models.pdf}
}

@inproceedings{degris2012modelfree,
  title = {Model-{{Free}} Reinforcement Learning with Continuous Action in Practice},
  booktitle = {American {{Control Conference}} ({{ACC}})},
  author = {Degris, Thomas and Pilarski, Patrick M. and Sutton, Richard S.},
  year = {2012},
  pages = {2177--2182},
  doi = {10.1109/ACC.2012.6315022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@degris2012modelfree-Model-Free reinforcement learning with continuous action in practice.pdf}
}

@article{deitke2024molmo,
  title = {Molmo and Pixmo: {{Open}} Weights and Open Data for State-of-the-Art Multimodal Models},
  author = {Deitke, Matt and Clark, Christopher and Lee, Sangho and Tripathi, Rohun and Yang, Yue and Park, Jae Sung and Salehi, Mohammadreza and Muennighoff, Niklas and Lo, Kyle and Soldaini, Luca and others},
  year = {2024},
  journal = {arXiv preprint arXiv:2409.17146},
  eprint = {2409.17146},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@deitke2024molmo-Molmo and pixmo - Open weights and open data for state-of-the-art multimodal.pdf}
}

@article{dellacqua2023empathetic,
  title = {Empathetic Human-Agent Interaction via Emotional Behavior Trees},
  author = {Dell'Acqua, Pierangelo and Costantini, Stefania},
  year = {2023},
  journal = {Intelligenza Artificiale},
  volume = {17},
  number = {1},
  pages = {89--100},
  publisher = {IOS Press}
}

@article{dietterich2000hierarchical,
  title = {Hierarchical Reinforcement Learning with the {{MAXQ}} Value Function Decomposition},
  author = {Dietterich, Thomas G.},
  year = {2000},
  month = nov,
  journal = JAIR,
  volume = {13},
  number = {1},
  pages = {227--303},
  issn = {1076-9757},
  keywords = {ObsCite}
}

@article{dijkstra1959note,
  title = {A Note on Two Problems in Connexion with Graphs},
  author = {Dijkstra, E. W.},
  year = {1959},
  journal = {Numerische Mathematik},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@dijkstra1959note-A note on two problems in connexion with graphs.pdf}
}

@article{ding2023integrating,
  title = {Integrating Action Knowledge and {{LLMs}} for Task Planning and Situation Handling in Open Worlds},
  author = {Ding, Yan and Zhang, Xiaohan and Amiri, Saeid and Cao, Nieqing and Yang, Hao and Kaminski, Andy and Esselink, Chad and Zhang, Shiqi},
  year = {2023},
  month = dec,
  journal = {Autonomous Robots},
  volume = {47},
  number = {8},
  pages = {981--997},
  issn = {1573-7527},
  doi = {10.1007/s10514-023-10133-5},
  abstract = {Task planning systems have been developed to help robots use human knowledge (about actions) to complete long-horizon tasks. Most of them have been developed for ``closed worlds'' while assuming the robot is provided with complete world knowledge. However, the real world is generally open, and the robots frequently encounter unforeseen situations that can potentially break theplanner's completeness. Could we leverage the recent advances on pre-trained Large Language Models (LLMs) to enable classical planning systems to deal with novel situations? This paper introduces a novel framework, called COWP, for open-world task planning and situation handling. COWP dynamically augments the robot's action knowledge, including the preconditions and effects of actions, with task-oriented commonsense knowledge. COWP embraces the openness from LLMs, and is grounded to specific domains via action knowledge. For systematic evaluations, we collected a dataset that includes 1085~execution-time situations. Each situation corresponds to a state instance wherein a robot is potentially unable to complete a task using a solution that normally works. Experimental results show that our approach outperforms competitive baselines from the literature in the success rate of service tasks. Additionally, we have demonstrated COWP using a mobile manipulator. Supplementary materials are available at: https://cowplanning.github.io/},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ding2023integrating-Integrating action knowledge and LLMs for task planning and situation handling.pdf}
}

@article{dipalo2023unified,
  title = {Towards a Unified Agent with Foundation Models},
  author = {Di Palo, Norman and Byravan, Arunkumar and Hasenclever, Leonard and Wulfmeier, Markus and Heess, Nicolas and Riedmiller, Martin},
  year = {2023},
  journal = {arXiv preprint arXiv:2307.09668},
  eprint = {2307.09668},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@dipalo2023unified-Towards a unified agent with foundation models.pdf}
}

@article{dipalo2024keypoint,
  title = {Keypoint {{Action}} Tokens Enable In-Context Imitation Learning in Robotics},
  author = {Di Palo, Norman and Johns, Edward},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.19578},
  eprint = {2403.19578},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@dipalo2024keypoint-Keypoint Action tokens enable in-context imitation learning in robotics.pdf}
}

@article{doncieux2015evolutionary,
  title = {Evolutionary Robotics: {{What}}, Why, and Where To},
  author = {Doncieux, Stephane and Bredeche, Nicolas and Mouret, Jean-Baptiste and Eiben, Agoston E. (Gusz)},
  year = {2015},
  journal = FRA,
  volume = {2},
  issn = {2296-9144},
  doi = {10.3389/frobt.2015.00004},
  abstract = {Evolutionary robotics applies the selection, variation, and heredity principles of natural evolution to the design of robots with embodied intelligence. It can be considered as a subfield of robotics that aims to create more robust and adaptive robots. A pivotal feature of the evolutionary approach is that it considers the whole robot at once, and enables the exploitation of robot features in a holistic manner. Evolutionary robotics can also be seen as an innovative approach to the study of evolution based on a new kind of experimentalism. The use of robots as a substrate can help to address questions that are difficult, if not impossible, to investigate through computer simulations or biological studies. In this paper, we consider the main achievements of evolutionary robotics, focusing particularly on its contributions to both engineering and biology. We briefly elaborate on methodological issues, review some of the most interesting findings, and discuss important open issues and promising avenues for future work.},
  keywords = {ObsCite}
}

@article{dortmans2022behavior,
  title = {Behavior {{Trees}} for {{Smart Robots Practical Guidelines}} for {{Robot Software Development}}.},
  author = {Dortmans, Eric and Punter, Teade},
  year = {2022},
  journal = {Journal of Robotics},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@dortmans2022behavior-Behavior Trees for Smart Robots Practical Guidelines for Robot Software.pdf}
}

@article{driess2023palme,
  title = {Palm-e: {{An}} Embodied Multimodal Language Model},
  author = {Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2303.03378},
  eprint = {2303.03378},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@driess2023palme-Palm-e - An embodied multimodal language model.pdf}
}

@article{duan2022survey,
  title = {A Survey of Embodied Ai: {{From}} Simulators to Research Tasks},
  author = {Duan, Jiafei and Yu, Samson and Tan, Hui Li and Zhu, Hongyuan and Tan, Cheston},
  year = {2022},
  journal = {IEEE Transactions on Emerging Topics in Computational Intelligence},
  volume = {6},
  number = {2},
  pages = {230--244},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@duan2022survey-A survey of embodied ai - From simulators to research tasks.pdf}
}

@article{duan2024aha,
  title = {{{AHA}}: {{A Vision-Language-Model}} for {{Detecting}} and {{Reasoning Over Failures}} in {{Robotic Manipulation}}},
  author = {Duan, Jiafei and Pumacay, Wilbert and Kumar, Nishanth and Wang, Yi Ru and Tian, Shulin and Yuan, Wentao and Krishna, Ranjay and Fox, Dieter and Mandlekar, Ajay and Guo, Yijie},
  year = {2024},
  journal = {arXiv preprint arXiv:2410.00371},
  eprint = {2410.00371},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@duan2024aha-AHA - A Vision-Language-Model for Detecting and Reasoning Over Failures in.pdf}
}

@article{duarte2020survey,
  title = {A Survey of Planning and Learning in Games},
  author = {Duarte, Fernando Fradique and Lau, Nuno and Pereira, Artur and Reis, Luis Paulo},
  year = {2020},
  journal = {Applied Sciences},
  volume = {10},
  number = {13},
  pages = {4529},
  publisher = {MDPI}
}

@article{dubied2022simtoreal,
  title = {Sim-to-Real for Soft Robots Using Differentiable Fem: {{Recipes}} for Meshing, Damping, and Actuation},
  author = {Dubied, Mathieu and Michelis, Mike Yan and Spielberg, Andrew and Katzschmann, Robert Kevin},
  year = {2022},
  journal = RA-L,
  volume = {7},
  number = {2},
  pages = {5015--5022},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@dubied2022simtoreal-Sim-to-real for soft robots using differentiable fem - Recipes for meshing,.pdf}
}

@article{elahi2022planning,
  title = {Planning with {{Complex Data Types}} in {{PDDL}}},
  author = {Elahi, Mojtaba and Rintanen, Jussi},
  year = {2022},
  journal = {arXiv preprint arXiv:2212.14462},
  eprint = {2212.14462},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@elahi2022planning-Planning with Complex Data Types in PDDL.pdf}
}

@article{elsken2021neural,
  title = {Neural {{Architecture Search}}: {{A Survey}}},
  author = {Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
  year = {2021},
  journal = {arXiv},
  pages = {21},
  abstract = {Deep Learning has enabled remarkable progress over the last years on a variety of tasks, such as image recognition, speech recognition, and machine translation. One crucial aspect for this progress are novel neural architectures. Currently employed architectures have mostly been developed manually by human experts, which is a time-consuming and errorprone process. Because of this, there is growing interest in automated neural architecture search methods. We provide an overview of existing work in this field of research and categorize them according to three dimensions: search space, search strategy, and performance estimation strategy.},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@elsken2021neural-Neural Architecture Search - A Survey.pdf}
}

@inproceedings{emedom-nnamdi2023knowledge,
  title = {Knowledge {{Transfer}} from {{Teachers}} to {{Learners}} in {{Growing-Batch Reinforcement Learning}}},
  booktitle = {Workshop on {{Reincarnating Reinforcement Learning}} at {{ICLR}} 2023},
  author = {{Emedom-Nnamdi}, Patrick and Friesen, Abram L. and Shahriari, Bobak and de Freitas, Nando and Hoffman, Matthew},
  year = {2023},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@emedom-nnamdi2023knowledge-Knowledge Transfer from Teachers to Learners in Growing-Batch Reinforcement.pdf}
}

@article{faina2013edhmor,
  title = {{{EDHMoR}}: {{Evolutionary}} Designer of Heterogeneous Modular Robots},
  author = {Fa{\'i}{\~n}a, Andr{\'e}s and Bellas, Francisco and {L{\'o}pez-Pe{\~n}a}, Fernando and Duro, Richard J},
  year = {2013},
  journal = {Engineering Applications of Artificial Intelligence},
  volume = {26},
  number = {10},
  pages = {2408--2423},
  publisher = {Elsevier}
}

@inproceedings{fan2022minedojo,
  title = {{{MineDojo}}: {{Building Open-Ended Embodied Agents}} with {{Internet-Scale Knowledge}}},
  booktitle = NeurIPS,
  author = {Fan, Linxi and Wang, Guanzhi and Jiang, Yunfan and Mandlekar, Ajay and Yang, Yuncong and Zhu, Haoyi and Tang, Andrew and Huang, De-An and Zhu, Yuke and Anandkumar, Anima},
  year = {2022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@fan2022minedojo-MineDojo - Building Open-Ended Embodied Agents with Internet-Scale Knowledge.pdf}
}

@inproceedings{fang2020graspnet1billion,
  title = {Graspnet-1billion: {{A}} Large-Scale Benchmark for General Object Grasping},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF}} Conference on Computer Vision and Pattern Recognition},
  author = {Fang, Hao-Shu and Wang, Chenxi and Gou, Minghao and Lu, Cewu},
  year = {2020},
  pages = {11444--11453},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@fang2020graspnet1billion-Graspnet-1billion - A large-scale benchmark for general object grasping.pdf}
}

@inproceedings{fang2021adaptive,
  title = {Adaptive {{Procedural Task Generation}} for {{Hard-Exploration Problems}}},
  booktitle = ICLR,
  author = {Fang, Kuan and Zhu, Yuke and Savarese, Silvio and {Fei-Fei}, Li},
  year = {2021},
  publisher = {OpenReview.net},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@fang2021adaptive-Adaptive Procedural Task Generation for Hard-Exploration Problems.pdf}
}

@inproceedings{fang2024large,
  title = {Large Language Models Are Neurosymbolic Reasoners},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Fang, Meng and Deng, Shilong and Zhang, Yudi and Shi, Zijing and Chen, Ling and Pechenizkiy, Mykola and Wang, Jun},
  year = {2024},
  volume = {38},
  pages = {17985--17993},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@fang2024large-Large language models are neurosymbolic reasoners.pdf}
}

@inproceedings{fasel2009task,
  title = {A {{Task Specification Language}} for {{Bootstrap Learning}}.},
  booktitle = {{{AAAI Spring Symposium}}: {{Agents}} That {{Learn}} from {{Human Teachers}}},
  author = {Fasel, Ian R and Quinlan, Michael J and Stone, Peter},
  year = {2009},
  pages = {48--55},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@fasel2009task-A Task Specification Language for Bootstrap Learning.pdf}
}

@article{fawzi2022discovering,
  title = {Discovering Faster Matrix Multiplication Algorithms with Reinforcement Learning},
  author = {Fawzi, Alhussein and Balog, Matej and Huang, Aja and Hubert, Thomas and {Romera-Paredes}, Bernardino and Barekatain, Mohammadamin and Novikov, Alexander and R. Ruiz, Francisco J. and Schrittwieser, Julian and Swirszcz, Grzegorz and Silver, David and Hassabis, Demis and Kohli, Pushmeet},
  year = {2022},
  month = oct,
  journal = {Nature},
  volume = {610},
  number = {7930},
  pages = {47--53},
  issn = {1476-4687},
  doi = {10.1038/s41586-022-05172-4},
  abstract = {Improving the efficiency of algorithms for fundamental computations can have a widespread impact, as it can affect the overall speed of a large amount of computations. Matrix multiplication is one such primitive task, occurring in many systems---from neural networks to scientific computing routines. The automatic discovery of algorithms using machine learning offers the prospect of reaching beyond human intuition and outperforming the current best human-designed algorithms. However, automating the algorithm discovery procedure is intricate, as the space of possible algorithms is enormous. Here we report a deep reinforcement learning approach based on AlphaZero1 for discovering efficient and provably correct algorithms for the multiplication of arbitrary matrices. Our agent, AlphaTensor, is trained to play a single-player game where the objective is finding tensor decompositions within a finite factor space. AlphaTensor discovered algorithms that outperform the state-of-the-art complexity for many matrix sizes. Particularly relevant is the case of 4\,{\texttimes}\,4 matrices in a finite field, where AlphaTensor's algorithm improves on Strassen's two-level algorithm for the first time, to our knowledge, since its discovery 50 years ago2. We further showcase the flexibility of AlphaTensor through different use-cases: algorithms with state-of-the-art complexity for structured matrix multiplication and improved practical efficiency by optimizing matrix multiplication for runtime on specific hardware. Our results highlight AlphaTensor's ability to accelerate the process of algorithmic discovery on a range of problems, and to optimize for different criteria.},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@fawzi2022discovering-Discovering faster matrix multiplication algorithms with reinforcement learning.pdf}
}

@article{fei-fei2022searching,
  title = {Searching for {{Computer Vision North Stars}}},
  author = {{Fei-Fei}, Li and Krishna, Ranjay},
  year = {2022},
  month = may,
  journal = {Daedalus},
  volume = {151},
  number = {2},
  pages = {85--99},
  issn = {0011-5266},
  doi = {10.1162/daed_a_01902},
  urldate = {2022-05-05},
  abstract = {Computer vision is one of the most fundamental areas of artificial intelligence research. It has contributed to the tremendous progress in the recent deep learning revolution in AI. In this essay, we provide a perspective of the recent evolution of object recognition in computer vision, a flagship research topic that led to the breakthrough data set of ImageNet and its ensuing algorithm developments. We argue that much of this progress is rooted in the pursuit of research ``north stars,'' wherein researchers focus on critical problems of a scientific discipline that can galvanize major efforts and groundbreaking progress. Following the success of ImageNet and object recognition, we observe a number of exciting areas of research and a growing list of north star problems to tackle. This essay recounts the brief history of ImageNet, its related work, and the follow-up progress. The goal is to inspire more north star work to advance the field, and AI at large.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@fei-fei2022searching-Searching for Computer Vision North Stars.pdf}
}

@inproceedings{feng2023memorybased,
  title = {Memory-Based {{Exploration-value Evaluation Model}} for {{Visual Navigation}}},
  booktitle = ICRA,
  author = {Feng, Yongquan},
  year = {2023},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@feng2023memorybased-Memory-based Exploration-value Evaluation Model for Visual Navigation.pdf}
}

@article{fenton2017ponyge2,
  title = {{{PonyGE2}}: Grammatical Evolution in {{Python}}},
  author = {Fenton, Michael and McDermott, James and Fagan, David and Forstenlechner, Stefan and Hemberg, Erik and O'Neill, Michael},
  year = {2017},
  journal = GECCO,
  pages = {1194--1201},
  keywords = {ObsCite},
  annotation = {GECCO},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@fenton2017ponyge2-PonyGE2 - grammatical evolution in Python.pdf}
}

@article{ferraro2023focus,
  title = {Focus: {{Object-centric}} World Models for Robotics Manipulation},
  author = {Ferraro, Stefano and Mazzaglia, Pietro and Verbelen, Tim and Dhoedt, Bart},
  year = {2023},
  journal = {arXiv preprint arXiv:2307.02427},
  eprint = {2307.02427},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ferraro2023focus-Focus - Object-centric world models for robotics manipulation.pdf}
}

@article{fikes1971strips,
  title = {{{STRIPS}}: {{A}} New Approach to the Application of Theorem Proving to Problem Solving},
  shorttitle = {Strips},
  author = {Fikes, Richard E. and Nilsson, Nils J.},
  year = {1971},
  month = dec,
  journal = AI,
  volume = {2},
  number = {3-4},
  pages = {189--208},
  issn = {00043702},
  doi = {10.1016/0004-3702(71)90010-5},
  urldate = {2022-03-03},
  abstract = {We describe a newproblem solver called STRIPS that attempts to find a sequence of operators in a spcce o f world models to transform a given initial world model into a model in which a given goal formula can be proven to be true. STRIPS represents a world n,{\textasciitilde}del as an arbitrary collection o f first-order predicate calculus formulas and is designed to work with .models consisting of large numbers o f formulas. It employs a resolution theorem prover to answer questions o fparticular models and uses means-ends analysis to guide it to the desired goal-satisfying model.},
  langid = {english},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@fikes1971strips-STRIPS - A new approach to the application of theorem proving to problem solving.pdf}
}

@inproceedings{finn2017modelagnostic,
  title = {Model-{{Agnostic Meta-Learning}} for {{Fast Adaptation}} of {{Deep Networks}}},
  booktitle = ICML,
  author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  editor = {Precup, Doina and Teh, Yee Whye},
  year = {2017},
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {70},
  pages = {1126--1135},
  publisher = {PMLR},
  file = {C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@finn2017modelagnostic-Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.pdf;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@finn2017modelagnostic-Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks2.pdf}
}

@incollection{floreano2008evolutionary,
  title = {Evolutionary Robotics},
  booktitle = {Evolutionary {{Intelligence}}},
  author = {Floreano, Dario and Husbands, Phil and Nolfi, Stefano},
  year = {2008},
  publisher = {Springer Verlag},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@floreano2008evolutionary-Evolutionary robotics.pdf}
}

@article{floreano2013miniature,
  title = {Miniature Curved Artificial Compound Eyes},
  author = {Floreano, Dario and {Pericet-Camara}, Ramon and Viollet, St{\'e}phane and Ruffier, Franck and Br{\"u}ckner, Andreas and Leitel, Robert and Buss, Wolfgang and Menouni, Mohsine and Expert, Fabien and Juston, Rapha{\"e}l and others},
  year = {2013},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {110},
  number = {23},
  pages = {9267--9272},
  publisher = {National Acad Sciences}
}

@inproceedings{florez-puga2008dynamic,
  title = {Dynamic Expansion of Behaviour Trees},
  booktitle = {Proceedings of the {{AAAI}} Conference on Artificial Intelligence and Interactive Digital Entertainment},
  author = {{Fl{\'o}rez-Puga}, Gonzalo and {Gomez-Martin}, Marco and {Diaz-Agudo}, Belen and {Gonzalez-Calero}, Pedro},
  year = {2008},
  volume = {4},
  pages = {36--41}
}

@inproceedings{formanek2023reduce,
  title = {Reduce, {{Reuse}}, {{Recycle}}: {{Selective Reincarnation}} in {{Multi-Agent Reinforcement Learning}}},
  booktitle = {Workshop on {{Reincarnating Reinforcement Learning}} at {{ICLR}} 2023},
  author = {Formanek, Juan Claude and Tilbury, Callum Rhys and Shock, Jonathan Phillip and Tessera, Kale-ab and Pretorius, Arnu},
  year = {2023},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@formanek2023reduce-Reduce, Reuse, Recycle - Selective Reincarnation in Multi-Agent Reinforcement.pdf}
}

@article{francis2022core,
  title = {Core Challenges in Embodied Vision-Language Planning},
  author = {Francis, Jonathan and Kitamura, Nariaki and Labelle, Felix and Lu, Xiaopeng and Navarro, Ingrid and Oh, Jean},
  year = {2022},
  journal = {Journal of Artificial Intelligence Research},
  volume = {74},
  pages = {459--515},
  urldate = {2024-01-02},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@francis2022core-Core challenges in embodied vision-language planning.pdf}
}

@inproceedings{freeman2021brax,
  title = {Brax - {{A Differentiable Physics Engine}} for {{Large Scale Rigid Body Simulation}}},
  booktitle = {Proceedings of the {{Neural Information Processing Systems Track}} on {{Datasets}} and {{Benchmarks}}},
  author = {Freeman, C. Daniel and Frey, Erik and Raichuk, Anton and Girgin, Sertan and Mordatch, Igor and Bachem, Olivier},
  editor = {Vanschoren, Joaquin and Yeung, Sai-Kit},
  year = {2021},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@freeman2021brax-Brax - A Differentiable Physics Engine for Large Scale Rigid Body Simulation.pdf}
}

@inproceedings{french2019learning,
  title = {Learning Behavior Trees from Demonstration},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {French, Kevin and Wu, Shiyu and Pan, Tianyang and Zhou, Zheming and Jenkins, Odest Chadwicke},
  year = {2019},
  pages = {7791--7797},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@french2019learning-Learning behavior trees from demonstration.pdf}
}

@article{fu2022rfuniverse,
  title = {{{RFUniverse}}: {{A Multiphysics Simulation Platform}} for {{Embodied AI}}},
  author = {Fu, Haoyuan and Xu, Wenqiang and Ye, Ruolin and Xue, Han and Yu, Zhenjun and Tang, Tutian and Li, Yutong and Du, Wenxin and Zhang, Jieyi and Lu, Cewu},
  year = {2022},
  journal = {arXiv preprint arXiv:2202.00199},
  eprint = {2202.00199},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@fu2022rfuniverse-RFUniverse - A Multiphysics Simulation Platform for Embodied AI.pdf}
}

@inproceedings{furelos-blanco2023hierarchies,
  title = {Hierarchies of {{Reward Machines}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Machine Learning}}},
  author = {{Furelos-Blanco}, Daniel and Law, Mark and Jonsson, Anders and Broda, Krysia and Russo, Alessandra},
  editor = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  year = {2023},
  month = jul,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {202},
  pages = {10494--10541},
  publisher = {PMLR},
  abstract = {Reward machines (RMs) are a recent formalism for representing the reward function of a reinforcement learning task through a finite-state machine whose edges encode subgoals of the task using high-level events. The structure of RMs enables the decomposition of a task into simpler and independently solvable subtasks that help tackle long-horizon and/or sparse reward tasks. We propose a formalism for further abstracting the subtask structure by endowing an RM with the ability to call other RMs, thus composing a hierarchy of RMs (HRM). We exploit HRMs by treating each call to an RM as an independently solvable subtask using the options framework, and describe a curriculum-based method to learn HRMs from traces observed by the agent. Our experiments reveal that exploiting a handcrafted HRM leads to faster convergence than with a flat HRM, and that learning an HRM is feasible in cases where its equivalent flat representation is not.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@furelos-blanco2023hierarchies-Hierarchies of Reward Machines.pdf}
}

@inproceedings{furuta2023system,
  title = {A {{System}} for {{Morphology-Task Generalization}} via {{Unified Representation}} and {{Behavior Distillation}}},
  booktitle = ICLR,
  author = {Furuta, Hiroki and Iwasawa, Yusuke and Matsuo, Yutaka and Gu, Shixiang Shane},
  year = {2023},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@furuta2023system-A System for Morphology-Task Generalization via Unified Representation and.pdf}
}

@inproceedings{gan2022threedworld,
  title = {The Threedworld Transport Challenge: {{A}} Visually Guided Task-and-Motion Planning Benchmark towards Physically Realistic Embodied Ai},
  booktitle = {2022 {{International}} Conference on Robotics and Automation ({{ICRA}})},
  author = {Gan, Chuang and Zhou, Siyuan and Schwartz, Jeremy and Alter, Seth and Bhandwaldar, Abhishek and Gutfreund, Dan and Yamins, Daniel LK and DiCarlo, James J and McDermott, Josh and Torralba, Antonio and others},
  year = {2022},
  pages = {8847--8854},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gan2022threedworld-The threedworld transport challenge - A visually guided task-and-motion planning.pdf}
}

@article{gao2019graphnas,
  title = {{{GraphNAS}}: {{Graph Neural Architecture Search}} with {{Reinforcement Learning}}},
  shorttitle = {{{GraphNAS}}},
  author = {Gao, Yang and Yang, Hong and Zhang, Peng and Zhou, Chuan and Hu, Yue},
  year = {2019},
  month = aug,
  journal = {arXiv},
  urldate = {2022-04-04},
  abstract = {Graph Neural Networks (GNNs) have been popularly used for analyzing non-Euclidean data such as social network data and biological data. Despite their success, the design of graph neural networks requires a lot of manual work and domain knowledge. In this paper, we propose a Graph Neural Architecture Search method (GraphNAS for short) that enables automatic search of the best graph neural architecture based on reinforcement learning. Specifically, GraphNAS first uses a recurrent network to generate variable-length strings that describe the architectures of graph neural networks, and then trains the recurrent network with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation data set. Extensive experimental results on node classification tasks in both transductive and inductive learning settings demonstrate that GraphNAS can achieve consistently better performance on the Cora, Citeseer, Pubmed citation network, and protein-protein interaction network. On node classification tasks, GraphNAS can design a novel network architecture that rivals the best humaninvented architecture in terms of test set accuracy.},
  langid = {english},
  keywords = {GNN,reinforcement learning},
  annotation = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gao2019graphnas-GraphNAS - Graph Neural Architecture Search with Reinforcement Learning.pdf}
}

@inproceedings{gao2020graph,
  title = {Graph {{Neural Architecture Search}}},
  booktitle = IJCAI,
  author = {Gao, Yang and Yang, Hong and Zhang, Peng and Zhou, Chuan and Hu, Yue},
  year = {2020},
  month = jul,
  pages = {1403--1409},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  address = {Yokohama, Japan},
  doi = {10.24963/ijcai.2020/195},
  urldate = {2022-04-11},
  abstract = {Graph neural networks (GNNs) emerged recently as a powerful tool for analyzing non-Euclidean data such as social network data. Despite their success, the design of graph neural networks requires heavy manual work and domain knowledge. In this paper, we present a graph neural architecture search method (GraphNAS) that enables automatic design of the best graph neural architecture based on reinforcement learning. Specifically, GraphNAS uses a recurrent network to generate variable-length strings that describe the architectures of graph neural networks, and trains the recurrent network with policy gradient to maximize the expected accuracy of the generated architectures on a validation data set. Furthermore, to improve the search efficiency of GraphNAS on big networks, GraphNAS restricts the search space from an entire architecture space to a sequential concatenation of the best search results built on each single architecture layer. Experiments on real-world datasets demonstrate that GraphNAS can design a novel network architecture that rivals the best human-invented architecture in terms of validation set accuracy. Moreover, in a transfer learning task we observe that graph neural architectures designed by GraphNAS, when transferred to new datasets, still gain improvement in terms of prediction accuracy.},
  isbn = {978-0-9992411-6-5},
  langid = {english},
  keywords = {graph},
  annotation = {IJCAI},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gao2020graph-Graph Neural Architecture Search.pdf}
}

@inproceedings{gao2023pal,
  title = {Pal: {{Program-aided}} Language Models},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  year = {2023},
  pages = {10764--10799},
  publisher = {PMLR},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gao2023pal-Pal - Program-aided language models.pdf}
}

@article{gao2023retrievalaugmented,
  title = {Retrieval-Augmented Generation for Large Language Models: {{A}} Survey},
  author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen},
  year = {2023},
  journal = {arXiv preprint arXiv:2312.10997},
  eprint = {2312.10997},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gao2023retrievalaugmented-Retrieval-augmented generation for large language models - A survey.pdf}
}

@article{gao2024dagplan,
  title = {{{DAG-Plan}}: {{Generating Directed Acyclic Dependency Graphs}} for {{Dual-Arm Cooperative Planning}}},
  author = {Gao, Zeyu and Mu, Yao and Qu, Jinye and Hu, Mengkang and Guo, Lingyue and Luo, Ping and Lu, Yanfeng},
  year = {2024},
  journal = {arXiv preprint arXiv:2406.09953},
  eprint = {2406.09953},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gao2024dagplan-DAG-Plan - Generating Directed Acyclic Dependency Graphs for Dual-Arm.pdf}
}

@article{garrett2017strips,
  title = {Strips Planning in Infinite Domains},
  author = {Garrett, Caelan Reed and {Lozano-P{\'e}rez}, Tom{\'a}s and Kaelbling, Leslie Pack},
  year = {2017},
  journal = {arXiv preprint arXiv:1701.00287},
  eprint = {1701.00287},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@garrett2017strips-Strips planning in infinite domains.pdf}
}

@inproceedings{gauci2017error,
  title = {Error {{Cascades}} in {{Collective Behavior}}: {{A Case Study}} of the {{Gradient Algorithm}} on 1000 {{Physical Agents}}},
  booktitle = {Proceedings of the 16th {{Conference}} on {{Autonomous Agents}} and {{MultiAgent Systems}}, {{AAMAS}} 2017, {{S{\~a}o Paulo}}, {{Brazil}}, {{May}} 8-12, 2017},
  author = {Gauci, Melvin and Ortiz, Monica E. and Rubenstein, Michael and Nagpal, Radhika},
  year = {2017},
  pages = {1404--1412},
  publisher = {ACM}
}

@article{gaur2023reasoning,
  title = {Reasoning in Large Language Models through Symbolic Math Word Problems},
  author = {Gaur, Vedant and Saunshi, Nikunj},
  year = {2023},
  journal = {arXiv preprint arXiv:2308.01906},
  eprint = {2308.01906},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gaur2023reasoning-Reasoning in large language models through symbolic math word problems.pdf}
}

@inproceedings{gehring2022reinforcement,
  title = {Reinforcement Learning for Classical Planning: {{Viewing}} Heuristics as Dense Reward Generators},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}}},
  author = {Gehring, Clement and Asai, Masataro and Chitnis, Rohan and Silver, Tom and Kaelbling, Leslie and Sohrabi, Shirin and Katz, Michael},
  year = {2022},
  volume = {32},
  pages = {588--596},
  abstract = {Recent advances in reinforcement learning (RL) have led to a growing interest in applying RL to classical planning domains or applying classical planning methods to some complex RL domains. However, the long-horizon goal-based problems found in classical planning lead to sparse rewards for RL, making direct application inefficient. In this paper, we propose to leverage domain-independent heuristic functions commonly used in the classical planning literature to improve the sample efficiency of RL. These classical heuristics act as dense reward generators to alleviate the sparse-rewards issue and enable our RL agent to learn domain-specific value functions as residuals on these heuristics, making learning easier. Correct application of this technique requires consolidating the discounted metric used in RL and the non-discounted metric used in heuristics. We implement the value functions using Neural Logic Machines, a neural network architecture designed for grounded first-order logic inputs. We demonstrate on several classical planning domains that using classical heuristics for RL allows for good sample efficiency compared to sparse-reward RL. We further show that our learned value functions generalize to novel problem instances in the same domain. The source code and the appendix are available at github. com/ibm/pddlrl and arxiv. org/abs/2109.14830.}
}

@article{geijtenbeek2012interactive,
  title = {Interactive {{Character Animation Using Simulated Physics}}: {{A State-of-the-Art Review}}},
  shorttitle = {Interactive {{Character Animation Using Simulated Physics}}},
  author = {Geijtenbeek, T. and Pronost, N.},
  year = {2012},
  month = dec,
  journal = {Computer Graphics Forum},
  volume = {31},
  number = {8},
  pages = {2492--2515},
  issn = {01677055},
  doi = {10.1111/j.1467-8659.2012.03189.x},
  urldate = {2022-06-10},
  abstract = {Physics simulation offers the possibility of truly responsive and realistic animation. Despite wide adoption of physics simulation for the animation of passive phenomena, such as fluids, cloths and rag-doll characters, commercial applications still resort to kinematics-based approaches for the animation of actively controlled characters. However, following a renewed interest in the use of physics simulation for interactive character animation, many recent publications demonstrate tremendous improvements in robustness, visual quality and usability. We present a structured review of over two decades of research on physics-based character animation, as well as point out various open research areas and possible future directions.},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@geijtenbeek2012interactive-Interactive Character Animation Using Simulated Physics - A State-of-the-Art.pdf}
}

@inproceedings{geng2023partmanip,
  title = {{{PartManip}}: {{Learning Cross-Category Generalizable Part Manipulation Policy From Point Cloud Observations}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Geng, Haoran and Li, Ziming and Geng, Yiran and Chen, Jiayi and Dong, Hao and Wang, He},
  year = {2023},
  month = jun,
  pages = {2978--2988},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@geng2023partmanip-PartManip - Learning Cross-Category Generalizable Part Manipulation Policy From.pdf}
}

@inproceedings{gerevini2002lpg,
  title = {{{LPG}}: {{A Planner Based}} on {{Local Search}} for {{Planning Graphs}} with {{Action Costs}}.},
  booktitle = {Aips},
  author = {Gerevini, Alfonso and Serina, Ivan and others},
  year = {2002},
  volume = {2},
  pages = {281--290},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gerevini2002lpg-LPG - A Planner Based on Local Search for Planning Graphs with Action Costs.pdf}
}

@book{ghallab2004automated,
  title = {Automated {{Planning}}: {{Theory}} and {{Practice}}},
  author = {Ghallab, Malik},
  year = {2004},
  publisher = {Morgan Kaufmann}
}

@inproceedings{ghzouli2020behavior,
  title = {Behavior Trees in Action: A Study of Robotics Applications},
  booktitle = {Proceedings of the 13th {{ACM SIGPLAN International Conference}} on {{Software Language Engineering}}},
  author = {Ghzouli, Razan and Berger, Thorsten and Johnsen, Einar Broch and Dragule, Swaib and W{\k a}sowski, Andrzej},
  year = {2020},
  series = {{{SLE}} 2020},
  pages = {196--209},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3426425.3426942},
  abstract = {Autonomous robots combine a variety of skills to form increasingly complex behaviors called missions. While the skills are often programmed at a relatively low level of abstraction, their coordination is architecturally separated and often expressed in higher-level languages or frameworks. Recently, the language of Behavior Trees gained attention among roboticists for this reason. Originally designed for computer games to model autonomous actors, Behavior Trees offer an extensible tree-based representation of missions. However, even though, several implementations of the language are in use, little is known about its usage and scope in the real world. How do behavior trees relate to traditional languages for describing behavior? How are behavior tree concepts used in applications? What are the benefits of using them? We present a study of the key language concepts in Behavior Trees and their use in real-world robotic applications. We identify behavior tree languages and compare their semantics to the most well-known behavior modeling languages: state and activity diagrams. We mine open source repositories for robotics applications that use the language and analyze this usage. We find that Behavior Trees are a pragmatic language, not fully specified, allowing projects to extend it even for just one model. Behavior trees clearly resemble the models-at-runtime paradigm. We contribute a dataset of real-world behavior models, hoping to inspire the community to use and further develop this language, associated tools, and analysis techniques.},
  isbn = {978-1-4503-8176-5},
  keywords = {behavior trees,empirical study,robotics applications},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ghzouli2020behavior-Behavior trees in action - a study of robotics applications.pdf}
}

@inproceedings{gigante2023compilability,
  title = {On the Compilability of Bounded Numeric Planning},
  booktitle = {Proceedings of the 32nd {{International Joint Conference}} on {{Artificial Intelligence}}, {{IJCAI}}},
  author = {Gigante, Nicola and Scala, Enrico},
  year = {2023},
  volume = {23},
  pages = {5341--5349},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gigante2023compilability-On the compilability of bounded numeric planning.pdf}
}

@article{glanois2024survey,
  title = {A Survey on Interpretable Reinforcement Learning},
  author = {Glanois, Claire and Weng, Paul and Zimmer, Matthieu and Li, Dong and Yang, Tianpei and Hao, Jianye and Liu, Wulong},
  year = {2024},
  journal = {Machine Learning},
  pages = {1--44},
  publisher = {Springer},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@glanois2024survey-A survey on interpretable reinforcement learning.pdf}
}

@article{gong2016evolutionary,
  title = {Evolutionary Computation in {{China}}: {{A}} Literature Survey},
  shorttitle = {Evolutionary Computation in {{China}}},
  author = {Gong, Maoguo and Wang, Shanfeng and Liu, Wenfeng and Yan, Jianan and Jiao, Licheng},
  year = {2016},
  month = oct,
  journal = {CAAI Transactions on Intelligence Technology},
  volume = {1},
  number = {4},
  pages = {334--354},
  issn = {24682322},
  doi = {10.1016/j.trit.2016.11.002},
  urldate = {2022-02-28},
  abstract = {Evolutionary computation (EC) has received significant attention in China during the last two decades. In this paper, we present an overview of the current state of this rapidly growing field in China. Chinese research in theoretical foundations of EC, EC-based optimization, EC-based data mining, and EC-based real-world applications are summarized.},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gong2016evolutionary-Evolutionary computation in China - A literature survey.pdf}
}

@article{gong2023mindagent,
  title = {Mindagent: {{Emergent}} Gaming Interaction},
  author = {Gong, Ran and Huang, Qiuyuan and Ma, Xiaojian and Vo, Hoi and Durante, Zane and Noda, Yusuke and Zheng, Zilong and Zhu, Song-Chun and Terzopoulos, Demetri and {Fei-Fei}, Li and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.09971},
  eprint = {2309.09971},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gong2023mindagent-Mindagent - Emergent gaming interaction.pdf}
}

@inproceedings{gorner2023plucking,
  title = {Plucking {{Chordophones}} through {{Kinesthetic Teaching}} and {{Audio-Tactile Feedback}}},
  booktitle = ICRA,
  author = {G{\"o}rner, Michael},
  year = {2023},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\2YAAWIWZ\\Görner_2023_Plucking Chordophones through Kinesthetic Teaching and Audio-Tactile Feedback.docx;C\:\\Users\\lenovo\\Zotero\\storage\\GKJ2ELBK\\Görner_2023_Plucking Chordophones through Kinesthetic Teaching and Audio-Tactile Feedback.md;C\:\\Users\\lenovo\\Zotero\\storage\\PYS4HPCV\\Görner_2023_Plucking Chordophones through Kinesthetic Teaching and Audio-Tactile Feedback.mp4;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@gorner2023plucking-Plucking Chordophones through Kinesthetic Teaching and Audio-Tactile Feedback.docx;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@gorner2023plucking-Plucking Chordophones through Kinesthetic Teaching and Audio-Tactile Feedback.pdf}
}

@article{gou2021knowledge,
  title = {Knowledge {{Distillation}}: {{A Survey}}},
  author = {Gou, Jianping and Yu, Baosheng and Maybank, Stephen J. and Tao, Dacheng},
  year = {2021},
  month = jun,
  journal = {IJCV},
  volume = {129},
  number = {6},
  pages = {1789--1819},
  issn = {1573-1405},
  doi = {10.1007/s11263-021-01453-z},
  abstract = {In recent years, deep neural networks have been successful in both industry and academia, especially for computer vision tasks. The great success of deep learning is mainly due to its scalability to encode large-scale data and to maneuver billions of model parameters. However, it is a challenge to deploy these cumbersome deep models on devices with limited resources, e.g., mobile phones and embedded devices, not only because of the high computational complexity but also the large storage requirements. To this end, a variety of model compression and acceleration techniques have been developed. As a representative type of model compression and acceleration, knowledge distillation effectively learns a small student model from a large teacher model. It has received rapid increasing attention from the community. This paper provides a comprehensive survey of knowledge distillation from the perspectives of knowledge categories, training schemes, teacher鈥搒tudent architecture, distillation algorithms, performance comparison and applications. Furthermore, challenges in knowledge distillation are briefly reviewed and comments on future research are discussed and forwarded.},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gou2021knowledge-Knowledge Distillation - A Survey.pdf}
}

@article{goyal2018graph,
  title = {Graph Embedding Techniques, Applications, and Performance: {{A}} Survey},
  author = {Goyal, Palash and Ferrara, Emilio},
  year = {2018},
  journal = KBS,
  volume = {151},
  pages = {78--94},
  issn = {0950-7051},
  doi = {10.1016/j.knosys.2018.03.022},
  abstract = {Graphs, such as social networks, word co-occurrence networks, and communication networks, occur naturally in various real-world applications. Analyzing them yields insight into the structure of society, language, and different patterns of communication. Many approaches have been proposed to perform the analysis. Recently, methods which use the representation of graph nodes in vector space have gained traction from the research community. In this survey, we provide a comprehensive and structured analysis of various graph embedding techniques proposed in the literature. We first introduce the embedding task and its challenges such as scalability, choice of dimensionality, and features to be preserved, and their possible solutions. We then present three categories of approaches based on factorization methods, random walks, and deep learning, with examples of representative algorithms in each category and analysis of their performance on various tasks. We evaluate these state-of-the-art methods on a few common datasets and compare their performance against one another. Our analysis concludes by suggesting some potential applications and future directions. We finally present the open-source Python library we developed, named GEM (Graph Embedding Methods, available at https://github.com/palash1992/GEM), which provides all presented algorithms within a unified interface to foster and facilitate research on the topic.},
  keywords = {graph embedding},
  annotation = {KBS},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@goyal2018graph-Graph embedding techniques, applications, and performance - A survey.pdf}
}

@article{goyal2021neural,
  title = {Neural Production Systems},
  author = {Goyal, A. and Didolkar, A. and Ke, N. R. and Blundell, C. and Bengio, Y.},
  year = {2021},
  journal = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@goyal2021neural-Neural production systems.pdf}
}

@inproceedings{gregory2016domain,
  title = {Domain Model Acquisition in Domains with Action Costs},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}}},
  author = {Gregory, Peter and Lindsay, Alan},
  year = {2016},
  volume = {26},
  pages = {149--157},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gregory2016domain-Domain model acquisition in domains with action costs.pdf}
}

@article{gu2023rlrtree,
  title = {The Rlr-Tree: {{A}} Reinforcement Learning Based r-Tree for Spatial Data},
  author = {Gu, Tu and Feng, Kaiyu and Cong, Gao and Long, Cheng and Wang, Zheng and Wang, Sheng},
  year = {2023},
  journal = {Proceedings of the ACM on Management of Data},
  volume = {1},
  number = {1},
  pages = {1--26},
  publisher = {ACM New York, NY, USA},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gu2023rlrtree-The rlr-tree - A reinforcement learning based r-tree for spatial data.pdf}
}

@article{gu2024seal,
  title = {{{SEAL}}: {{SEmantic-Augmented Imitation Learning}} via {{Language Model}}},
  author = {Gu, Chengyang and Pan, Yuxin and Bai, Haotian and Xiong, Hui and Chen, Yize},
  year = {2024},
  journal = {arXiv preprint arXiv:2410.02231},
  eprint = {2410.02231},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gu2024seal-SEAL - SEmantic-Augmented Imitation Learning via Language Model.pdf}
}

@inproceedings{guan2023leveraging,
  title = {Leveraging {{Pre-trained Large Language Models}} to {{Construct}} and {{Utilize World Models}} for {{Model-based Task Planning}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Guan, Lin and Valmeekam, Karthik and Sreedharan, Sarath and Kambhampati, Subbarao},
  editor = {Oh, A. and Neumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.},
  year = {2023},
  volume = {36},
  pages = {79081--79094},
  publisher = {Curran Associates, Inc.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@guan2023leveraging-Leveraging Pre-trained Large Language Models to Construct and Utilize World.pdf}
}

@article{gugliermo2023learning,
  title = {Learning Behavior Trees from Planning Experts Using Decision Tree and Logic Factorization},
  author = {Gugliermo, Simona and Schaffernicht, Erik and Koniaris, Christos and Pecora, Federico},
  year = {2023},
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {6},
  pages = {3534--3541},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gugliermo2023learning-Learning behavior trees from planning experts using decision tree and logic.pdf}
}

@inproceedings{guidotti2024generative,
  title = {Generative {{Model}} for {{Decision Trees}}},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Guidotti, Riccardo and Monreale, Anna and Setzu, Mattia and Volpi, Giulia},
  year = {2024},
  volume = {38},
  pages = {21116--21124},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@guidotti2024generative-Generative Model for Decision Trees.pdf}
}

@inproceedings{gulcehre2020making,
  title = {Making {{Efficient Use}} of {{Demonstrations}} to {{Solve Hard Exploration Problems}}},
  booktitle = ICLR,
  author = {Gulcehre, Caglar and Paine, Tom Le and Shahriari, Bobak and Denil, Misha and Hoffman, Matt and Soyer, Hubert and Tanburn, Richard and Kapturowski, Steven and Rabinowitz, Neil and Williams, Duncan and {Barth-Maron}, Gabriel and Wang, Ziyu and de Freitas, Nando and Team, Worlds},
  year = {2020},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gulcehre2020making-Making Efficient Use of Demonstrations to Solve Hard Exploration Problems.pdf}
}

@article{guo2018allianceros,
  title = {{{ALLIANCE-ROS}}: {{A Software Framework}} on {{ROS}} for {{Fault-Tolerant}} and {{Cooperative Mobile Robots}}},
  author = {Guo, Zhongyuan and Yang, Wenjing and Li, Minglong and Yi, Xiaodong and Cai, Zhongxuan and Wang, Yanzhen},
  year = {2018},
  journal = {Chinese Journal of Electronics},
  volume = {27},
  number = {3},
  pages = {467--475},
  publisher = {Wiley Online Library},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@guo2018allianceros-ALLIANCE-ROS - A Software Framework on ROS for Fault-Tolerant and Cooperative.pdf}
}

@article{guo2023recent,
  title = {Recent Trends in Task and Motion Planning for Robotics: {{A}} Survey},
  author = {Guo, Huihui and Wu, Fan and Qin, Yunchuan and Li, Ruihui and Li, Keqin and Li, Kenli},
  year = {2023},
  journal = {ACM Computing Surveys},
  volume = {55},
  number = {13s},
  pages = {1--36},
  publisher = {ACM New York, NY},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@guo2023recent-Recent trends in task and motion planning for robotics - A survey.pdf}
}

@article{guo2024large,
  title = {Large Language Model Based Multi-Agents: {{A}} Survey of Progress and Challenges},
  author = {Guo, Taicheng and Chen, Xiuying and Wang, Yaqi and Chang, Ruidi and Pei, Shichao and Chawla, Nitesh V and Wiest, Olaf and Zhang, Xiangliang},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.01680},
  eprint = {2402.01680},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@guo2024large-Large language model based multi-agents - A survey of progress and challenges.pdf}
}

@inproceedings{gupta2017cooperative,
  title = {Cooperative {{Multi-agent Control Using Deep Reinforcement Learning}}},
  booktitle = AAMAS,
  author = {Gupta, Jayesh K. and Egorov, Maxim and Kochenderfer, Mykel},
  editor = {Sukthankar, Gita and {Rodriguez-Aguilar}, Juan A.},
  year = {2017},
  volume = {10642},
  pages = {66--83},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-71682-4_5},
  urldate = {2022-12-01},
  abstract = {This work considers the problem of learning cooperative policies in complex, partially observable domains without explicit communication. We extend three classes of single-agent deep reinforcement learning algorithms based on policy gradient, temporal-difference error, and actor-critic methods to cooperative multi-agent systems. We introduce a set of cooperative control tasks that includes tasks with discrete and continuous actions, as well as tasks that involve hundreds of agents. The three approaches are evaluated against each other using different neural architectures, training procedures, and reward structures. Using deep reinforcement learning with a curriculum learning scheme, our approach can solve problems that were previously considered intractable by most multi-agent reinforcement learning algorithms. We show that policy gradient methods tend to outperform both temporal-difference and actor-critic methods when using feed-forward neural architectures. We also show that recurrent policies, while more difficult to train, outperform feed-forward policies on our evaluation tasks.},
  isbn = {978-3-319-71681-7 978-3-319-71682-4},
  langid = {english},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gupta2017cooperative-Cooperative Multi-agent Control Using Deep Reinforcement Learning.pdf}
}

@inproceedings{gupta2017learning,
  title = {Learning {{Invariant Feature Spaces}} to {{Transfer Skills}} with {{Reinforcement Learning}}},
  booktitle = ICLR,
  author = {Gupta, Abhishek and Devin, Coline and Liu, YuXuan and Abbeel, Pieter and Levine, Sergey},
  year = {2017},
  keywords = {ObsCite},
  annotation = {Learning a common feature space between robots with different morphology or actuation to transfer skills.（通过逼近两状态映射值，产生额外的奖励项引导新技能学习）},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gupta2017learning-Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning.pdf}
}

@article{gupta2021embodied,
  title = {Embodied Intelligence via Learning and Evolution},
  author = {Gupta, Agrim and Savarese, Silvio and Ganguli, Surya and {Fei-Fei}, Li},
  year = {2021},
  month = dec,
  journal = NC,
  volume = {12},
  number = {1},
  pages = {5721},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-25874-z},
  urldate = {2022-02-16},
  langid = {english},
  keywords = {core,embodied intelligence,ObsCite,policy,reinforcement learning},
  annotation = {Nature},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gupta2021embodied-Embodied intelligence via learning and evolution.pdf}
}

@inproceedings{gupta2022metamorph,
  title = {{{MetaMorph}}: {{Learning Universal Controllers}} with {{Transformers}}},
  shorttitle = {{{MetaMorph}}},
  booktitle = ICLR,
  author = {Gupta, Agrim and Fan, Linxi and Ganguli, Surya and {Fei-Fei}, Li},
  year = {2022},
  month = mar,
  publisher = {arXiv},
  urldate = {2022-10-06},
  abstract = {Multiple domains like vision, natural language, and audio are witnessing tremendous progress by leveraging Transformers for large scale pre-training followed by task specific fine tuning. In contrast, in robotics we primarily train a single robot for a single task. However, modular robot systems now allow for the flexible combination of general-purpose building blocks into task optimized morphologies. However, given the exponentially large number of possible robot morphologies, training a controller for each new design is impractical. In this work, we propose MetaMorph, a Transformer based approach to learn a universal controller over a modular robot design space. MetaMorph is based on the insight that robot morphology is just another modality on which we can condition the output of a Transformer. Through extensive experiments we demonstrate that large scale pretraining on a variety of robot morphologies results in policies with combinatorial generalization capabilities, including zero shot generalization to unseen robot morphologies. We further demonstrate that our pre-trained policy can be used for sample-efficient transfer to completely new robot morphologies and tasks.},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Robotics,core,ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gupta2022metamorph-MetaMorph - Learning Universal Controllers with Transformers.pdf}
}

@inproceedings{gupta2024goalnet,
  title = {{{GOALNET}}: {{Interleaving Neural Goal Predicate Inference}} with {{Classical Planning}} for {{Generalization}} in {{Robot Instruction Following}}},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Gupta, Jigyasa and Sharma, Shreya and Tuli, Shreshth and Paul, Rohan and others},
  year = {2024},
  volume = {38},
  pages = {20113--20122},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gupta2024goalnet-GOALNET - Interleaving Neural Goal Predicate Inference with Classical Planning.pdf}
}

@article{gur2023realworld,
  title = {A Real-World Webagent with Planning, Long Context Understanding, and Program Synthesis},
  author = {Gur, Izzeddin and Furuta, Hiroki and Huang, Austin and Safdari, Mustafa and Matsuo, Yutaka and Eck, Douglas and Faust, Aleksandra},
  year = {2023},
  journal = {arXiv preprint arXiv:2307.12856},
  eprint = {2307.12856},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gur2023realworld-A real-world webagent with planning, long context understanding, and program.pdf}
}

@inproceedings{gurtler2023benchmarking,
  title = {Benchmarking Offline Reinforcement Learning on Real-Robot Hardware},
  booktitle = ICLR,
  author = {G{\"u}rtler, Nico and Blaes, Sebastian and Kolev, Pavel and Widmaier, Felix and W{\"u}thrich, Manuel and Bauer, Stefan and Sch{\"o}lkopf, Bernhard and Martius, Georg},
  year = {2023}
}

@inproceedings{gutierrez2021meta,
  title = {Meta {{Reinforcement Learning}} for {{Heuristic Planing}}},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}}},
  author = {Gutierrez, Ricardo Luna and Leonetti, Matteo},
  year = {2021},
  volume = {31},
  pages = {551--559},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@gutierrez2021meta-Meta Reinforcement Learning for Heuristic Planing.pdf}
}

@inproceedings{ha2017joint,
  title = {{Joint optimization of robot design and motion parameters using the implicit function theorem}},
  booktitle = RSS,
  author = {Ha, Sehoon and Coros, Stelian and Alspach, Alexander and Kim, Joohyung and Yamane, Katsu},
  editor = {Srinivasa, Siddhartha and Ayanian, Nora and Amato, Nancy and Kuindersma, Scott},
  year = {2017},
  month = jan,
  series = {{Robotics: Science and Systems}},
  publisher = {MIT Press Journals},
  address = {United States},
  doi = {10.15607/rss.2017.xiii.003},
  abstract = {We present a novel computational approach to optimizing the morphological design of robots. Our framework takes as input a parameterized robot design and a motion plan consisting of trajectories for end-effectors, as well as optionally, for its body. The algorithm we propose is used to optimize design parameters, namely link lengths and the placement of actuators, while concurrently adjusting motion parameters such as joint trajectories, actuator inputs, and contact forces. Our key insight is that the complex relationship between design and motion parameters can be established via sensitivity analysis if the robot's movements are modeled as spatio-temporal solutions to optimal control problems. This relationship between form and function allows us to automatically optimize robot designs based on specifications expressed as a function of range of motion or actuator forces. We evaluate our model by computationally optimizing two simulated robots that employ linear actuators: a manipulator and a large quadruped. We further validate our framework by optimizing the design of a small quadrupedal robot and testing its performance using a hardware implementation.},
  langid = {English (US)},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ha2017joint-Joint optimization of robot design and motion parameters using the implicit.pdf}
}

@article{ha2019reinforcement,
  title = {Reinforcement {{Learning}} for {{Improving Agent Design}}},
  author = {Ha, David},
  year = {2019},
  month = nov,
  journal = {Artificial Life},
  volume = {25},
  number = {4},
  pages = {352--365},
  issn = {1064-5462},
  doi = {10.1162/artl_a_00301},
  urldate = {2022-08-09},
  abstract = {In many reinforcement learning tasks, the goal is to learn a policy to manipulate an agent, whose design is fixed, to maximize some notion of cumulative reward. The design of the agent's physical structure is rarely optimized for the task at hand. In this work, we explore the possibility of learning a version of the agent's design that is better suited for its task, jointly with the policy. We propose an alteration to the popular OpenAI Gym framework, where we parameterize parts of an environment, and allow an agent to jointly learn to modify these environment parameters along with its policy. We demonstrate that an agent can learn a better structure of its body that is not only better suited for the task, but also facilitates policy learning. Joint learning of policy and structure may even uncover design principles that are useful for assisted-design applications.}
}

@inproceedings{ha2023scaling,
  title = {Scaling {{Up}} and {{Distilling Down}}: {{Language-Guided Robot Skill Acquisition}}},
  booktitle = {Proceedings of {{The}} 7th {{Conference}} on {{Robot Learning}}},
  author = {Ha, Huy and Florence, Pete and Song, Shuran},
  editor = {Tan, Jie and Toussaint, Marc and Darvish, Kourosh},
  year = {2023},
  month = nov,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {229},
  pages = {3766--3777},
  publisher = {PMLR},
  abstract = {We present a framework for robot skill acquisition, which 1) efficiently scale up data generation of language-labelled robot data and 2) effectively distills this data down into a robust multi-task language-conditioned visuo-motor policy. For (1), we use a large language model (LLM) to guide high-level planning, and sampling-based robot planners (e.g. motion or grasp samplers) for generating diverse and rich manipulation trajectories. To robustify this data-collection process, the LLM also infers a code-snippet for the success condition of each task, simultaneously enabling the data-collection process to detect failure and retry as well as the automatic labeling of trajectories with success/failure. For (2), we extend the diffusion policy single-task behavior-cloning approach to multi-task settings with language conditioning. Finally, we propose a new multi-task benchmark with 18 tasks across five domains to test long-horizon behavior, common-sense reasoning, tool-use, and intuitive physics. We find that our distilled policy successfully learned the robust retrying behavior in its data collection procedure, while improving absolute success rates by 33.2\% on average across five domains. Code, data, and additional qualitative results are available on https://www.cs.columbia.edu/\&nbsp;huy/scalingup/.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ha2023scaling-Scaling Up and Distilling Down - Language-Guided Robot Skill Acquisition.pdf}
}

@inproceedings{haarnoja2018soft,
  title = {Soft {{Actor-Critic}}: {{Off-Policy Maximum Entropy Deep Reinforcement Learning}} with a {{Stochastic Actor}}},
  shorttitle = {Soft {{Actor-Critic}}},
  booktitle = ICML,
  author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  year = {2018},
  month = aug,
  number = {arXiv:1801.01290},
  eprint = {1801.01290},
  primaryclass = {cs, stat},
  urldate = {2022-05-25},
  abstract = {Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an offpolicy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@haarnoja2018soft-Soft Actor-Critic - Off-Policy Maximum Entropy Deep Reinforcement Learning with.pdf}
}

@article{hafner2023mastering,
  title = {Mastering Diverse Domains through World Models},
  author = {Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
  year = {2023},
  journal = {arXiv preprint arXiv:2301.04104},
  eprint = {2301.04104},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hafner2023mastering-Mastering diverse domains through world models.pdf}
}

@inproceedings{hambro2022dungeons,
  title = {Dungeons and {{Data}}: {{A Large-Scale NetHack Dataset}}},
  booktitle = NeurIPS,
  author = {Hambro, Eric and Raileanu, Roberta and Rothermel, Danielle and Mella, Vegard and Rockt{\"a}schel, Tim and Kuttler, Heinrich and Murray, Naila},
  year = {2022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hambro2022dungeons-Dungeons and Data - A Large-Scale NetHack Dataset.pdf}
}

@inproceedings{hammond2023large,
  title = {Large {{Language Models Need Symbolic AI}}.},
  booktitle = {{{NeSy}}},
  author = {Hammond, Kristian J and Leake, David B},
  year = {2023},
  pages = {204--209},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hammond2023large-Large Language Models Need Symbolic AI.pdf}
}

@article{han2022folio,
  title = {Folio: {{Natural}} Language Reasoning with First-Order Logic},
  author = {Han, Simeng and Schoelkopf, Hailey and Zhao, Yilun and Qi, Zhenting and Riddell, Martin and Benson, Luke and Sun, Lucy and Zubova, Ekaterina and Qiao, Yujie and Burtell, Matthew and others},
  year = {2022},
  journal = {arXiv preprint arXiv:2209.00840},
  eprint = {2209.00840},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@han2022folio-Folio - Natural language reasoning with first-order logic.pdf}
}

@inproceedings{handelman2023multiagent,
  title = {Multi-Agent Playbook for Human-Robot Teaming},
  booktitle = {Artificial {{Intelligence}} and {{Machine Learning}} for {{Multi-Domain Operations Applications V}}},
  author = {Handelman, David A and Holmes, Emma A and Badger, Andrew R and Rivera, Corban G and Rexwinkle, Joe T and Gremillion, Gregory M},
  year = {2023},
  volume = {12538},
  pages = {123--135},
  publisher = {SPIE}
}

@article{hanks1996classical,
  title = {Classical {{Planning}} under {{Uncertainty}}},
  author = {Hanks, Steve},
  year = {1996},
  journal = {proceedings ARPI},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hanks1996classical-Classical Planning under Uncertainty.pdf}
}

@article{hao2023reasoning,
  title = {Reasoning with Language Model Is Planning with World Model},
  author = {Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.14992},
  eprint = {2305.14992},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hao2023reasoning-Reasoning with language model is planning with world model.pdf}
}

@misc{hao2023reasoninga,
  title = {Reasoning with {{Language Model}} Is {{Planning}} with {{World Model}}},
  author = {Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting},
  year = {2023},
  month = oct,
  number = {arXiv:2305.14992},
  eprint = {2305.14992},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-09-19},
  abstract = {Large language models (LLMs) have shown remarkable reasoning capabilities, especially when prompted to generate intermediate reasoning steps (e.g., Chain-of-Thought, CoT). However, LLMs can still struggle with problems that are easy for humans, such as generating action plans for executing tasks in a given environment, or performing complex math, logical, and commonsense reasoning. The deficiency stems from the key fact that LLMs lack an internal \${\textbackslash}textit\{world model\}\$ to predict the world \${\textbackslash}textit\{state\}\$ (e.g., environment status, intermediate variable values) and simulate long-term outcomes of actions. This prevents LLMs from performing deliberate planning akin to human brains, which involves exploring alternative reasoning paths, anticipating future states and rewards, and iteratively refining existing reasoning steps. To overcome the limitations, we propose a new LLM reasoning framework, \${\textbackslash}underline\{R\}\$easoning vi\${\textbackslash}underline\{a\}\$ \${\textbackslash}underline\{P\}\$lanning \${\textbackslash}textbf\{(RAP)\}\$. RAP repurposes the LLM as both a world model and a reasoning agent, and incorporates a principled planning algorithm (based on Monto Carlo Tree Search) for strategic exploration in the vast reasoning space. During reasoning, the LLM (as agent) incrementally builds a reasoning tree under the guidance of the LLM (as world model) and task-specific rewards, and obtains a high-reward reasoning path efficiently with a proper balance between exploration \${\textbackslash}textit\{vs.\}\$ exploitation. We apply RAP to a variety of challenging reasoning problems including plan generation, math reasoning, and logical inference. Empirical results on these tasks demonstrate the superiority of RAP over various strong baselines, including CoT and least-to-most prompting with self-consistency. RAP on LLAMA-33B surpasses CoT on GPT-4 with 33\% relative improvement in a plan generation setting.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hao2023reasoninga-Reasoning with Language Model is Planning with World Model.pdf}
}

@book{hara2003morphofunctional,
  title = {Morpho-Functional {{Machines}}: {{The New Species}}},
  shorttitle = {Morpho-Functional {{Machines}}},
  editor = {Hara, Fumio and Pfeifer, Rolf},
  year = {2003},
  publisher = {Springer Japan},
  address = {Tokyo},
  urldate = {2022-05-06},
  isbn = {978-4-431-68006-2 978-4-431-67869-4},
  langid = {english},
  keywords = {ObsCite},
  file = {C:\Users\lenovo\Zotero\storage\4S6YIXQG\Hara_Pfeifer_2003_Morpho-functional Machines.pdf}
}

@inproceedings{haresh2024clevrskills,
  title = {{{ClevrSkills}}: {{Compositional Language And Visual Reasoning}} in {{Robotics}}},
  booktitle = NeurIPS,
  author = {Haresh, Sanjay and Dijkman, Daniel and Bhattacharyya, Apratim and Memisevic, Roland},
  year = {2024},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@haresh2024clevrskills-ClevrSkills - Compositional Language And Visual Reasoning in Robotics.pdf}
}

@article{hart2021artificial,
  title = {Artificial Evolution of Robot Bodies and Control: On the Interaction between Evolution, Individual and Cultural Learning},
  author = {Hart, Emma and Goff, L{\'e}ni K Le},
  year = {2021},
  journal = {Phil. Trans. Roy. Soc. B},
  pages = {13},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hart2021artificial-Artificial evolution of robot bodies and control - on the interaction between.pdf}
}

@article{harvey1997evolutionary,
  title = {Evolutionary Robotics: The {{Sussex}} Approach},
  author = {Harvey, Inman and Husbands, Phil and Cliff, Dave and Thompson, Adrian and Jakobi, Nick},
  year = {1997},
  journal = {Robotics and Autonomous Systems},
  volume = {20},
  number = {2-4},
  pages = {205--224},
  publisher = {Elsevier},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@harvey1997evolutionary-Evolutionary robotics - the Sussex approach.pdf}
}

@article{hasanbeig2024symbolic,
  title = {Symbolic Task Inference in Deep Reinforcement Learning},
  author = {Hasanbeig, Hosein and Jeppu, Natasha Yogananda and Abate, Alessandro and Melham, Tom and Kroening, Daniel},
  year = {2024},
  journal = {Journal of Artificial Intelligence Research},
  volume = {80},
  pages = {1099--1137},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hasanbeig2024symbolic-Symbolic task inference in deep reinforcement learning.pdf}
}

@misc{haslum2019introduction,
  title = {An Introduction to the Planning Domain Definition Language},
  author = {Haslum, Patrik and Lipovetzky, Nir and Magazzeni, Daniele and Muise, Christian},
  year = {2019},
  journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
  volume = {13},
  number = {2},
  pages = {1--187},
  publisher = {Morgan \& Claypool Publishers},
  abstract = {Planning is the branch of Artificial Intelligence (AI) that seeks to automate reasoning about plans, most importantly the reasoning that goes into formulating a plan to achieve a given goal in a given situation. AI planning is model-based: a planning system takes as input a description (or model) of the initial situation, the actions available to change it, and the goal condition to output a plan composed of those actions that will accomplish the goal when executed from the initial situation. {\textbackslash}n The Planning Domain Definition Language (PDDL) is a formal knowledge representation language designed to express planning models. Developed by the planning research community as a means of facilitating systems comparison, it has become a de-facto standard input language of many planning systems, although it is not the only modelling language for planning. Several variants of PDDL have emerged that capture planning problems of different natures and complexities, with a focus on deterministic problems. {\textbackslash}n The purpose of this book is two-fold. First, we present a unified and current account of PDDL, covering the subsets of PDDL that express discrete, numeric, temporal, and hybrid planning. Second, we want to introduce readers to the art of modelling planning problems in this language, through educational examples that demonstrate how PDDL is used to model realistic planning problems. The book is intended for advanced students and researchers in AI who want to dive into the mechanics of AI planning, as well as those who want to be able to use AI planning systems without an in-depth explanation of the algorithms and implementation techniques they use. {\textbackslash}n Table of Contents: Praise for *An Introduction to the Planning Domain Definition Language / Preface / Introduction / Discrete and Deterministic Planning / More Expressive Classical Planning / Numeric Planning / Temporal Planning / Planning with Hybrid Systems / Conclusion / Bibliography / Authors' Biographies / Index*},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@haslum2019introduction-An introduction to the planning domain definition language.pdf}
}

@article{hauser2011theoretical,
  title = {Towards a Theoretical Foundation for Morphological Computation with Compliant Bodies},
  author = {Hauser, Helmut and Ijspeert, Auke J and F{\"u}chslin, Rudolf M and Pfeifer, Rolf and Maass, Wolfgang},
  year = {2011},
  journal = {Biological cybernetics},
  volume = {105},
  number = {5},
  pages = {355--370},
  publisher = {Springer}
}

@article{hauser2012role,
  title = {The Role of Feedback in Morphological Computation with Compliant Bodies},
  author = {Hauser, Helmut and Ijspeert, Auke J and F{\"u}chslin, Rudolf M and Pfeifer, Rolf and Maass, Wolfgang},
  year = {2012},
  journal = {Biological cybernetics},
  volume = {106},
  number = {10},
  pages = {595--613},
  publisher = {Springer}
}

@inproceedings{hazra2023saycanpay,
  title = {{{SayCanPay}}: {{Heuristic Planning}} with {{Large Language Models}} Using {{Learnable Domain Knowledge}}},
  booktitle = AAAI,
  author = {Hazra, Rishi and Martires, Pedro Zuidberg Dos and De Raedt, Luc},
  year = {2023},
  publisher = {2024},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hazra2023saycanpay-SayCanPay - Heuristic Planning with Large Language Models using Learnable Domain.pdf}
}

@inproceedings{he2010puma,
  title = {{{PUMA}}: {{Planning}} under Uncertainty with Macro-Actions},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {He, Ruijie and Brunskill, Emma and Roy, Nicholas},
  year = {2010},
  volume = {24},
  pages = {1089--1095},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@he2010puma-PUMA - Planning under uncertainty with macro-actions.pdf}
}

@article{heiden2021benchmr,
  title = {Bench-{{MR}}: {{A Motion Planning Benchmark}} for {{Wheeled Mobile Robots}}},
  author = {Heiden, Eric and Palmieri, Luigi and Bruns, Leonard and Arras, Kai O. and Sukhatme, Gaurav S. and Koenig, Sven},
  year = {2021},
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {3},
  pages = {4536--4543},
  doi = {10.1109/LRA.2021.3068913},
  keywords = {Benchmark testing,Collision avoidance,Mobile robots,Navigation,Nonholonomic motion planning,Open source software,Planning,Robot kinematics,software tools for benchmarking and reproducibility,wheeled robots}
}

@inproceedings{hejna2020hierarchically,
  title = {Hierarchically {{Decoupled Imitation For Morphological Transfer}}},
  booktitle = ICML,
  author = {Hejna, Donald and Pinto, Lerrel and Abbeel, Pieter},
  editor = {III, Hal Daum{\'e} and Singh, Aarti},
  year = {2020},
  month = jul,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {119},
  pages = {4159--4171},
  publisher = {PMLR},
  abstract = {Learning long-range behaviors on complex high-dimensional agents is a fundamental problem in robot learning. For such tasks, we argue that transferring learned information from a morphologically simpler agent can massively improve the sample efficiency of a more complex one. To this end, we propose a hierarchical decoupling of policies into two parts: an independently learned low-level policy and a transferable high-level policy. To remedy poor transfer performance due to mismatch in morphologies, we contribute two key ideas. First, we show that incentivizing a complex agent's low-level to imitate a simpler agent's low-level significantly improves zero-shot high-level transfer. Second, we show that KL-regularized training of the high level stabilizes learning and prevents mode-collapse. Finally, on a suite of publicly released navigation and manipulation environments, we demonstrate the applicability of hierarchical transfer on long-range tasks across morphologies. Our code and videos can be found at https://sites.google.com/berkeley.edu/morphology-transfer.},
  keywords = {ObsCite},
  annotation = {介绍了独立的低层控制策略和可形态间迁移的高层策略，其中低层策略的行为直接定义为高层状态序列，以解决动作维度不同的问题。},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hejna2020hierarchically-Hierarchically Decoupled Imitation For Morphological Transfer.pdf}
}

@article{helmert2006fast,
  title = {The Fast Downward Planning System},
  author = {Helmert, Malte},
  year = {2006},
  journal = {Journal of Artificial Intelligence Research},
  volume = {26},
  pages = {191--246},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@helmert2006fast-The fast downward planning system.pdf}
}

@article{heppner2024behavior,
  title = {Behavior {{Tree Capabilities}} for {{Dynamic Multi-Robot Task Allocation}} with {{Heterogeneous Robot Teams}}},
  author = {Heppner, Georg and Oberacker, David and Roennau, Arne and Dillmann, R{\"u}diger},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.02833},
  eprint = {2402.02833},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@heppner2024behavior-Behavior Tree Capabilities for Dynamic Multi-Robot Task Allocation with.pdf}
}

@inproceedings{heppnerl2023distributed,
  title = {Distributed {{Behavior Trees}} for {{Heterogeneous Robot Teams}}},
  booktitle = {2023 {{IEEE}} 19th {{International Conference}} on {{Automation Science}} and {{Engineering}} ({{CASE}})},
  author = {Heppnerl, Georg and Berg, Nils and Oberacker, David and Spielbauer, Niklas and Roennau, Arne and Dillmann, R{\"u}diger},
  year = {2023},
  pages = {1--8},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@heppnerl2023distributed-Distributed Behavior Trees for Heterogeneous Robot Teams.pdf}
}

@article{hiller2011automatic,
  title = {Automatic Design and Manufacture of Soft Robots},
  author = {Hiller, Jonathan and Lipson, Hod},
  year = {2011},
  journal = {IEEE Transactions on Robotics},
  volume = {28},
  number = {2},
  pages = {457--466},
  publisher = {IEEE}
}

@article{hinton2022forwardforward,
  title = {The Forward-Forward Algorithm: {{Some}} Preliminary Investigations},
  author = {Hinton, Geoffrey},
  year = {2022},
  journal = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hinton2022forwardforward-The forward-forward algorithm - Some preliminary investigations.pdf}
}

@book{hodel2013introduction,
  title = {An Introduction to Mathematical Logic},
  author = {Hodel, Richard E},
  year = {2013},
  publisher = {Courier Corporation},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hodel2013introduction-An introduction to mathematical logic.pdf}
}

@article{hoffmann2001ff,
  title = {The {{FF}} Planning System: {{Fast}} Plan Generation through Heuristic Search},
  author = {Hoffmann, J{\"o}rg and Nebel, Bernhard},
  year = {2001},
  journal = {Journal of Artificial Intelligence Research},
  volume = {14},
  pages = {253--302},
  abstract = {We describe and evaluate the algorithmic techniques that are used in the FF planning system. Like the HSP system, FF relies on forward state space search, using a heuristic that estimates goal distances by ignoring delete lists. Unlike HSP's heuristic, our method does not assume facts to be independent. We introduce a novel search strategy that combines hill-climbing with systematic search, and we show how other powerful heuristic information can be extracted and used to prune the search space. FF was the most successful automatic planner at the recent AIPS-2000 planning competition. We review the results of the competition, give data for other benchmark domains, and investigate the reasons for the runtime performance of FF compared to HSP.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hoffmann2001ff-The FF planning system - Fast plan generation through heuristic search.pdf}
}

@article{hoffmann2004ordered,
  title = {Ordered Landmarks in Planning},
  author = {Hoffmann, J{\"o}rg and Porteous, Julie and Sebastia, Laura},
  year = {2004},
  journal = {Journal of Artificial Intelligence Research},
  volume = {22},
  pages = {215--278},
  abstract = {Many known planning tasks have inherent constraints concerning the best order in which to achieve the goals. A number of research efforts have been made to detect such constraints and to use them for guiding search, in the hope of speeding up the planning process. We go beyond the previous approaches by considering ordering constraints not only over the (top-level) goals, but also over the sub-goals that will necessarily arise during planning. Landmarks are facts that must be true at some point in every valid solution plan. We extend Koehler and Hoffmann's definition of reasonable orders between top level goals to the more general case of landmarks. We show how landmarks can be found, how their reasonable orders can be approximated, and how this information can be used to decompose a given planning task into several smaller sub-tasks. Our methodology is completely domain- and planner-independent. The implementation demonstrates that the approach can yield significant runtime performance improvements when used as a control loop around state-of-the-art sub-optimal planning systems, as exemplified by FF and LPG.}
}

@article{hoffmann2006conformant,
  title = {Conformant Planning via Heuristic Forward Search: {{A}} New Approach},
  author = {Hoffmann, J{\"o}rg and Brafman, Ronen I},
  year = {2006},
  journal = {Artificial Intelligence},
  volume = {170},
  number = {6-7},
  pages = {507--541},
  publisher = {Elsevier},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hoffmann2006conformant-Conformant planning via heuristic forward search - A new approach.pdf}
}

@article{holden2017phasefunctioned,
  title = {Phase-Functioned Neural Networks for Character Control},
  author = {Holden, Daniel and Komura, Taku and Saito, Jun},
  year = {2017},
  month = jul,
  journal = TOG,
  volume = {36},
  number = {4},
  pages = {1--13},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3072959.3073663},
  urldate = {2022-02-28},
  langid = {english},
  keywords = {neural network},
  annotation = {TOG},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@holden2017phasefunctioned-Phase-functioned neural networks for character control.pdf}
}

@article{honerkamp2021learning,
  title = {Learning {{Kinematic Feasibility}} for {{Mobile Manipulation Through Deep Reinforcement Learning}}},
  author = {Honerkamp, Daniel and Welschehold, Tim and Valada, Abhinav},
  year = {2021},
  month = oct,
  journal = RA-L,
  volume = {6},
  number = {4},
  pages = {6289--6296},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3092685},
  abstract = {Mobile manipulation tasks remain one of the critical challenges for the widespread adoption of autonomous robots in both service and industrial scenarios. While planning approaches are good at generating feasible whole-body robot trajectories, they struggle with dynamic environments as well as the incorporation of constraints given by the task and the environment. On the other hand, dynamic motion models in the action space struggle with generating kinematically feasible trajectories for mobile manipulation actions. We propose a deep reinforcement learning approach to learn feasible dynamic motions for a mobile base while the end-effector follows a trajectory in task space generated by an arbitrary system to fulfill the task at hand. This modular formulation has several benefits: it enables us to readily transform a broad range of end-effector motions into mobile applications, it allows us to use the kinematic feasibility of the end-effector trajectory as a dense reward signal and its modular formulation allows it to generalise to unseen end-effector motions at test time. We demonstrate the capabilities of our approach on multiple mobile robot platforms with different kinematic abilities and different types of wheeled platforms in extensive simulated as well as real-world experiments.},
  keywords = {Collision avoidance,End effectors,Kinematics,Mobile manipulation,Planning,reinforcement learning,Robots,Task analysis,Trajectory},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@honerkamp2021learning-Learning Kinematic Feasibility for Mobile Manipulation Through Deep.pdf}
}

@inproceedings{hong2021structureaware,
  title = {Structure-Aware Transformer Policy for Inhomogeneous Multi-Task Reinforcement Learning},
  booktitle = ICLR,
  author = {Hong, Sunghoon and Yoon, Deunsol and Kim, Kee-Eung},
  year = {2021},
  keywords = {ObsCite},
  annotation = {We present a modular Multi-task Reinforcement Learning method for inhomogeneous control tasks incorporating structural embedding of morphology.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hong2021structureaware-Structure-aware transformer policy for inhomogeneous multi-task reinforcement.pdf}
}

@article{howard2019evolving,
  title = {Evolving Embodied Intelligence from Materials to Machines},
  author = {Howard, David and Eiben, Agoston E. and Kennedy, Danielle Frances and Mouret, Jean-Baptiste and Valencia, Philip and Winkler, Dave},
  year = {2019},
  month = jan,
  journal = NMI,
  volume = {1},
  number = {1},
  pages = {12--19},
  issn = {2522-5839},
  doi = {10.1038/s42256-018-0009-9},
  abstract = {Natural lifeforms specialize to their environmental niches across many levels, from low-level features such as DNA and proteins, through to higher-level artefacts including eyes, limbs and overarching body plans. We propose `multi-level evolution', a bottom-up automatic process that designs robots across multiple levels and niches them to tasks and environmental conditions. Multi-level evolution concurrently explores constituent molecular and material building blocks, as well as their possible assemblies into specialized morphological and sensorimotor configurations. Multi-level evolution provides a route to fully harness a recent explosion in available candidate materials and ongoing advances in rapid manufacturing processes. We outline a feasible architecture that realizes this vision, highlight the main roadblocks and how they may be overcome, and show robotic applications to which multi-level evolution is particularly suited. By forming a research agenda to stimulate discussion between researchers in related fields, we hope to inspire the pursuit of multi-level robotic design all the way from material to machine.},
  keywords = {evolutionary,ObsCite,TBD},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@howard2019evolving-Evolving embodied intelligence from materials to machines.pdf}
}

@inproceedings{howe2022myriad,
  title = {Myriad: A Real-World Testbed to Bridge Trajectory Optimization and Deep Learning},
  booktitle = NeurIPS,
  author = {Howe, Nikolaus H. R. and {Dufort-Labb{\'e}}, Simon and Rajkumar, Nitarshan and Bacon, Pierre-Luc},
  year = {2022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@howe2022myriad-Myriad - a real-world testbed to bridge trajectory optimization and deep learning.pdf}
}

@inproceedings{hsu2023ns3d,
  title = {{{NS3D}}: {{Neuro-Symbolic Grounding}} of {{3D Objects}} and {{Relations}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Hsu, Joy and Mao, Jiayuan and Wu, Jiajun},
  year = {2023},
  month = jun,
  pages = {2614--2623},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hsu2023ns3d-NS3D - Neuro-Symbolic Grounding of 3D Objects and Relations.pdf}
}

@inproceedings{hsu2023whats,
  title = {What's Left? Concept Grounding with Logic-Enhanced Foundation Models},
  booktitle = NeurIPS,
  author = {Hsu, Joy and Mao, Jiayuan and Tenenbaum, Josh and Wu, Jiajun},
  year = {2023},
  volume = {36},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hsu2024whats-What’s left - concept grounding with logic-enhanced foundation models.pdf}
}

@article{hsu2024spot,
  title = {{{SPOT}}: {{SE}} (3) {{Pose Trajectory Diffusion}} for {{Object-Centric Manipulation}}},
  author = {Hsu, Cheng-Chun and Wen, Bowen and Xu, Jie and Narang, Yashraj and Wang, Xiaolong and Zhu, Yuke and Biswas, Joydeep and Birchfield, Stan},
  year = {2024},
  journal = {arXiv preprint arXiv:2411.00965},
  eprint = {2411.00965},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hsu2024spot-SPOT - SE (3) Pose Trajectory Diffusion for Object-Centric Manipulation.pdf}
}

@inproceedings{hu2015semiautonomous,
  title = {Semi-Autonomous Simulated Brain Tumor Ablation with {{RAVENII Surgical Robot}} Using Behavior Tree},
  booktitle = ICRA,
  author = {Hu, Danying and Gong, Yuanzheng and Hannaford, Blake and Seibel, Eric J.},
  year = {2015},
  pages = {3868--3875},
  doi = {10.1109/ICRA.2015.7139738},
  keywords = {Accuracy,Medical robotics,Solid modeling,Surgery,Three-dimensional displays,Tumors}
}

@article{hu2020decentralized,
  title = {Decentralized Runtime Enforcement for Robotic Swarms},
  author = {Hu, C. and Dong, W. and Yang, Y. H. and Shi, H. and Deng, F.},
  year = {2020},
  journal = {Frontiers of Information Technology \& Electronic Engineering},
  volume = {21},
  number = {11},
  pages = {16}
}

@inproceedings{hu2021neural,
  title = {Neural Fidelity Warping for Efficient Robot Morphology Design},
  booktitle = ICRA,
  author = {Hu, Sha and Yang, Zeshi and Mori, Greg},
  year = {2021},
  pages = {7079--7086},
  publisher = {IEEE},
  doi = {10.1109/ICRA48506.2021.9561733},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hu2021neural-Neural fidelity warping for efficient robot morphology design.pdf}
}

@inproceedings{hu2022glso,
  title = {{{GLSO}}: {{Grammar-guided Latent Space Optimization}} for {{Sample-efficient Robot Design Automation}}},
  booktitle = CoRL,
  author = {Hu, Jiaheng and Whitman, Julian and Choset, Howie},
  year = {2022},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hu2022glso-GLSO - Grammar-guided Latent Space Optimization for Sample-efficient Robot.pdf}
}

@article{hu2023treeplanner,
  title = {Tree-Planner: {{Efficient}} Close-Loop Task Planning with Large Language Models},
  author = {Hu, Mengkang and Mu, Yao and Yu, Xinmiao and Ding, Mingyu and Wu, Shiguang and Shao, Wenqi and Chen, Qiguang and Wang, Bin and Qiao, Yu and Luo, Ping},
  year = {2023},
  journal = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hu2023treeplanner-Tree-planner - Efficient close-loop task planning with large language models.pdf}
}

@article{hua2021learning,
  title = {Learning for a {{Robot}}: {{Deep Reinforcement Learning}}, {{Imitation Learning}}, {{Transfer Learning}}},
  author = {Hua, Jiang and Zeng, Liangcai and Li, Gongfa and Ju, Zhaojie},
  year = {2021},
  journal = {Sensors},
  volume = {21},
  number = {4},
  issn = {1424-8220},
  doi = {10.3390/s21041278},
  abstract = {Dexterous manipulation of the robot is an important part of realizing intelligence, but manipulators can only perform simple tasks such as sorting and packing in a structured environment. In view of the existing problem, this paper presents a state-of-the-art survey on an intelligent robot with the capability of autonomous deciding and learning. The paper first reviews the main achievements and research of the robot, which were mainly based on the breakthrough of automatic control and hardware in mechanics. With the evolution of artificial intelligence, many pieces of research have made further progresses in adaptive and robust control. The survey reveals that the latest research in deep learning and reinforcement learning has paved the way for highly complex tasks to be performed by robots. Furthermore, deep reinforcement learning, imitation learning, and transfer learning in robot control are discussed in detail. Finally, major achievements based on these methods are summarized and analyzed thoroughly, and future research challenges are proposed.},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@hua2021learning-Learning for a Robot - Deep Reinforcement Learning, Imitation Learning, Transfer.pdf}
}

@inproceedings{huang2020cen,
  title = {{{CEN}}: {{Concept}} Evolution Network for Image Classification Tasks},
  booktitle = {Proceedings of the 2020 2nd International Conference on Robotics, Intelligent Control and Artificial Intelligence},
  author = {Huang, Da and Chen, Xinglin},
  year = {2020},
  series = {{{RICAI}} 2020},
  pages = {192--199},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3438872.3439080},
  abstract = {Image classification is a challenging but fundamental task for many computer vision applications, such as self-driving, face recognition, and object tracking. The deep neural network (DNN) is a modern, powerful model to tackle this task, whose representation ability mainly comes from hidden layers. The interpretability of DNN, however, drops rapidly as the inexplicable hidden part becomes deeper and deeper. To make neural networks more explainable, we propose a novel neural network named concept evolution network (CEN), learning explicit concepts of images to help classify. Concepts evolve during training with three stages: emergence, elevation, and elimination. We design three algorithms (one primary and two improved) to train CEN. The experiment results on MNIST show our methods' feasibility and that CEN has both interpretability and adaptive learning capacity for the image classification task. In the last section, we discuss the development prospects of CEN in the future.},
  isbn = {978-1-4503-8830-6},
  annotation = {RICAI}
}

@inproceedings{huang2020one,
  title = {One Policy to Control Them All: {{Shared}} Modular Policies for Agent-Agnostic Control},
  booktitle = ICML,
  author = {Huang, Wenlong and Mordatch, Igor and Pathak, Deepak},
  year = {2020},
  pages = {4455--4464},
  keywords = {core,ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@huang2020one-One policy to control them all - Shared modular policies for agent-agnostic.pdf}
}

@inproceedings{huang2022adarl,
  title = {{{AdaRL}}: {{What}}, {{Where}}, and {{How}} to {{Adapt}} in {{Transfer Reinforcement Learning}}},
  booktitle = ICLR,
  author = {Huang, Biwei and Feng, Fan and Lu, Chaochao and Magliacane, Sara and Zhang, Kun},
  year = {2022},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@huang2022adarl-AdaRL - What, Where, and How to Adapt in Transfer Reinforcement Learning.pdf}
}

@article{huang2022inner,
  title = {Inner Monologue: {{Embodied}} Reasoning through Planning with Language Models},
  author = {Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  year = {2022},
  journal = {arXiv preprint arXiv:2207.05608},
  eprint = {2207.05608},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@huang2022inner-Inner monologue - Embodied reasoning through planning with language models.pdf}
}

@inproceedings{huang2022language,
  title = {Language {{Models}} as {{Zero-Shot Planners}}: {{Extracting Actionable Knowledge}} for {{Embodied Agents}}},
  booktitle = {Proceedings of the 39th {{International Conference}} on {{Machine Learning}}},
  author = {Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  year = {2022},
  month = jul,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {162},
  pages = {9118--9147},
  publisher = {PMLR},
  abstract = {Can world knowledge learned by large language models (LLMs) be used to act in interactive environments? In this paper, we investigate the possibility of grounding high-level tasks, expressed in natural language (e.g. ``make breakfast''), to a chosen set of actionable steps (e.g. ``open fridge''). While prior work focused on learning from explicit step-by-step examples of how to act, we surprisingly find that if pre-trained LMs are large enough and prompted appropriately, they can effectively decompose high-level tasks into mid-level plans without any further training. However, the plans produced naively by LLMs often cannot map precisely to admissible actions. We propose a procedure that conditions on existing demonstrations and semantically translates the plans to admissible actions. Our evaluation in the recent VirtualHome environment shows that the resulting method substantially improves executability over the LLM baseline. The conducted human evaluation reveals a trade-off between executability and correctness but shows a promising sign towards extracting actionable knowledge from language models.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@huang2022language-Language Models as Zero-Shot Planners - Extracting Actionable Knowledge for.pdf}
}

@inproceedings{huang2023skill,
  title = {Skill {{Transformer}}: {{A Monolithic Policy}} for {{Mobile Manipulation}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Huang, Xiaoyu and Batra, Dhruv and Rai, Akshara and Szot, Andrew},
  year = {2023},
  month = oct,
  pages = {10852--10862},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@huang2023skill-Skill Transformer - A Monolithic Policy for Mobile Manipulation.pdf}
}

@article{huang2023voxposer,
  title = {Voxposer: {{Composable}} 3d Value Maps for Robotic Manipulation with Language Models},
  author = {Huang, Wenlong and Wang, Chen and Zhang, Ruohan and Li, Yunzhu and Wu, Jiajun and {Fei-Fei}, Li},
  year = {2023},
  journal = {arXiv preprint arXiv:2307.05973},
  eprint = {2307.05973},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@huang2023voxposer-Voxposer - Composable 3d value maps for robotic manipulation with language models.pdf}
}

@article{huang2024copa,
  title = {Copa: {{General}} Robotic Manipulation through Spatial Constraints of Parts with Foundation Models},
  author = {Huang, Haoxu and Lin, Fanqi and Hu, Yingdong and Wang, Shengjie and Gao, Yang},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.08248},
  eprint = {2403.08248},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@huang2024copa-Copa - General robotic manipulation through spatial constraints of parts with.pdf}
}

@article{huang2024rekep,
  title = {Rekep: {{Spatio-temporal}} Reasoning of Relational Keypoint Constraints for Robotic Manipulation},
  author = {Huang, Wenlong and Wang, Chen and Li, Yunzhu and Zhang, Ruohan and {Fei-Fei}, Li},
  year = {2024},
  journal = {arXiv preprint arXiv:2409.01652},
  eprint = {2409.01652},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@huang2024rekep-Rekep - Spatio-temporal reasoning of relational keypoint constraints for robotic.pdf}
}

@article{huang2024understanding,
  title = {Understanding the Planning of {{LLM}} Agents: {{A}} Survey},
  author = {Huang, Xu and Liu, Weiwen and Chen, Xiaolong and Wang, Xingmei and Wang, Hao and Lian, Defu and Wang, Yasheng and Tang, Ruiming and Chen, Enhong},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.02716},
  eprint = {2402.02716},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@huang2024understanding-Understanding the planning of LLM agents - A survey.pdf}
}

@inproceedings{hubert2021learning,
  title = {Learning and {{Planning}} in {{Complex Action Spaces}}},
  booktitle = ICML,
  author = {Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Barekatain, Mohammadamin and Schmitt, Simon and Silver, David},
  editor = {Meila, Marina and Zhang, Tong},
  year = {2021},
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {139},
  pages = {4476--4486},
  publisher = {PMLR},
  keywords = {ObsCite},
  file = {C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@hubert2021learning-Learning and Planning in Complex Action Spaces.pdf;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@hubert2021learning-Learning and Planning in Complex Action Spaces2.pdf}
}

@article{husbands2021recent,
  title = {Recent Advances in Evolutionary and Bio-Inspired Adaptive Robotics: {{Exploiting}} Embodied Dynamics},
  author = {Husbands, Phil and Shim, Yoonsik and Garvie, Michael and Dewar, Alex and Domcsek, Norbert and Graham, Paul and Knight, James and Nowotny, Thomas and Philippides, Andrew},
  year = {2021},
  month = sep,
  journal = {Applied Intelligence},
  volume = {51},
  number = {9},
  pages = {6467--6496},
  issn = {1573-7497},
  doi = {10.1007/s10489-021-02275-9},
  abstract = {This paper explores current developments in evolutionary and bio-inspired approaches to autonomous robotics, concentrating on research from our group at the University of Sussex. These developments are discussed in the context of advances in the wider fields of adaptive and evolutionary approaches to AI and robotics, focusing on the exploitation of embodied dynamics to create behaviour. Four case studies highlight various aspects of such exploitation. The first exploits the dynamical properties of a physical electronic substrate, demonstrating for the first time how component-level analog electronic circuits can be evolved directly in hardware to act as robot controllers. The second develops novel, effective and highly parsimonious navigation methods inspired by the way insects exploit the embodied dynamics of innate behaviours. Combining biological experiments with robotic modeling, it is shown how rapid route learning can be achieved with the aid of navigation-specific visual information that is provided and exploited by the innate behaviours. The third study focuses on the exploitation of neuromechanical chaos in the generation of robust motor behaviours. It is demonstrated how chaotic dynamics can be exploited to power a goal-driven search for desired motor behaviours in embodied systems using a particular control architecture based around neural oscillators. The dynamics are shown to be chaotic at all levels in the system, from the neural to the embodied mechanical. The final study explores the exploitation of the dynamics of brain-body-environment interactions for efficient, agile flapping winged flight. It is shown how a multi-objective evolutionary algorithm can be used to evolved dynamical neural controllers for a simulated flapping wing robot with feathered wings. Results demonstrate robust, stable, agile flight is achieved in the face of random wind gusts by exploiting complex asymmetric dynamics partly enabled by continually changing wing and tail morphologies.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@husbands2021recent-Recent advances in evolutionary and bio-inspired adaptive robotics - Exploiting.pdf}
}

@article{ibarz2021how,
  title = {How to Train Your Robot with Deep Reinforcement Learning: Lessons We Have Learned},
  author = {Ibarz, Julian and Tan, Jie and Finn, Chelsea and Kalakrishnan, Mrinal and Pastor, Peter and Levine, Sergey},
  year = {2021},
  journal = {The International Journal of Robotics Research},
  volume = {40},
  number = {4-5},
  pages = {698--721},
  publisher = {SAGE Publications Sage UK: London, England},
  keywords = {ObsCite},
  file = {D:\Cloud\BaiduSyncdisk\CXL_Big\SoftwareData\zotfile\The International Journal of Robotics Research2021_How to train your robot with deep reinforcement learning - lessons we have @ibarz2021how.pdf}
}

@inproceedings{icarte2018using,
  title = {Using Reward Machines for High-Level Task Specification and Decomposition in Reinforcement Learning},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Icarte, Rodrigo Toro and Klassen, Toryn and Valenzano, Richard and McIlraith, Sheila},
  year = {2018},
  pages = {2107--2116},
  publisher = {PMLR},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@icarte2018using-Using reward machines for high-level task specification and decomposition in.pdf}
}

@inproceedings{iii2021taskagnostic,
  title = {Task-Agnostic Morphology Evolution},
  booktitle = ICLR,
  author = {III, Donald Joseph Hejna and Abbeel, Pieter and Pinto, Lerrel},
  year = {2021},
  publisher = {OpenReview.net},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@iii2021taskagnostic-Task-agnostic morphology evolution.pdf}
}

@article{ionescu2023are,
  title = {Are {{TikTok Algorithms Influencing Users}}' {{Self-Perceived Identities}} and {{Personal Values}}? {{A Mini Review}}},
  author = {Ionescu, Claudiu Gabriel and Licu, Monica},
  year = {2023},
  journal = {Social Sciences},
  volume = {12},
  number = {8},
  pages = {465},
  publisher = {MDPI},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ionescu2023are-Are TikTok Algorithms Influencing Users’ Self-Perceived Identities and Personal.pdf}
}

@article{iovino2022survey,
  title = {A Survey of {{Behavior Trees}} in Robotics and {{AI}}},
  author = {Iovino, Matteo and Scukins, Edvards and Styrud, Jonathan and {\"O}gren, Petter and Smith, Christian},
  year = {2022},
  journal = {Robotics and Autonomous Systems},
  volume = {154},
  keywords = {ObsCite},
  annotation = {ArXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@iovino2022survey-A survey of Behavior Trees in robotics and AI.pdf}
}

@inproceedings{iovino2023framework,
  title = {A Framework for Learning Behavior Trees in Collaborative Robotic Applications},
  booktitle = {2023 {{IEEE}} 19th {{International Conference}} on {{Automation Science}} and {{Engineering}} ({{CASE}})},
  author = {Iovino, Matteo and Styrud, Jonathan and Falco, Pietro and Smith, Christian},
  year = {2023},
  pages = {1--8},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@iovino2023framework-A framework for learning behavior trees in collaborative robotic applications.pdf}
}

@inproceedings{iovino2023frameworka,
  title = {A Framework for Learning Behavior Trees in Collaborative Robotic Applications},
  booktitle = {2023 {{IEEE}} 19th {{International Conference}} on {{Automation Science}} and {{Engineering}} ({{CASE}})},
  author = {Iovino, Matteo and Styrud, Jonathan and Falco, Pietro and Smith, Christian},
  year = {2023},
  pages = {1--8},
  publisher = {IEEE}
}

@article{izzo2024btgenbot,
  title = {{{BTGenBot}}: {{Behavior Tree Generation}} for {{Robotic Tasks}} with {{Lightweight LLMs}}},
  author = {Izzo, Riccardo Andrea and Bardaro, Gianluca and Matteucci, Matteo},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.12761},
  eprint = {2403.12761},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@izzo2024btgenbot-BTGenBot - Behavior Tree Generation for Robotic Tasks with Lightweight LLMs.pdf}
}

@inproceedings{jain2019hierarchical,
  title = {Hierarchical {{Reinforcement Learning}} for {{Quadruped Locomotion}}},
  booktitle = IROS,
  author = {Jain, Deepali and Iscen, Atil and Caluwaerts, Ken},
  year = {2019},
  month = nov,
  pages = {7551--7557},
  publisher = {IEEE},
  address = {Macau, China},
  doi = {10.1109/IROS40897.2019.8967913},
  urldate = {2022-02-28},
  isbn = {978-1-72814-004-9},
  langid = {english},
  keywords = {ObsCite},
  annotation = {IROS},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@jain2019hierarchical-Hierarchical Reinforcement Learning for Quadruped Locomotion.pdf}
}

@article{jain2023bring,
  title = {Bring {{Your Own Data}}! {{Self-Supervised Evaluation}} for {{Large Language Models}}},
  author = {Jain, Neel and Saifullah, Khalid and Wen, Yuxin and Kirchenbauer, John and Shu, Manli and Saha, Aniruddha and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
  year = {2023},
  journal = {arXiv preprint arXiv:2306.13651},
  eprint = {2306.13651},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@jain2023bring-Bring Your Own Data! Self-Supervised Evaluation for Large Language Models.pdf}
}

@article{jain2024structsum,
  title = {Structsum {{Generation}} for {{Faster Text Comprehension}}},
  author = {Jain, Parag and Marzoca, Andreea and Piccinno, Francesco},
  year = {2024},
  journal = {arXiv preprint arXiv:2401.06837},
  eprint = {2401.06837},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@jain2024structsum-Structsum Generation for Faster Text Comprehension.pdf}
}

@article{jansen2020visuallygrounded,
  title = {Visually-Grounded Planning without Vision: {{Language}} Models Infer Detailed Plans from High-Level Instructions},
  author = {Jansen, Peter A},
  year = {2020},
  journal = {arXiv preprint arXiv:2009.14259},
  eprint = {2009.14259},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@jansen2020visuallygrounded-Visually-grounded planning without vision - Language models infer detailed plans.pdf}
}

@inproceedings{ji2023safety,
  title = {Safety {{Gymnasium}}: {{A Unified Safe Reinforcement Learning Benchmark}}},
  booktitle = NeurIPS,
  author = {Ji, Jiaming and Zhang, Borong and Zhou, Jiayi and Pan, Xuehai and Huang, Weidong and Sun, Ruiyang and Geng, Yiran and Zhong, Yifan and Dai, Josef and Yang, Yaodong},
  editor = {Oh, A. and Naumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.},
  year = {2023},
  volume = {36},
  pages = {18964--18993},
  publisher = {Curran Associates, Inc.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ji2023safety-Safety Gymnasium - A Unified Safe Reinforcement Learning Benchmark.pdf}
}

@article{ji2024aligner,
  title = {Aligner: {{Achieving}} Efficient Alignment through Weak-to-Strong Correction},
  author = {Ji, Jiaming and Chen, Boyuan and Lou, Hantao and Hong, Donghai and Zhang, Borong and Pan, Xuehai and Dai, Juntao and Yang, Yaodong},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.02416},
  eprint = {2402.02416},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ji2024aligner-Aligner - Achieving efficient alignment through weak-to-strong correction.pdf}
}

@article{jia2024sceneverse,
  title = {Sceneverse: {{Scaling}} 3d Vision-Language Learning for Grounded Scene Understanding},
  author = {Jia, Baoxiong and Chen, Yixin and Yu, Huangyue and Wang, Yan and Niu, Xuesong and Liu, Tengyu and Li, Qing and Huang, Siyuan},
  year = {2024},
  journal = {arXiv preprint arXiv:2401.09340},
  eprint = {2401.09340},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@jia2024sceneverse-Sceneverse - Scaling 3d vision-language learning for grounded scene understanding.pdf}
}

@article{jiang2019task,
  title = {Task Planning in Robotics: An Empirical Comparison of Pddl-and Asp-Based Systems},
  author = {Jiang, Yu-qian and Zhang, Shi-qi and Khandelwal, Piyush and Stone, Peter},
  year = {2019},
  journal = {Frontiers of Information Technology \& Electronic Engineering},
  volume = {20},
  pages = {363--373},
  publisher = {Springer},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@jiang2019task-Task planning in robotics - an empirical comparison of pddl-and asp-based systems.pdf}
}

@article{jiang2022vima,
  title = {Vima: {{General}} Robot Manipulation with Multimodal Prompts},
  author = {Jiang, Yunfan and Gupta, Agrim and Zhang, Zichen and Wang, Guanzhi and Dou, Yongqiang and Chen, Yanjun and {Fei-Fei}, Li and Anandkumar, Anima and Zhu, Yuke and Fan, Linxi},
  year = {2022},
  journal = {arXiv},
  volume = {2210.03094},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@jiang2022vima-Vima - General robot manipulation with multimodal prompts.pdf}
}

@article{jiang2024multimodal,
  title = {Multi-{{Modal}} and {{Multi-Agent Systems Meet Rationality}}: {{A Survey}}},
  author = {Jiang, Bowen and Xie, Yangxinyu and Wang, Xiaomeng and Su, Weijie J and Taylor, Camillo J and Mallick, Tanwi},
  year = {2024},
  journal = {arXiv preprint arXiv:2406.00252},
  eprint = {2406.00252},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@jiang2024multimodal-Multi-Modal and Multi-Agent Systems Meet Rationality - A Survey.pdf}
}

@article{jilani2014automated,
  title = {Automated Knowledge Engineering Tools in Planning: State-of-the-Art and Future Challenges},
  author = {Jilani, Rabia and Crampton, Andrew and Kitchin, Diane E and Vallati, Mauro},
  year = {2014},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@jilani2014automated-Automated knowledge engineering tools in planning - state-of-the-art and future.pdf}
}

@article{jin2020embodied,
  title = {Embodied Intelligence Weaves a Better Future},
  author = {Jin, Dongdong and Zhang, Li},
  year = {2020},
  month = nov,
  journal = NMI,
  volume = {2},
  number = {11},
  pages = {663--664},
  issn = {2522-5839},
  doi = {10.1038/s42256-020-00250-6},
  abstract = {Microrobots can interact intelligently with their environment and complete specific tasks by well-designed incorporation of responsive materials. Recent work demonstrates how swarms of microbots with specifically tuned surface chemistry can remove a hormone pollutant from a solution by coalescing it into a web.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@jin2020embodied-Embodied intelligence weaves a better future.pdf}
}

@inproceedings{jing2020reinforcement,
  title = {Reinforcement Learning from Imperfect Demonstrations under Soft Expert Guidance},
  booktitle = AAAI,
  author = {Jing, Mingxuan and Ma, Xiaojian and Huang, Wenbing and Sun, Fuchun and Yang, Chao and Fang, Bin and Liu, Huaping},
  year = {2020},
  volume = {34},
  pages = {5109--5116},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@jing2020reinforcement-Reinforcement learning from imperfect demonstrations under soft expert guidance.pdf}
}

@book{jingshenbingxue,
  title = {精神病学},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@jingshenbingxue-精神病学.pdf}
}

@book{jiqirenxueheren,
  title = {机器人学和人工智能中的行为树},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@jiqirenxueheren-机器人学和人工智能中的行为树.pdf}
}

@book{jisuanjikexuesh,
  title = {计算机科学数学},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@jisuanjikexuesh-计算机科学数学.pdf}
}

@article{joachimczak2016artificial,
  title = {Artificial Metamorphosis: {{Evolutionary}} Design of Transforming, Soft-Bodied Robots},
  author = {Joachimczak, Micha{\textbackslash}l and Suzuki, Reiji and Arita, Takaya},
  year = {2016},
  journal = {Artificial life},
  volume = {22},
  number = {3},
  pages = {271--298},
  publisher = {MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info {\dots}}
}

@book{johnson20body,
  title = {The Body in the Mind: The Bodily Basis of Meaning, Imagination, and Reason},
  shorttitle = {The Body in the Mind},
  author = {Johnson, Mark},
  year = {20},
  edition = {Paperback ed., [9. print.]},
  publisher = {University of Chicago Press},
  address = {Chicago},
  isbn = {978-0-226-40318-2},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@johnson20body-The body in the mind - the bodily basis of meaning, imagination, and reason.pdf}
}

@article{kaddour2021causal,
  title = {Causal Effect Inference for Structured Treatments},
  author = {Kaddour, Jean and Zhu, Yuchen and Liu, Qi and Kusner, Matt J and Silva, Ricardo},
  year = {2021},
  journal = {Advances in Neural Information Processing Systems},
  volume = {34},
  pages = {24841--24854},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kaddour2021causal-Causal effect inference for structured treatments.pdf}
}

@article{kaddour2022causal,
  title = {Causal Machine Learning: {{A}} Survey and Open Problems},
  author = {Kaddour, Jean and Lynch, Aengus and Liu, Qi and Kusner, Matt J and Silva, Ricardo},
  year = {2022},
  journal = {arXiv preprint arXiv:2206.15475},
  eprint = {2206.15475},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kaddour2022causal-Causal machine learning - A survey and open problems.pdf}
}

@article{kahneman2003maps,
  title = {Maps of {{Bounded Rationality}}: {{Psychology}} for {{Behavioral Economics}}},
  author = {Kahneman, Daniel},
  year = {2003},
  month = dec,
  journal = {American Economic Review},
  volume = {93},
  number = {5},
  pages = {1449--1475},
  doi = {10.1257/000282803322655392},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kahneman2003maps-Maps of Bounded Rationality - Psychology for Behavioral Economics.pdf}
}

@book{kahneman2011thinking,
  title = {Thinking, Fast and Slow},
  author = {Kahneman, Daniel},
  year = {2011},
  publisher = {Macmillan},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kahneman2011thinking-Thinking, fast and slow.pdf}
}

@article{kambhampati2024llms,
  title = {{{LLMs Can}}'t {{Plan}}, {{But Can Help Planning}} in {{LLM-Modulo Frameworks}}},
  author = {Kambhampati, Subbarao and Valmeekam, Karthik and Guan, Lin and Stechly, Kaya and Verma, Mudit and Bhambri, Siddhant and Saldyt, Lucas and Murthy, Anil},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.01817},
  eprint = {2402.01817},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kambhampati2024llms-LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks.pdf}
}

@article{kannan2023smartllm,
  title = {Smart-Llm: {{Smart}} Multi-Agent Robot Task Planning Using Large Language Models},
  author = {Kannan, Shyam Sundar and Venkatesh, Vishnunandan LN and Min, Byung-Cheol},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.10062},
  eprint = {2309.10062},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kannan2023smartllm-Smart-llm - Smart multi-agent robot task planning using large language models.pdf}
}

@article{karpas2022mrkl,
  title = {{{MRKL Systems}}: {{A}} Modular, Neuro-Symbolic Architecture That Combines Large Language Models, External Knowledge Sources and Discrete Reasoning},
  author = {Karpas, Ehud and Abend, Omri and Belinkov, Yonatan and Lenz, Barak and Lieber, Opher and Ratner, Nir and Shoham, Yoav and Bata, Hofit and Levine, Yoav and {Leyton-Brown}, Kevin and others},
  year = {2022},
  journal = {arXiv preprint arXiv:2205.00445},
  eprint = {2205.00445},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@karpas2022mrkl-MRKL Systems - A modular, neuro-symbolic architecture that combines large.pdf}
}

@article{kartasev2021improving,
  title = {Improving the Performance of Backward Chained Behavior Trees That Use Reinforcement Learning},
  author = {Karta{\v s}ev, Mart and Saler, Justin and {\"O}gren, Petter},
  year = {2021},
  journal = {arXiv preprint arXiv:2112.13744},
  eprint = {2112.13744},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kartasev2021improving-Improving the performance of backward chained behavior trees that use.pdf}
}

@article{kemmerling2024games,
  title = {Beyond Games: A Systematic Review of Neural {{Monte Carlo}} Tree Search Applications},
  author = {Kemmerling, Marco and L{\"u}tticke, Daniel and Schmitt, Robert H.},
  year = {2024},
  month = jan,
  journal = {Applied Intelligence},
  volume = {54},
  number = {1},
  pages = {1020--1046},
  issn = {1573-7497},
  doi = {10.1007/s10489-023-05240-w},
  abstract = {The advent of AlphaGo and its successors marked the beginning of a new paradigm in playing games using artificial intelligence. This was achieved by combining Monte Carlo tree search, a planning procedure, and deep learning. While the impact on the domain of games has been undeniable, it is less clear how useful similar approaches are in applications beyond games and how they need to be adapted from the original methodology. We perform a systematic literature review of peer-reviewed articles detailing the application of neural Monte Carlo tree search methods in domains other than games. Our goal is to systematically assess how such methods are structured in practice and if their success can be extended to other domains. We find applications in a variety of domains, many distinct ways of guiding the tree search using learned policy and value functions, and various training methods. Our review maps the current landscape of algorithms in the family of neural monte carlo tree search as they are applied to practical problems, which is a first step towards a more principled way of designing such algorithms for specific problems and their requirements.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kemmerling2024games-Beyond games - a systematic review of neural Monte Carlo tree search applications.pdf}
}

@incollection{keyder2008heuristics,
  title = {Heuristics for Planning with Action Costs Revisited},
  booktitle = {{{ECAI}} 2008},
  author = {Keyder, Emil and Geffner, H{\'e}ctor},
  year = {2008},
  pages = {588--592},
  publisher = {IOS Press},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@keyder2008heuristics-Heuristics for planning with action costs revisited.pdf}
}

@article{khan2023natural,
  title = {Natural {{Language Robot Programming}}: {{NLP}} Integrated with Autonomous Robotic Grasping},
  author = {Khan, Muhammad Arshad and Kenney, Max and Painter, Jack and Kamale, Disha and {Batista-Navarro}, Riza and {Ghalamzan-E}, Amir},
  year = {2023},
  journal = {arXiv preprint arXiv:2304.02993},
  eprint = {2304.02993},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@khan2023natural-Natural Language Robot Programming - NLP integrated with autonomous robotic.pdf}
}

@article{khan2023review,
  title = {A Review on Gait Generation of the Biped Robot on Various Terrains},
  author = {Khan, Moh Shahid and Mandava, Ravi Kumar},
  year = {2023},
  month = jun,
  journal = {Robotica},
  volume = {41},
  number = {6},
  pages = {1888--1930},
  publisher = {Cambridge University Press},
  issn = {0263-5747, 1469-8668},
  doi = {10.1017/S0263574723000097},
  urldate = {2023-05-23},
  abstract = {Day by day, biped robots' usage is increasing enormously in all industrial and non-industrial applications due to their ability to move in any unstructured environment compared to wheeled robots. Keeping this in mind, worldwide, many researchers are working on various aspects of biped robots, such as gait generation, dynamic balance margin, and the design of controllers. The main aim of this review article is to discuss the main challenges encountered in the biped gait generation and design of various controllers while moving on different terrain conditions such as flat, ascending and descending slopes or stairs, avoiding obstacles/ditches, uneven terrain, and an unknown environment. As per the authors' knowledge, no single study has been carried out in one place related to the gait generation and design of controllers for each joint of the biped robot on various terrains. This review will help researchers working in this field better understand the concepts of gait generation, dynamic balance margin, and the design of controllers while moving on various terrains. Moreover, the current article will also cover the different soft computing techniques used to tune the gains of the controllers. In this article, the authors have reviewed a vast compilation of research work on the gait generation of the biped robot on various terrains. Further, the authors have proposed taxonomies on various design issues identified while generating the gait in different aspects. The authors reviewed approximately 296 articles and discovered that all researchers attempted to generate the dynamically balanced biped gait on various terrains.},
  langid = {english},
  keywords = {biped robot,controllers,DBM,gait generation,ObsCite,review,soft computing techniques,ZMP},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@khan2023review-A review on gait generation of the biped robot on various terrains.pdf}
}

@article{kim2017robust,
  title = {Robust {{Dynamic Locomotion}} via {{Reinforcement Learning}} and {{Novel Whole Body Controller}}},
  author = {Kim, Donghyun and Lee, Jaemin and Sentis, L.},
  year = {2017},
  month = aug,
  journal = {ArXiv},
  urldate = {2023-05-19},
  abstract = {We propose a robust dynamic walking controller consisting of a dynamic locomotion planner, a reinforcement learning process for robustness, and a novel whole-body locomotion controller (WBLC). Previous approaches specify either the position or the timing of steps, however, the proposed locomotion planner simultaneously computes both of these parameters as locomotion outputs. Our locomotion strategy relies on devising a reinforcement learning (RL) approach for robust walking. The learned policy generates multi step walking patterns, and the process is quick enough to be suitable for real-time controls. For learning, we devise an RL strategy that uses a phase space planner (PSP) and a linear inverted pendulum model to make the problem tractable and very fast. Then, the learned policy is used to provide goal-based commands to the WBLC, which calculates the torque commands to be executed in full-humanoid robots. The WBLC combines multiple prioritized tasks and calculates the associated reaction forces based on practical inequality constraints. The novel formulation includes efficient calculation of the time derivatives of various Jacobians. This provides high-fidelity dynamic control of fast motions. More specifically, we compute the time derivative of the Jacobian for various tasks and the Jacobian of the centroidal momentum task by utilizing Lie group operators and operational space dynamics respectively. The integration of RL-PSP and the WBLC provides highly robust, versatile, and practical locomotion including steering while walking and handling push disturbances of up to 520 N during an interval of 0.1 sec. Theoretical and numerical results are tested through a 3D physics-based simulation of the humanoid robot Valkyrie.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kim2017robust-Robust Dynamic Locomotion via Reinforcement Learning and Novel Whole Body.pdf}
}

@article{kim2023llm,
  title = {An {{LLM}} Compiler for Parallel Function Calling},
  author = {Kim, Sehoon and Moon, Suhong and Tabrizi, Ryan and Lee, Nicholas and Mahoney, Michael W and Keutzer, Kurt and Gholami, Amir},
  year = {2023},
  journal = {arXiv preprint arXiv:2312.04511},
  eprint = {2312.04511},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kim2023llm-An LLM compiler for parallel function calling.pdf}
}

@article{kim2024openvla,
  title = {{{OpenVLA}}: {{An Open-Source Vision-Language-Action Model}}},
  author = {Kim, Moo Jin and Pertsch, Karl and Karamcheti, Siddharth and Xiao, Ted and Balakrishna, Ashwin and Nair, Suraj and Rafailov, Rafael and Foster, Ethan and Lam, Grace and Sanketi, Pannag and others},
  year = {2024},
  journal = {arXiv preprint arXiv:2406.09246},
  eprint = {2406.09246},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kim2024openvla-OpenVLA - An Open-Source Vision-Language-Action Model.pdf}
}

@article{kim2024relevance,
  title = {Relevance {{Score}}: {{A Landmark-Like Heuristic}} for {{Planning}}},
  author = {Kim, Oliver and Sridharan, Mohan},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.07510},
  eprint = {2403.07510},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kim2024relevance-Relevance Score - A Landmark-Like Heuristic for Planning.pdf}
}

@article{kober2013reinforcement,
  title = {Reinforcement Learning in Robotics: {{A}} Survey},
  author = {Kober, Jens and Bagnell, J. Andrew and Peters, Jan},
  year = {2013},
  journal = {The International Journal of Robotics Research},
  volume = {32},
  pages = {1238--1274},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kober2013reinforcement-Reinforcement learning in robotics - A survey.pdf}
}

@inproceedings{kockemann2023planning,
  title = {Planning for Automated Testing of Implicit Constraints in Behavior Trees},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}}},
  author = {K{\"o}ckemann, Uwe and Calisi, Daniele and Gemignani, Guglielmo and Renoux, Jennifer and Saffiotti, Alessandro},
  year = {2023},
  volume = {33},
  pages = {649--658},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kockemann2023planning-Planning for automated testing of implicit constraints in behavior trees.pdf}
}

@inproceedings{kojima2022large,
  title = {Large {{Language Models}} Are {{Zero-Shot Reasoners}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Kojima, Takeshi and Gu, Shixiang (Shane) and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  editor = {Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
  year = {2022},
  volume = {35},
  pages = {22199--22213},
  publisher = {Curran Associates, Inc.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kojima2022large-Large Language Models are Zero-Shot Reasoners.pdf}
}

@article{kokotinis2024behavior,
  title = {A {{Behavior Trees-based}} Architecture towards Operation Planning in Hybrid Manufacturing},
  author = {Kokotinis, George and Michalos, George and Arkouli, Zoi and Makris, Sotiris},
  year = {2024},
  journal = {International Journal of Computer Integrated Manufacturing},
  volume = {37},
  number = {3},
  pages = {324--349},
  publisher = {Taylor \& Francis},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kokotinis2024behavior-A Behavior Trees-based architecture towards operation planning in hybrid.pdf}
}

@article{koza1992genetic,
  title = {Genetic {{Programming}}: v. 1 {{On}} the {{Programming}} of {{Computers}} by {{Means}} of {{Natural Selection}}},
  author = {Koza, J. R.},
  year = {1992},
  journal = {MIT Press}
}

@article{kroemer2021review,
  title = {A Review of Robot Learning for Manipulation: {{Challenges}}, Representations, and Algorithms},
  author = {Kroemer, Oliver and Niekum, Scott and Konidaris, George},
  year = {2021},
  journal = JMLR,
  volume = {22},
  number = {30},
  pages = {1--82},
  keywords = {learning},
  annotation = {JMLR},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kroemer2021review-A review of robot learning for manipulation - Challenges, representations, and.pdf}
}

@article{kubricht2017intuitive,
  title = {Intuitive {{Physics}}: {{Current Research}} and {{Controversies}}},
  shorttitle = {Intuitive {{Physics}}},
  author = {Kubricht, James R. and Holyoak, Keith J. and Lu, Hongjing},
  year = {2017},
  month = oct,
  journal = {Trends in Cognitive Sciences},
  volume = {21},
  number = {10},
  pages = {749--759},
  issn = {13646613},
  doi = {10.1016/j.tics.2017.06.002},
  urldate = {2022-10-22},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kubricht2017intuitive-Intuitive Physics - Current Research and Controversies.pdf}
}

@inproceedings{kuckling2018behavior,
  title = {Behavior Trees as a Control Architecture in the Automatic Modular Design of Robot Swarms},
  booktitle = {International Conference on Swarm Intelligence},
  author = {Kuckling, Jonas and Ligot, Antoine and Bozhinoski, Darko and Birattari, Mauro},
  year = {2018},
  pages = {30--43},
  publisher = {Springer},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kuckling2018behavior-Behavior trees as a control architecture in the automatic modular design of.pdf}
}

@inproceedings{kuckling2021automatic,
  title = {Automatic {{Modular Design}} of {{Behavior Trees}} for {{Robot Swarms}} with {{Communication Capabilites}}},
  booktitle = {Applications of {{Evolutionary Computation}}},
  author = {Kuckling, Jonas and {van Pelt}, Vincent and Birattari, Mauro},
  editor = {Castillo, Pedro A. and Jim{\'e}nez Laredo, Juan Luis},
  year = {2021},
  pages = {130--145},
  publisher = {Springer International Publishing},
  address = {Cham},
  abstract = {In this work, we develop a set of behavioral and conditional modules for the use with behavior trees. We present AutoMoDe-Cedrata, an automatic modular design method that automatically assembles and fine-tunes these modules into behavior trees that control robot swarms. We test Cedrata on three missions and, to gain further insights on its effectiveness, we design control software for the same missions using AutoMoDe-Maple, another automatic design method, and by a group of human designers. Results show that the proposed modules allow for well-performing behavior trees. Yet, Cedrata had difficulties automatically generating control software that performs similarly well as the one generated by human designers, especially when involving communication.},
  isbn = {978-3-030-72699-7},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kuckling2021automatic-Automatic Modular Design of Behavior Trees for Robot Swarms with Communication.pdf}
}

@inproceedings{kulkarni2019unsupervised,
  title = {Unsupervised Learning of Object Keypoints for Perception and Control},
  booktitle = NeurIPS,
  author = {Kulkarni, Tejas D and Gupta, Ankush and Ionescu, Catalin and Borgeaud, Sebastian and Reynolds, Malcolm and Zisserman, Andrew and Mnih, Volodymyr},
  year = {2019},
  volume = {32},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kulkarni2019unsupervised-Unsupervised learning of object keypoints for perception and control.pdf}
}

@inproceedings{kumar2023learning,
  title = {Learning Efficient Abstract Planning Models That Choose What to Predict},
  booktitle = {Conference on {{Robot Learning}}},
  author = {Kumar, Nishanth and McClinton, Willie and Chitnis, Rohan and Silver, Tom and {Lozano-P{\'e}rez}, Tom{\'a}s and Kaelbling, Leslie Pack},
  year = {2023},
  pages = {2070--2095},
  publisher = {PMLR},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kumar2023learning-Learning efficient abstract planning models that choose what to predict.pdf}
}

@article{kumar2024openworld,
  title = {Open-{{World Task}} and {{Motion Planning}} via {{Vision-Language Model Inferred Constraints}}},
  author = {Kumar, Nishanth and Ramos, Fabio and Fox, Dieter and Garrett, Caelan Reed},
  year = {2024},
  journal = {arXiv preprint arXiv:2411.08253},
  eprint = {2411.08253},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kumar2024openworld-Open-World Task and Motion Planning via Vision-Language Model Inferred.pdf}
}

@article{kuniyoshi2019fusing,
  title = {Fusing Autonomy and Sociality via Embodied Emergence and Development of Behaviour and Cognition from Fetal Period},
  author = {Kuniyoshi, Yasuo},
  year = {2019},
  journal = {Philosophical Transactions of the Royal Society B},
  volume = {374},
  number = {1771},
  pages = {20180031},
  publisher = {The Royal Society}
}

@inproceedings{kurin2021my,
  title = {My {{Body}} Is a {{Cage}}: The {{Role}} of {{Morphology}} in {{Graph-Based Incompatible Control}}},
  booktitle = ICLR,
  author = {Kurin, Vitaly and Igl, Maximilian and Rockt{\"a}schel, Tim and Boehmer, Wendelin and Whiteson, Shimon},
  year = {2021},
  publisher = {OpenReview.net},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@kurin2021my-My Body is a Cage - the Role of Morphology in Graph-Based Incompatible Control.pdf}
}

@article{ladosz2022exploration,
  title = {Exploration in Deep Reinforcement Learning: {{A}} Survey},
  author = {Ladosz, Pawel and Weng, Lilian and Kim, Minwoo and Oh, Hyondong},
  year = {2022},
  journal = {Information Fusion},
  publisher = {Elsevier},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ladosz2022exploration-Exploration in deep reinforcement learning - A survey.pdf}
}

@article{lai2024scalable,
  title = {Scalable and {{Effective Arithmetic Tree Generation}} for {{Adder}} and {{Multiplier Designs}}},
  author = {Lai, Yao and Liu, Jinxin and Pan, David Z and Luo, Ping},
  year = {2024},
  journal = {arXiv preprint arXiv:2405.06758},
  eprint = {2405.06758},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@lai2024scalable-Scalable and Effective Arithmetic Tree Generation for Adder and Multiplier.pdf}
}

@article{lan2020semionline,
  title = {Semi-Online {{Multi-people Tracking}} by {{Re-identification}}},
  author = {Lan, Long and Wang, Xinchao and Hua, Gang and Huang, Thomas S. and Tao, Dacheng},
  year = {2020},
  journal = {IJCV},
  volume = {128},
  number = {7},
  pages = {1937--1955},
  doi = {10.1007/s11263-020-01314-1}
}

@book{langchaozhidian,
  title = {浪潮之巅（下）},
  file = {D:\Cloud\Storage\SoftwareData\zotfile\浪潮之巅（下） @langchaozhidian.pdf}
}

@book{langchaozhidiana,
  title = {浪潮之巅（上）},
  file = {D:\Cloud\Storage\SoftwareData\zotfile\浪潮之巅（上） @langchaozhidiana.pdf}
}

@article{laroche2017transfer,
  title = {Transfer {{Reinforcement Learning}} with {{Shared Dynamics}}},
  author = {Laroche, Romain and Barlier, Merwan},
  year = {2017},
  month = feb,
  journal = AAAI,
  volume = {31},
  number = {1},
  doi = {10.1609/aaai.v31i1.10796},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@laroche2017transfer-Transfer Reinforcement Learning with Shared Dynamics.pdf}
}

@inproceedings{laskey2017dart,
  title = {Dart: {{Noise}} Injection for Robust Imitation Learning},
  booktitle = CoRL,
  author = {Laskey, Michael and Lee, Jonathan and Fox, Roy and Dragan, Anca and Goldberg, Ken},
  year = {2017},
  pages = {143--156},
  publisher = {PMLR},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@laskey2017dart-Dart - Noise injection for robust imitation learning.pdf}
}

@inproceedings{lauer2021polynomialtime,
  title = {Polynomial-Time in {{PDDL}} Input Size: {{Making}} the Delete Relaxation Feasible for Lifted Planning},
  booktitle = {{{ICAPS}} 2021 {{Workshop}} on {{Heuristics}} and {{Search}} for {{Domain-independent Planning}}},
  author = {Lauer, Pascal and Torralba, Alvaro and Fi{\v s}er, Daniel and H{\"o}ller, Daniel and Wichlacz, Julia and Hoffmann, J{\"o}rg},
  year = {2021},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@lauer2021polynomialtime-Polynomial-time in PDDL input size - Making the delete relaxation feasible for.pdf}
}

@book{lavalle2006planning,
  title = {Planning Algorithms},
  author = {LaValle, Steven M},
  year = {2006},
  publisher = {Cambridge university press},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@lavalle2006planning-Planning algorithms.pdf}
}

@misc{learning,
  title = {Learning Body Shape Variation in Physics-Based Characters {\textbar} {{ACM Transactions}} on {{Graphics}}},
  urldate = {2023-05-29},
  howpublished = {https://dl.acm.org/doi/10.1145/3355089.3356499},
  file = {C:\Users\lenovo\Zotero\storage\6W4DXICB\3355089.html}
}

@article{lecun1998gradientbased,
  title = {Gradient-Based Learning Applied to Document Recognition},
  author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  year = {1998},
  month = nov,
  journal = {Proceedings of the IEEE},
  volume = {86},
  number = {11},
  pages = {2278--2324},
  issn = {00189219},
  doi = {10.1109/5.726791},
  urldate = {2022-03-31},
  langid = {english},
  keywords = {cnn},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@lecun1998gradientbased-Gradient-based learning applied to document recognition.pdf}
}

@article{lecun2022path,
  title = {A Path towards Autonomous Machine Intelligence},
  author = {LeCun, Yann},
  year = {2022},
  journal = {preprint posted on openreview},
  keywords = {ObsCite},
  file = {C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@lecun2022path-A path towards autonomous machine intelligence.pdf;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@lecun2022path-A path towards autonomous machine intelligence2.pdf}
}

@inproceedings{lee2011intrinsic,
  title = {Intrinsic Activitity: From Motor Babbling to Play},
  booktitle = {{{IEEE International Conference}} on {{Development}} and {{Learning}} ({{ICDL}})},
  author = {Lee, Mark H},
  year = {2011},
  volume = {2},
  pages = {1--6},
  publisher = {IEEE}
}

@inproceedings{lee2018gated,
  title = {Gated {{Path Planning Networks}}},
  booktitle = ICLR,
  author = {Lee, Lisa and Parisotto, Emilio and Chaplot, Devendra Singh and Xing, Eric and Salakhutdinov, Ruslan},
  year = {2018},
  month = jun,
  urldate = {2022-04-19},
  abstract = {Value Iteration Networks (VINs) are effective differentiable path planning modules that can be used by agents to perform navigation while still maintaining end-to-end differentiability of the entire architecture. Despite their effectiveness, they suffer from several disadvantages including training instability, random seed sensitivity, and other optimization problems. In this work, we reframe VINs as recurrent-convolutional networks which demonstrates that VINs couple recurrent convolutions with an unconventional max-pooling activation. From this perspective, we argue that standard gated recurrent update equations could potentially alleviate the optimization issues plaguing VIN. The resulting architecture, which we call the Gated Path Planning Network, is shown to empirically outperform VIN on a variety of metrics such as learning speed, hyperparameter sensitivity, iteration count, and even generalization. Furthermore, we show that this performance gap is consistent across different maze transition types, maze sizes and even show success on a challenging 3D environment, where the planner is only provided with first-person RGB images.},
  langid = {english},
  annotation = {ICML},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@lee2018gated-Gated Path Planning Networks.pdf}
}

@inproceedings{levine2013guided,
  title = {Guided {{Policy Search}}},
  booktitle = ICML,
  author = {Levine, Sergey and Koltun, Vladlen},
  year = {2013},
  month = jun,
  abstract = {Direct policy search can effectively scale to high-dimensional systems, but complex policies with hundreds of parameters often present a challenge for such methods, requiring numerous samples and often falling into poor local optima. We present a guided policy search algorithm that uses trajectory optimization to direct policy learning and avoid poor local optima. We show how differential dynamic programming can be used to generate suitable guiding samples, and describe a regularized importance sampled policy optimization that incorporates these samples into the policy search. We evaluate the method by learning neural network controllers for planar swimming, hopping, and walking, as well as simulated 3D humanoid running.},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@levine2013guided-Guided Policy Search.pdf}
}

@inproceedings{levine2014learning,
  title = {Learning {{Neural Network Policies}} with {{Guided Policy Search}} under {{Unknown Dynamics}}},
  booktitle = NeurIPS,
  author = {Levine, Sergey and Abbeel, Pieter},
  editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. and Weinberger, K. Q.},
  year = {2014},
  volume = {27},
  publisher = {Curran Associates, Inc.},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@levine2014learning-Learning Neural Network Policies with Guided Policy Search under Unknown.pdf}
}

@article{levine2015learning,
  title = {Learning Contact-Rich Manipulation Skills with Guided Policy Search},
  author = {Levine, Sergey and Wagener, Nolan and Abbeel, P.},
  year = {2015},
  journal = ICRA,
  pages = {156--163},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@levine2015learning-Learning contact-rich manipulation skills with guided policy search.pdf}
}

@article{li2015reinforcement,
  title = {Reinforcement Learning Control for Coordinated Manipulation of Multi-Robots},
  author = {Li, Yanan and Chen, Long and Tee, Keng Peng and Li, Qingquan},
  year = {2015},
  month = dec,
  journal = {Neurocomputing},
  series = {Advances on {{Biological Rhythmic Pattern Generation}}: {{Experiments}}, {{Algorithms}} and {{Applications}}},
  volume = {170},
  pages = {168--175},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2015.02.091},
  urldate = {2023-05-19},
  abstract = {In this paper, coordination control is investigated for multi-robots to manipulate an object with a common desired trajectory. Both trajectory tracking and control input minimization are considered for each individual robot manipulator, such that possible disagreement between different manipulators can be handled. Reinforcement learning is employed to cope with the problem of unknown dynamics of both robots and the manipulated object. It is rigorously proven that the proposed method guarantees the coordination control of the multi-robots system under study. The validity of the proposed method is verified through simulation studies.},
  langid = {english},
  keywords = {Multi-robots coordination,Reinforcement learning,Robot control},
  file = {C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@li2015reinforcement-Reinforcement learning control for coordinated manipulation of multi-robots.pdf;C\:\\Users\\lenovo\\Zotero\\storage\\YP3BLZWU\\S0925231215009339.html}
}

@article{li2016causal,
  title = {Causal Decision Trees},
  author = {Li, Jiuyong and Ma, Saisai and Le, Thuc and Liu, Lin and Liu, Jixue},
  year = {2016},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {29},
  number = {2},
  pages = {257--271},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2016causal-Causal decision trees.pdf}
}

@article{li2017hyperband,
  title = {Hyperband: {{A Novel Bandit-Based Approach}} to {{Hyperparameter Optimization}}},
  author = {Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
  year = {2017},
  journal = JMLR,
  volume = {18},
  number = {1},
  pages = {6765--6816},
  publisher = {JMLR.org},
  issn = {1532-4435},
  abstract = {Performance of machine learning algorithms depends critically on identifying a good set of hyperparameters. While recent approaches use Bayesian optimization to adaptively select configurations, we focus on speeding up random search through adaptive resource allocation and early-stopping. We formulate hyperparameter optimization as a pure-exploration nonstochastic infinite-armed bandit problem where a predefined resource like iterations, data samples, or features is allocated to randomly sampled configurations. We introduce a novel algorithm, Hyperband, for this framework and analyze its theoretical properties, providing several desirable guarantees. Furthermore, we compare Hyperband with popular Bayesian optimization methods on a suite of hyperparameter optimization problems. We observe that Hyperband can provide over an order-of-magnitude speedup over our competitor set on a variety of deep-learning and kernel-based learning problems.},
  keywords = {deep learning,hyperparameter optimization,infinite-armed bandits,model selection,online optimization},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2017hyperband-Hyperband - A Novel Bandit-Based Approach to Hyperparameter Optimization.pdf}
}

@inproceedings{li2019integrating,
  title = {Integrating {{Decision Sharing}} with {{Prediction}} in {{Decentralized Planning}} for {{Multi-Agent Coordination}} under {{Uncertainty}}},
  booktitle = IJCAI,
  author = {Li, Minglong and Yang, Wenjing and Cai, Zhongxuan and Yang, Shaowu and Wang, Ji},
  year = {2019},
  month = aug,
  pages = {450--456},
  publisher = {IJCAI Organization},
  address = {Macao, China},
  doi = {10.24963/ijcai.2019/64},
  urldate = {2022-02-28},
  isbn = {978-0-9992411-4-1},
  langid = {english},
  keywords = {team paper},
  annotation = {IJCAI},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2019integrating-Integrating Decision Sharing with Prediction in Decentralized Planning for.pdf}
}

@inproceedings{li2019offline,
  title = {Offline Policy Iteration Based Reinforcement Learning Controller for Online Robotic Knee Prosthesis Parameter Tuning},
  booktitle = ICRA,
  author = {Li, Minhan and Gao, Xiang and Wen, Yue and Si, Jennie and Huang, He Helen},
  year = {2019},
  pages = {2831--2837},
  doi = {10.1109/ICRA.2019.8794212},
  keywords = {ObsCite},
  annotation = {使用 FSM 划分步态，并分别使用独立的 RL 来学习各阶段控制},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2019offline-Offline policy iteration based reinforcement learning controller for online.pdf}
}

@inproceedings{li2020gpnas,
  title = {{{GP-NAS}}: {{Gaussian Process Based Neural Architecture Search}}},
  booktitle = CVPR,
  author = {Li, Zhihang and Xi, Teng and Deng, Jiankang and Zhang, Gang and Wen, Shengzhao and He, Ran},
  year = {2020},
  pages = {10},
  abstract = {Neural architecture search (NAS) advances beyond the state-of-the-art in various computer vision tasks by automating the designs of deep neural networks. In this paper, we aim to address three important questions in NAS: (1) How to measure the correlation between architectures and their performances? (2) How to evaluate the correlation between different architectures? (3) How to learn these correlations with a small number of samples? To this end, we first model these correlations from a Bayesian perspective. Specifically, by introducing a novel Gaussian Process based NAS (GP-NAS) method, the correlations are modeled by the kernel function and mean function. The kernel function is also learnable to enable adaptive modeling for complex correlations in different search spaces. Furthermore, by incorporating a mutual information based sampling method, we can theoretically ensure the high-performance architecture with only a small set of samples. After addressing these problems, training GP-NAS once enables direct performance prediction of any architecture in different scenarios and may obtain efficient networks for different deployment platforms. Extensive experiments on both image classification and face recognition tasks verify the effectiveness of our algorithm.},
  langid = {english},
  keywords = {gaussion},
  annotation = {CVPR},
  file = {C:\Users\lenovo\Zotero\storage\2THQVGQJ\Li_2020_GP-NAS.pdf}
}

@inproceedings{li2020learning,
  title = {Learning {{Generalizable Locomotion Skills}} with {{Hierarchical Reinforcement Learning}}},
  booktitle = ICRA,
  author = {Li, Tianyu and Lambert, Nathan and Calandra, Roberto and Meier, Franziska and Rai, Akshara},
  year = {2020},
  month = may,
  pages = {413--419},
  publisher = {IEEE},
  address = {Paris, France},
  doi = {10.1109/ICRA40945.2020.9196642},
  urldate = {2022-02-28},
  abstract = {Learning to locomote to arbitrary goals on hardware remains a challenging problem for reinforcement learning. In this paper, we present a hierarchical framework that improves sample-efficiency and generalizability of learned locomotion skills on real-world robots. Our approach divides the problem of goal-oriented locomotion into two sub-problems: learning diverse primitives skills, and using model-based planning to sequence these skills. We parametrize our primitives as cyclic movements, improving sample-efficiency of learning from scratch on a 18 degrees of freedom robot. Then, we learn coarse dynamics models over primitive cycles and use them in a model predictive control framework. This allows us to learn to walk to arbitrary goals up to 12m away, after about two hours of training from scratch on hardware. Our results on a Daisy hexapod hardware and simulation demonstrate the efficacy of our approach at reaching distant targets, in different environments, and with sensory noise.},
  isbn = {978-1-72817-395-5},
  langid = {english},
  keywords = {ObsCite},
  annotation = {ICRA},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2020learning-Learning Generalizable Locomotion Skills with Hierarchical Reinforcement.pdf}
}

@inproceedings{li2020neural,
  title = {Neural {{Graph Embedding}} for {{Neural Architecture Search}}},
  booktitle = AAAI,
  author = {Li, Wei and Gong, Shaogang and Zhu, Xiatian},
  year = {2020},
  month = apr,
  volume = {34},
  pages = {4707--4714},
  doi = {10.1609/aaai.v34i04.5903},
  urldate = {2022-03-12},
  abstract = {Existing neural architecture search (NAS) methods often operate in discrete or continuous spaces directly, which ignores the graphical topology knowledge of neural networks. This leads to suboptimal search performance and efficiency, given the factor that neural networks are essentially directed acyclic graphs (DAG). In this work, we address this limitation by introducing a novel idea of neural graph embedding (NGE). Specifically, we represent the building block (i.e. the cell) of neural networks with a neural DAG, and learn it by leveraging a Graph Convolutional Network to propagate and model the intrinsic topology information of network architectures. This results in a generic neural network representation integrable with different existing NAS frameworks. Extensive experiments show the superiority of NGE over the state-of-the-art methods on image classification and semantic segmentation.},
  langid = {english},
  keywords = {architecture encoding,graph embedding},
  annotation = {AAAI},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\BKNTEYBG\\2020 - AAAI - Neural Graph Embedding for Neural Architecture Search.pptx;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@li2020neural-Neural Graph Embedding for Neural Architecture Search.pdf}
}

@inproceedings{li2021decsgts,
  title = {Dec-{{SGTS}}: {{Decentralized Sub-Goal Tree Search}} for {{Multi-Agent Coordination}}},
  booktitle = AAAI,
  author = {Li, Minglong and Cai, Zhongxuan and Yang, Wenjing and Wu, Lixia and Xu, Yinghui and Wang, Ji},
  year = {2021},
  pages = {8},
  langid = {english},
  keywords = {ObsCite,team paper},
  annotation = {AAAI},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2021decsgts-Dec-SGTS - Decentralized Sub-Goal Tree Search for Multi-Agent Coordination.pdf}
}

@inproceedings{li2021generic,
  title = {Generic Neural Architecture Search via Regression},
  booktitle = NeurIPS,
  author = {Li, Yuhong and Hao, Cong and Li, Pan and Xiong, Jinjun and Chen, Deming},
  editor = {Beygelzimer, A. and Dauphin, Y. and Liang, P. and Vaughan, J. Wortman},
  year = {2021},
  keywords = {regression},
  annotation = {NeurIPS},
  file = {D:\Cloud\BaiduSyncdisk\CXL_Big\SoftwareData\zotfile\NeurIPS2021_Generic neural architecture search via regression @li2021GenericNeuralArchitecture.pdf}
}

@inproceedings{li2021mfeshb,
  title = {{{MFES-HB}}: {{Efficient Hyperband}} with {{Multi-Fidelity Quality Measurements}}},
  shorttitle = {{{MFES-HB}}},
  booktitle = AAAI,
  author = {Li, Yang and Shen, Yu and Jiang, Jiawei and Gao, Jinyang and Zhang, Ce and Cui, Bin},
  year = {2021},
  month = aug,
  number = {arXiv:2012.03011},
  eprint = {2012.03011},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2022-05-24},
  abstract = {Hyperparameter optimization (HPO) is a fundamental problem in automatic machine learning (AutoML). However, due to the expensive evaluation cost of models (e.g., training deep learning models or training models on large datasets), vanilla Bayesian optimization (BO) is typically computationally infeasible. To alleviate this issue, Hyperband (HB) utilizes the early stopping mechanism to speed up configuration evaluations by terminating those badly-performing configurations in advance. This leads to two kinds of quality measurements: (1) many low-fidelity measurements for configurations that get early-stopped, and (2) few high-fidelity measurements for configurations that are evaluated without being early stopped. The state-of-the-art HB-style method, BOHB, aims to combine the benefits of both BO and HB. Instead of sampling configurations randomly in HB, BOHB samples configurations based on a BO surrogate model, which is constructed with the high-fidelity measurements only. However, the scarcity of high-fidelity measurements greatly hampers the efficiency of BO to guide the configuration search.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2021mfeshb-MFES-HB - Efficient Hyperband with Multi-Fidelity Quality Measurements.pdf}
}

@inproceedings{li2021neural,
  title = {Neural Architecture Dilation for Adversarial Robustness},
  booktitle = NeurIPS,
  author = {Li, Yanxi and Yang, Zhaohui and Wang, Yunhe and Xu, Chang},
  editor = {Beygelzimer, A. and Dauphin, Y. and Liang, P. and Vaughan, J. Wortman},
  year = {2021},
  keywords = {adversarial},
  annotation = {NeurIPS},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2021neural-Neural architecture dilation for adversarial robustness.pdf}
}

@article{li2021oneshot,
  title = {One-Shot {{Graph Neural Architecture Search}} with {{Dynamic Search Space}}},
  author = {Li, Yanxi and Wen, Zean and Wang, Yunhe and Xu, Chang},
  year = {2021},
  journal = AAAI,
  pages = {8},
  langid = {english},
  keywords = {dynamic search space,one-shot},
  annotation = {AAAI},
  file = {C:\Users\lenovo\Zotero\storage\4EU3XYRR\Li_2021_One-shot Graph Neural Architecture Search with Dynamic Search Space.pdf}
}

@inproceedings{li2021reactive,
  title = {Reactive Task and Motion Planning under Temporal Logic Specifications},
  booktitle = ICRA,
  author = {Li, Shen and Park, Daehyung and Sung, Yoonchang and Shah, Julie A and Roy, Nicholas},
  year = {2021},
  pages = {12618--12624},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2021reactive-Reactive task and motion planning under temporal logic specifications.pdf}
}

@article{li2022competitionlevel,
  title = {Competition-Level Code Generation with {{AlphaCode}}},
  author = {Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Lago, Agustin Dal and Hubert, Thomas and Choy, Peter and {d'Autume}, Cyprien de Masson and Babuschkin, Igor and Chen, Xinyun and Huang, Po-Sen and Welbl, Johannes and Gowal, Sven and Cherepanov, Alexey and Molloy, James and Mankowitz, Daniel J. and Robson, Esme Sutherland and Kohli, Pushmeet and de Freitas, Nando and Kavukcuoglu, Koray and Vinyals, Oriol},
  year = {2022},
  month = mar,
  journal = {Science},
  volume = {378},
  number = {6624},
  pages = {1092--1097},
  doi = {10.1126/science.abq1158},
  abstract = {Programming is a powerful and ubiquitous problem-solving tool. Systems that can assist programmers or even generate programs themselves could make programming more productive and accessible. Recent transformer-based neural network models show impressive code generation abilities yet still perform poorly on more complex tasks requiring problem-solving skills, such as competitive programming problems. Here, we introduce AlphaCode, a system for code generation that achieved an average ranking in the top 54.3\% in simulated evaluations on recent programming competitions on the Codeforces platform. AlphaCode solves problems by generating millions of diverse programs using specially trained transformer-based networks and then filtering and clustering those programs to a maximum of just 10 submissions. This result marks the first time an artificial intelligence system has performed competitively in programming competitions. Computer programming competitions are popular tests among programmers that require critical thinking informed by experience and creating solutions to unforeseen problems, both of which are key aspects of human intelligence but challenging to mimic by machine learning models. Using self-supervised learning and an encoder-decoder transformer architecture, Li et al. developed AlphaCode, a deep-learning model that can achieve approximately human-level performance on the Codeforces platform, which regularly hosts these competitions and attracts numerous participants worldwide (see the Perspective by Kolter). The development of such coding platforms could have a huge impact on programmers' productivity. It may even change the culture of programming by shifting human work to formulating problems, with machine learning being the main one responsible for generating and executing codes. ---YS Modern machine learning systems can achieve average human-level performance in popular competitive programming contests.},
  keywords = {ObsCite},
  file = {C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@li2022competitionlevel-Competition-level code generation with AlphaCode.pdf;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@li2022competitionlevel-Competition-level code generation with AlphaCode2.pdf}
}

@inproceedings{li2022hyar,
  title = {{{HyAR}}: {{Addressing Discrete-Continuous Action Reinforcement Learning}} via {{Hybrid Action Representation}}},
  booktitle = ICLR,
  author = {Li, Boyan and Tang, Hongyao and ZHENG, {\relax YAN} and HAO, Jianye and Li, Pengyi and Wang, Zhen and Meng, Zhaopeng and Wang, L. I.},
  year = {2022}
}

@article{li2022pretrained,
  title = {Pre-Trained Language Models for Interactive Decision-Making},
  author = {Li, Shuang and Puig, Xavier and Paxton, Chris and Du, Yilun and Wang, Clinton and Fan, Linxi and Chen, Tao and Huang, De-An and Aky{\"u}rek, Ekin and Anandkumar, Anima and others},
  year = {2022},
  journal = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {31199--31212},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2022pretrained-Pre-trained language models for interactive decision-making.pdf}
}

@inproceedings{li2023behavior1k,
  title = {{{BEHAVIOR-1K}}: {{A Benchmark}} for {{Embodied AI}} with 1,000 {{Everyday Activities}} and {{Realistic Simulation}}},
  booktitle = {Proceedings of {{The}} 6th {{Conference}} on {{Robot Learning}}},
  author = {Li, Chengshu and Zhang, Ruohan and Wong, Josiah and Gokmen, Cem and Srivastava, Sanjana and {Mart{\'i}n-Mart{\'i}n}, Roberto and Wang, Chen and Levine, Gabrael and Lingelbach, Michael and Sun, Jiankai and Anvari, Mona and Hwang, Minjune and Sharma, Manasi and Aydin, Arman and Bansal, Dhruva and Hunter, Samuel and Kim, Kyu-Young and Lou, Alan and Matthews, Caleb R and {Villa-Renteria}, Ivan and Tang, Jerry Huayang and Tang, Claire and Xia, Fei and Savarese, Silvio and Gweon, Hyowon and Liu, Karen and Wu, Jiajun and {Fei-Fei}, Li},
  editor = {Liu, Karen and Kulic, Dana and Ichnowski, Jeff},
  year = {2023},
  month = dec,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {205},
  pages = {80--93},
  publisher = {PMLR},
  abstract = {We present BEHAVIOR-1K, a comprehensive simulation benchmark for human-centered robotics. BEHAVIOR-1K includes two components, guided and motivated by the results of an extensive survey on "what do you want robots to do for you?". The first is the definition of 1,000 everyday activities, grounded in 50 scenes (houses, gardens, restaurants, offices, etc.) with more than 5,000 objects annotated with rich physical and semantic properties. The second is OmniGibson, a novel simulation environment that supports these activities via realistic physics simulation and rendering of rigid bodies, deformable bodies, and liquids. Our experiments indicate that the activities in BEHAVIOR-1K are long-horizon and dependent on complex manipulation skills, both of which remain a challenge for even state-of-the-art robot learning solutions. To calibrate the simulation-to-reality gap of BEHAVIOR-1K, we provide an initial study on transferring solutions learned with a mobile manipulator in a simulated apartment to its real-world counterpart. We hope that BEHAVIOR-1K's human-grounded nature, diversity, and realism make it valuable for embodied AI and robot learning research. Project website: https://behavior.stanford.edu.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2023behavior1k-BEHAVIOR-1K - A Benchmark for Embodied AI with 1,000 Everyday Activities and2.pdf}
}

@article{li2024chain,
  title = {Chain of Thought Empowers Transformers to Solve Inherently Serial Problems},
  author = {Li, Zhiyuan and Liu, Hong and Zhou, Denny and Ma, Tengyu},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.12875},
  eprint = {2402.12875},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2024chain-Chain of thought empowers transformers to solve inherently serial problems.pdf}
}

@article{li2024cogact,
  title = {{{CogACT}}: {{A Foundational Vision-Language-Action Model}} for {{Synergizing Cognition}} and {{Action}} in {{Robotic Manipulation}}},
  author = {Li, Qixiu and Liang, Yaobo and Wang, Zeyu and Luo, Lin and Chen, Xi and Liao, Mozheng and Wei, Fangyun and Deng, Yu and Xu, Sicheng and Zhang, Yizhong and others},
  year = {2024},
  journal = {arXiv preprint arXiv:2411.19650},
  eprint = {2411.19650},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2024cogact-CogACT - A Foundational Vision-Language-Action Model for Synergizing Cognition.pdf}
}

@article{li2024embedding,
  title = {Embedding Multi-Agent Reinforcement Learning into Behavior Trees with Unexpected Interruptions},
  author = {Li, Xianglong and Li, Yuan and Zhang, Jieyuan and Xu, Xinhai and Liu, Donghong},
  year = {2024},
  journal = {Complex \& Intelligent Systems},
  pages = {1--10},
  publisher = {Springer},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2024embedding-Embedding multi-agent reinforcement learning into behavior trees with.pdf}
}

@article{li2024formalllm,
  title = {Formal-Llm: {{Integrating}} Formal Language and Natural Language for Controllable Llm-Based Agents},
  author = {Li, Zelong and Hua, Wenyue and Wang, Hao and Zhu, He and Zhang, Yongfeng},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.00798},
  eprint = {2402.00798},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2024formalllm-Formal-llm - Integrating formal language and natural language for controllable.pdf}
}

@article{li2024generalist,
  title = {Towards {{Generalist Robot Policies}}: {{What Matters}} in {{Building Vision-Language-Action Models}}},
  author = {Li, Xinghang and Li, Peiyan and Liu, Minghuan and Wang, Dong and Liu, Jirong and Kang, Bingyi and Ma, Xiao and Kong, Tao and Zhang, Hanbo and Liu, Huaping},
  year = {2024},
  journal = {arXiv preprint arXiv:2412.14058},
  eprint = {2412.14058},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2024generalist-Towards Generalist Robot Policies - What Matters in Building.pdf}
}

@inproceedings{li2024manipllm,
  title = {Manipllm: {{Embodied}} Multimodal Large Language Model for Object-Centric Robotic Manipulation},
  booktitle = CVPR,
  author = {Li, Xiaoqi and Zhang, Mingxu and Geng, Yiran and Geng, Haoran and Long, Yuxing and Shen, Yan and Zhang, Renrui and Liu, Jiaming and Dong, Hao},
  year = {2024},
  pages = {18061--18070},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2024manipllm-Manipllm - Embodied multimodal large language model for object-centric robotic2.pdf}
}

@misc{li2024review,
  title = {A {{Review}} of {{Prominent Paradigms}} for {{LLM-Based Agents}}: {{Tool Use}} ({{Including RAG}}), {{Planning}}, and {{Feedback Learning}}},
  shorttitle = {A {{Review}} of {{Prominent Paradigms}} for {{LLM-Based Agents}}},
  author = {Li, Xinzhe},
  year = {2024},
  month = sep,
  number = {arXiv:2406.05804},
  eprint = {2406.05804},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-09-19},
  abstract = {Tool use, planning, and feedback learning are currently three prominent paradigms for developing Large Language Model (LLM)-based agents across various tasks. Although numerous frameworks have been devised for each paradigm, their intricate workflows and inconsistent taxonomy create challenges in understanding and reviewing the frameworks across different paradigms. This survey introduces a unified taxonomy to systematically review and discuss these frameworks. Specifically, 1) the taxonomy defines environments/tasks, common LLM-profiled roles (policy models, evaluators, and dynamic models), and universally applicable workflows found in prior work, and 2) it enables a comparison of key perspectives on LMPR implementations and workflow usage across different agent paradigms.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Software Engineering},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2024review-A Review of Prominent Paradigms for LLM-Based Agents - Tool Use (Including RAG),.pdf}
}

@article{li2024softened,
  title = {Softened Symbol Grounding for Neuro-Symbolic Systems},
  author = {Li, Zenan and Yao, Yuan and Chen, Taolue and Xu, Jingwei and Cao, Chun and Ma, Xiaoxing and L{\"u}, Jian},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.00323},
  eprint = {2403.00323},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2024softened-Softened symbol grounding for neuro-symbolic systems.pdf}
}

@article{li2024study,
  title = {A {{Study}} on {{Training}} and {{Developing Large Language Models}} for {{Behavior Tree Generation}}},
  author = {Li, Fu and Wang, Xueying and Li, Bin and Wu, Yunlong and Wang, Yanzhen and Yi, Xiaodong},
  year = {2024},
  journal = {arXiv preprint arXiv:2401.08089},
  eprint = {2401.08089},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2024study-A Study on Training and Developing Large Language Models for Behavior Tree.pdf}
}

@article{li2024unidoormanip,
  title = {Unidoormanip: {{Learning}} Universal Door Manipulation Policy over Large-Scale and Diverse Door Manipulation Environments},
  author = {Li, Yu and Zhang, Xiaojie and Wu, Ruihai and Zhang, Zilong and Geng, Yiran and Dong, Hao and He, Zhaofeng},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.02604},
  eprint = {2403.02604},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2024unidoormanip-Unidoormanip - Learning universal door manipulation policy over large-scale and.pdf}
}

@inproceedings{li2024visionlanguage,
  title = {Vision-Language Foundation Models as Effective Robot Imitators},
  booktitle = ICLR,
  author = {Li, Xinghang and Liu, Minghuan and Zhang, Hanbo and Yu, Cunjun and Xu, Jie and Wu, Hongtao and Cheang, Chilam and Jing, Ya and Zhang, Weinan and Liu, Huaping and others},
  year = {2024},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@li2024visionlanguage-Vision-language foundation models as effective robot imitators.pdf}
}

@article{lian2010simple,
  title = {A Simple Method to Quantify the Morphological Similarity between Signals},
  author = {Lian, Jie and Garner, Garth and Muessig, Dirk and Lang, Volker},
  year = {2010},
  month = feb,
  journal = {Signal Processing},
  volume = {90},
  number = {2},
  pages = {684--688},
  issn = {01651684},
  doi = {10.1016/j.sigpro.2009.07.010},
  urldate = {2022-02-18},
  abstract = {We propose a simple index, termed adaptive signed correlation index (ASCI), to quantify the morphological similarity between signals. The ASCI between two signals is calculated by trichotomizing each signal based on predefined three signal subspaces, then calculating the signed correlation of the trichotomized vectors. Examples are shown to compare ASCI with conventional correlation coefficients with respect to the effects of signal perturbation and additive noise. The ASCI provides a robust and efficient measure of morphological similarity and has particular applications in embedded systems involving biological signal analysis.},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@lian2010simple-A simple method to quantify the morphological similarity between signals.pdf}
}

@inproceedings{liang2011pruning,
  title = {Pruning {{Search Space}} for {{Heuristic Planning}} through {{Action Utility Analysis}}},
  booktitle = {Advances in {{Information Technology}} and {{Education}}},
  author = {Liang, Ruishi and Ma, Hui and Huang, Min},
  editor = {Tan, Honghua and Zhou, Mark},
  year = {2011},
  pages = {78--86},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  abstract = {This paper studies how to prune search space under the Relaxed Planning Graph heuristic framework which is firstly proposed in FF. Based on the observation of relations between action and proposition layers, we present a new and high-quality domain-independent pruning strategy for forward-chaining heuristic planning through Action Utility Analysis. The proposed strategy extracts so-called directly-used actions from relaxed planning graph as promising successors. Its pruning result is in general better than the helpful actions strategy. Our strategy can be used in any progression state space search framework. Experiments in the STRIPS benchmarks of International Planning Competitions (IPC) show that our pruning strategy along with algorithms decreases the search space effectively, and can outperform helpful action strategy of FF.},
  isbn = {978-3-642-22418-8}
}

@inproceedings{liang2022code,
  title = {Code as {{Policies}}: {{Language Model Programs}} for {{Embodied Control}}},
  booktitle = {{{arXiv}} Preprint {{arXiv}}:2209.07753},
  author = {Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  year = {2022},
  eprint = {2209.07753},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@liang2022code-Code as Policies - Language Model Programs for Embodied Control.pdf}
}

@article{liang2023movln,
  title = {{{MO-VLN}}: {{A Multi-Task Benchmark}} for {{Open-set Zero-Shot Vision-and-Language Navigation}}},
  author = {Liang, Xiwen and Ma, Liang and Guo, Shanshan and Han, Jianhua and Xu, Hang and Ma, Shikui and Liang, Xiaodan},
  year = {2023},
  journal = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@liang2023movln-MO-VLN - A Multi-Task Benchmark for Open-set Zero-Shot Vision-and-Language.pdf}
}

@inproceedings{liao2019synthesizing,
  title = {Synthesizing Environment-Aware Activities via Activity Sketches},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Liao, Yuan-Hong and Puig, Xavier and Boben, Marko and Torralba, Antonio and Fidler, Sanja},
  year = {2019},
  pages = {6291--6299},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@liao2019synthesizing-Synthesizing environment-aware activities via activity sketches.pdf}
}

@inproceedings{libardi2020guided,
  title = {Guided {{Exploration}} with {{Proximal Policy Optimization}} Using a {{Single Demonstration}}},
  booktitle = ICML,
  author = {Libardi, Gabriele and Fabritiis, Gianni De},
  year = {2020},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@libardi2020guided-Guided Exploration with Proximal Policy Optimization using a Single.pdf}
}

@phdthesis{Lijiyuyitugongxia,
  title = {基于意图共享的分散式任务规划方法研究},
  author = {李, 明龙},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@Lijiyuyitugongxia-基于意图共享的分散式任务规划方法研究.pdf}
}

@phdthesis{Lijiyuyitugongxiaa,
  title = {基于意图共享的分散式任务规划方法研究},
  author = {李, 明龙}
}

@inproceedings{lillicrap2016continuous,
  title = {Continuous Control with Deep Reinforcement Learning},
  booktitle = ICLR,
  author = {Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  year = {2016},
  pages = {14},
  abstract = {We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies ``end-to-end'': directly from raw pixel inputs.},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@lillicrap2016continuous-Continuous control with deep reinforcement learning.pdf}
}

@inproceedings{lim2010evolving,
  title = {Evolving Behaviour Trees for the Commercial Game {{DEFCON}}},
  booktitle = {Applications of {{Evolutionary Computation}}: {{EvoApplicatons}} 2010: {{EvoCOMPLEX}}, {{EvoGAMES}}, {{EvoIASP}}, {{EvoIN}}TEL{{LIGENCE}}, {{EvoNUM}}, and {{EvoSTOC}}, {{Istanbul}}, {{Turkey}}, {{April}} 7-9, 2010, {{Proceedings}}, {{Part I}}},
  author = {Lim, Chong-U and Baumgarten, Robin and Colton, Simon},
  year = {2010},
  pages = {100--110},
  publisher = {Springer},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@lim2010evolving-Evolving behaviour trees for the commercial game DEFCON.pdf}
}

@article{LiMingLong2019mianxiangzainans,
  title = {面向灾难搜索救援场景的空地协同无人群体任务规划研究},
  author = {{李明龙} and {杨文婧} and {易晓东} and {王彦臻} and {王戟}},
  year = {2019},
  journal = {机械工程学报},
  number = {第11期},
  pages = {1--9},
  keywords = {ObsCite,team paper},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@LiMingLong2019mianxiangzainans-面向灾难搜索救援场景的空地协同无人群体任务规划研究.pdf}
}

@article{lin2023addressing,
  title = {Addressing Long-Horizon Tasks by Integrating Program Synthesis and State Machines},
  author = {Lin, Yu-An and Lee, Chen-Tao and Liu, Guan-Ting and Cheng, Pu-Jen and Sun, Shao-Hua},
  year = {2023},
  journal = {arXiv preprint arXiv:2311.15960},
  eprint = {2311.15960},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@lin2023addressing-Addressing long-horizon tasks by integrating program synthesis and state.pdf}
}

@inproceedings{lin2023grounded,
  title = {On Grounded Planning for Embodied Tasks with Language Models},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Lin, Bill Yuchen and Huang, Chengsong and Liu, Qian and Gu, Wenda and Sommerer, Sam and Ren, Xiang},
  year = {2023},
  volume = {37},
  pages = {13192--13200},
  urldate = {2024-01-02},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@lin2023grounded-On grounded planning for embodied tasks with language models.pdf}
}

@inproceedings{lin2023swiftsage,
  title = {{{SwiftSage}}: {{A Generative Agent}} with {{Fast}} and {{Slow Thinking}} for {{Complex Interactive Tasks}}},
  booktitle = NeurIPS,
  author = {Lin, Bill Yuchen and Fu, Yicheng and Yang, Karina and Brahman, Faeze and Huang, Shiyu and Bhagavatula, Chandra and Ammanabrolu, Prithviraj and Choi, Yejin and Ren, Xiang},
  editor = {Oh, A. and Neumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.},
  year = {2023},
  volume = {36},
  pages = {23813--23825},
  publisher = {Curran Associates, Inc.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@lin2023swiftsage-SwiftSage - A Generative Agent with Fast and Slow Thinking for Complex.pdf}
}

@misc{lin2024advances,
  title = {Advances in {{Embodied Navigation Using Large Language Models}}: {{A Survey}}},
  shorttitle = {Advances in {{Embodied Navigation Using Large Language Models}}},
  author = {Lin, Jinzhou and Gao, Han and Feng, Xuxiang and Xu, Rongtao and Wang, Changwei and Zhang, Man and Guo, Li and Xu, Shibiao},
  year = {2024},
  month = jun,
  number = {arXiv:2311.00530},
  eprint = {2311.00530},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-09-19},
  abstract = {In recent years, the rapid advancement of Large Language Models (LLMs) such as the Generative Pre-trained Transformer (GPT) has attracted increasing attention due to their potential in a variety of practical applications. The application of LLMs with Embodied Intelligence has emerged as a significant area of focus. Among the myriad applications of LLMs, navigation tasks are particularly noteworthy because they demand a deep understanding of the environment and quick, accurate decision-making. LLMs can augment embodied intelligence systems with sophisticated environmental perception and decision-making support, leveraging their robust language and image-processing capabilities. This article offers an exhaustive summary of the symbiosis between LLMs and embodied intelligence with a focus on navigation. It reviews state-of-the-art models, research methodologies, and assesses the advantages and disadvantages of existing embodied navigation models and datasets. Finally, the article elucidates the role of LLMs in embodied intelligence, based on current research, and forecasts future directions in the field. A comprehensive list of studies in this survey is available at https://github.com/Rongtao-Xu/Awesome-LLM-EN.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@lin2024advances-Advances in Embodied Navigation Using Large Language Models - A Survey.pdf}
}

@incollection{lindenmayer1992grammars,
  title = {Grammars of Development: Discrete-State Models for Growth, Differentiation, and Gene Expression in Modular Organisms},
  booktitle = {Lindenmayer Systems},
  author = {Lindenmayer, Aristid and J{\"u}rgensen, Hans},
  year = {1992},
  pages = {3--21},
  publisher = {Springer}
}

@article{ling2020character,
  title = {Character Controllers Using Motion {{VAEs}}},
  author = {Ling, Hung Yu and Zinno, Fabio and Cheng, George and Van De Panne, Michiel},
  year = {2020},
  month = aug,
  journal = TOG,
  volume = {39},
  number = {4},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3386569.3392422},
  urldate = {2022-02-28},
  abstract = {A fundamental problem in computer animation is that of realizing purposeful and realistic human movement given a sufficiently-rich set of motion capture clips. We learn data-driven generative models of human movement using autoregressive conditional variational autoencoders, or Motion VAEs. The latent variables of the learned autoencoder define the action space for the movement and thereby govern its evolution over time. Planning or control algorithms can then use this action space to generate desired motions. In particular, we use deep reinforcement learning to learn controllers that achieve goal-directed movements. We demonstrate the effectiveness of the approach on multiple tasks. We further evaluate system-design choices and describe the current limitations of Motion VAEs. CCS Concepts: {$\bullet$} Computing methodologies {$\rightarrow$} Motion capture; Reinforcement learning.},
  langid = {english},
  keywords = {neural network},
  annotation = {TOG},
  file = {C:\Users\lenovo\Zotero\storage\2J4IRPFU\Ling_2020_Character controllers using motion VAEs.pdf}
}

@article{lipson2000automatic,
  title = {Automatic Design and Manufacture of Robotic Lifeforms},
  author = {Lipson, Hod and Pollack, Jordan B.},
  year = {2000},
  journal = {Nature},
  volume = {406},
  number = {6799},
  pages = {974--978},
  issn = {1476-4687},
  keywords = {ObsCite},
  annotation = {利用可变长度的圆柱形部件构建可物理可实现的进化机器人},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@lipson2000automatic-Automatic design and manufacture of robotic lifeforms.pdf}
}

@article{liu2012terrain,
  title = {Terrain Runner: Control, Parameterization, Composition, and Planning for Highly Dynamic Motions},
  shorttitle = {Terrain Runner},
  author = {Liu, Libin and Yin, KangKang and {van de Panne}, Michiel and Guo, Baining},
  year = {2012},
  month = nov,
  journal = TOG,
  volume = {31},
  number = {6},
  pages = {1--10},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/2366145.2366173},
  urldate = {2022-06-10},
  abstract = {In this paper we learn the skills required by real-time physics-based avatars to perform parkour-style fast terrain crossing using a mix of running, jumping, speed-vaulting, and drop-rolling. We begin with a single motion capture example of each skill and then learn reduced-order linear feedback control laws that provide robust execution of the motions during forward dynamic simulation. We then parameterize each skill with respect to the environment, such as the height of obstacles, or with respect to the task parameters, such as running speed and direction. We employ a continuation process to achieve the required parameterization of the motions and their affine feedback laws. The continuation method uses a predictor-corrector method based on radial basis functions. Lastly, we build control laws specific to the sequential composition of different skills, so that the simulated character can robustly transition to obstacle clearing maneuvers from running whenever obstacles are encountered. The learned transition skills work in tandem with a simple online step-based planning algorithm, and together they robustly guide the character to achieve a state that is well-suited for the chosen obstacle-clearing motion.},
  langid = {english},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\7NVJ9HBW\\2012 - TOG - Terrain runner.mov;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@liu2012terrain-Terrain runner - control, parameterization, composition, and planning for highly.pdf}
}

@article{liu2016guided,
  title = {Guided {{Learning}} of {{Control Graphs}} for {{Physics-Based Characters}}},
  author = {Liu, Libin and Panne, Michiel Van De and Yin, Kangkang},
  year = {2016},
  month = may,
  journal = TOG,
  volume = {35},
  number = {3},
  issn = {0730-0301},
  doi = {10.1145/2893476},
  abstract = {The difficulty of developing control strategies has been a primary bottleneck in the adoption of physics-based simulations of human motion. We present a method for learning robust feedback strategies around given motion capture clips as well as the transition paths between clips. The output is a control graph that supports real-time physics-based simulation of multiple characters, each capable of a diverse range of robust movement skills, such as walking, running, sharp turns, cartwheels, spin-kicks, and flips. The control fragments that compose the control graph are developed using guided learning. This leverages the results of open-loop sampling-based reconstruction in order to produce state-action pairs that are then transformed into a linear feedback policy for each control fragment using linear regression. Our synthesis framework allows for the development of robust controllers with a minimal amount of prior knowledge.},
  keywords = {control graphs,guided policy search,human simulation,Motion control,ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2016guided-Guided Learning of Control Graphs for Physics-Based Characters.pdf}
}

@inproceedings{liu2017impact,
  title = {The Impact of Module Morphologies on Modular Robots},
  booktitle = {2017 18th {{International Conference}} on {{Advanced Robotics}} ({{ICAR}})},
  author = {Liu, Ceyue and Liu, Jiangong and Moreno, Rodrigo and Veenstra, Frank and Faina, Andres},
  year = {2017},
  pages = {237--243},
  publisher = {IEEE}
}

@article{liu2018reinforcement,
  title = {Reinforcement Learning on Web Interfaces Using Workflow-Guided Exploration},
  author = {Liu, Evan Zheran and Guu, Kelvin and Pasupat, Panupong and Shi, Tianlin and Liang, Percy},
  year = {2018},
  journal = {arXiv preprint arXiv:1802.08802},
  eprint = {1802.08802},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2018reinforcement-Reinforcement learning on web interfaces using workflow-guided exploration.pdf}
}

@inproceedings{liu2018treegan,
  title = {{{TreeGAN}}: {{Syntax-Aware Sequence Generation}} with {{Generative Adversarial Networks}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Data Mining}} ({{ICDM}})},
  author = {Liu, Xinyue and Kong, Xiangnan and Liu, Lei and Chiang, Kuorong},
  year = {2018},
  pages = {1140--1145},
  doi = {10.1109/ICDM.2018.00149},
  keywords = {Context-Free Language,Gallium nitride,Generative adversarial networks,Generative Adversarial Networks,Generators,Grammar,Production,Sequence Generation,Syntactics,Training,Tree Generation},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2018treegan-TreeGAN - Syntax-Aware Sequence Generation with Generative Adversarial Networks.pdf}
}

@article{liu2019efficient,
  title = {Efficient Batch-Mode Reinforcement Learning Using Extreme Learning Machines},
  author = {Liu, J. and Zuo, L. and Xu, X. and Zhang, X. and Liu, X.},
  year = {2019},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
  volume = {PP},
  number = {99},
  pages = {1--14}
}

@inproceedings{liu2020state,
  title = {State {{Alignment-based Imitation Learning}}},
  booktitle = ICLR,
  author = {Liu, Fangchen and Ling, Zhan and Mu, Tongzhou and Su, Hao},
  year = {2020},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2020state-State Alignment-based Imitation Learning.pdf}
}

@article{liu2021survey,
  title = {A {{Survey}} on {{Evolutionary Neural Architecture Search}}.},
  author = {Liu, Yuqiao and Sun, Yanan and Xue, Bing and Zhang, Mengjie and Yen, Gary G. and Tan, Kay Chen},
  year = {2021},
  month = aug,
  journal = TPAMI,
  volume = {PP},
  address = {United States},
  issn = {2162-2388 2162-237X},
  doi = {10.1109/TNNLS.2021.3100554},
  abstract = {Deep neural networks (DNNs) have achieved great success in many applications. The architectures of DNNs play a crucial role in their performance, which is usually  manually designed with rich expertise. However, such a design process is  labor-intensive because of the trial-and-error process and also not easy to realize  due to the rare expertise in practice. Neural architecture search (NAS) is a type of  technology that can design the architectures automatically. Among different methods  to realize NAS, the evolutionary computation (EC) methods have recently gained much  attention and success. Unfortunately, there has not yet been a comprehensive summary  of the EC-based NAS algorithms. This article reviews over 200 articles of most  recent EC-based NAS methods in light of the core components, to systematically  discuss their design principles and justifications on the design. Furthermore,  current challenges and issues are also discussed to identify future research in this  emerging field.},
  langid = {english},
  pmid = {34357870},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2021survey-A Survey on Evolutionary Neural Architecture Search.pdf}
}

@article{liu2022benchmarking,
  title = {Benchmarking and Optimization of Robot Motion Planning with Motion Planning Pipeline},
  author = {Liu, Shuai and Liu, Pengcheng},
  year = {2022},
  month = jan,
  journal = {The International Journal of Advanced Manufacturing Technology},
  volume = {118},
  number = {3},
  pages = {949--961},
  issn = {1433-3015},
  doi = {10.1007/s00170-021-07985-5},
  abstract = {Algorithms have been designed for robot motion planning with various adaptability to different problems. However, how to choose the most suitable planner in a scene has always been a problem worthy of research. This paper aims to find the most suitable motion planner for each query under three different scenes and six different queries. The work lies in optimization of sampling-based motion planning algorithms through motion planning pipeline and planning request adapter. The idea is to use the pre-processing of the planning request adapter, to run OMPL as a pre-processer for the optimized CHOMP or STOMP algorithm, and connect through the motion planning pipeline, to realize the optimization of the motion trajectory. The optimized trajectories are compared with original trajectories through benchmarking. The benchmarking determines the most suitable motion planning algorithm for different scenarios and different queries. Experimental results show that after optimization, the planning time of the algorithm is longer, but the efficiency is significantly improved. In the low-complexity scenes, STOMP optimizes the sampling algorithm very well, improves the trajectory quality greatly, and has a higher success rate. CHOMP also has a good optimization of the sampling algorithm, but it reduces the success rate of the original algorithm. However, in more complex scenes, optimization performance of the two optimization methods may not be as good as the original algorithm. In future work, we need to find better algorithms and better optimization algorithms to tackle with complex scenes.}
}

@inproceedings{liu2022finrlmeta,
  title = {{{FinRL-Meta}}: {{Market Environments}} and {{Benchmarks}} for {{Data-Driven Financial Reinforcement Learning}}},
  booktitle = NeurIPS,
  author = {Liu, Xiao-Yang and Xia, Ziyi and Rui, Jingyang and Gao, Jiechao and Yang, Hongyang and Zhu, Ming and Wang, Christina Dan and Wang, Zhaoran and Guo, Jian},
  year = {2022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2022finrlmeta-FinRL-Meta - Market Environments and Benchmarks for Data-Driven Financial.pdf}
}

@article{liu2022goalconditioned,
  title = {Goal-{{Conditioned Reinforcement Learning}}: {{Problems}} and {{Solutions}}},
  shorttitle = {Goal-{{Conditioned Reinforcement Learning}}},
  author = {Liu, Minghuan and Zhu, Menghui and Zhang, Weinan},
  year = {2022},
  month = sep,
  journal = {arXiv},
  eprint = {2201.08299},
  primaryclass = {cs},
  urldate = {2022-11-07},
  abstract = {Goal-conditioned reinforcement learning (GCRL), related to a set of complex RL problems, trains an agent to achieve different goals under particular scenarios. Compared to the standard RL solutions that learn a policy solely depending on the states or observations, GCRL additionally requires the agent to make decisions according to different goals. In this survey, we provide a comprehensive overview of the challenges and algorithms for GCRL. Firstly, we answer what the basic problems are studied in this field. Then, we explain how goals are represented and present how existing solutions are designed from different points of view. Finally, we make the conclusion and discuss potential future prospects that recent researches focus on.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2022goalconditioned-Goal-Conditioned Reinforcement Learning - Problems and Solutions.pdf}
}

@inproceedings{liu2022herd,
  title = {{{HERD}}: {{Continuous Human-to-Robot Evolution}} for {{Learning}} from {{Human Demonstration}}},
  booktitle = CoRL,
  author = {Liu, Xingyu and Pathak, Deepak and Kitani, Kris M},
  year = {2022},
  keywords = {ObsCite}
}

@inproceedings{liu2022revolver,
  title = {{{REvolveR}}: {{Continuous}} Evolutionary Models for Robot-to-Robot Policy Transfer},
  booktitle = ICML,
  author = {Liu, Xingyu and Pathak, Deepak and Kitani, Kris},
  editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesv{\'a}ri, Csaba and Niu, Gang and Sabato, Sivan},
  year = {2022},
  series = {Proceedings of Machine Learning Research},
  volume = {162},
  pages = {13995--14007},
  publisher = {PMLR},
  keywords = {ObsCite},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\MTIM64AM\\revolver_supp.mp4;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@liu2022revolver-REvolveR - Continuous evolutionary models for robot-to-robot policy transfer.pdf}
}

@inproceedings{liu2023biped,
  title = {A {{Biped Robot Learning}} to {{Walk}} like {{Human}} by {{Reinforcement Learning}}},
  booktitle = {International {{Conference}} on {{Advanced Information Science}} and {{System}}},
  author = {Liu, Yi and An, Honglei and Ma, Hongxu},
  year = {2023},
  month = jan,
  series = {{{AISS}} '22},
  pages = {1--5},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3573834.3574484},
  urldate = {2023-05-23},
  abstract = {It's challenging to make a biped robot walk like a human. Many researches have been made such as gait planning, stable walking controller and so on and achieve great progress. Reinforcement learning methods are used in biped robots recently due to their powerful ability to deal with high-dimensional computing problem. However, it's hard to design good reward function to guide the robot to walk and behavior like human. This paper builds a biped robot model and presents a control framework of reinforcement learning based on Isaac Gym simulation platform. The designed reward function considers the velocity tracking, the symmetry of hip angle and leg lifting to simulate human motion. The training process only lasts for 2 hours from the very beginning. The results show that after training the biped robot has a good performance of velocity tracking and attitude control and shows good symmetries in joint angles especially in hip. The results also prove the designed reward function is effective and hopeful to be available on other applications.},
  isbn = {978-1-4503-9793-3},
  keywords = {biped robot,ObsCite,reinforcement learning,reword function,symmetry}
}

@article{liu2023fimo,
  title = {Fimo: {{A}} Challenge Formal Dataset for Automated Theorem Proving},
  author = {Liu, Chengwu and Shen, Jianhao and Xin, Huajian and Liu, Zhengying and Yuan, Ye and Wang, Haiming and Ju, Wei and Zheng, Chuanyang and Yin, Yichun and Li, Lin and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.04295},
  eprint = {2309.04295},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2023fimo-Fimo - A challenge formal dataset for automated theorem proving.pdf}
}

@article{Liu2023jiyuxingtaideju,
  title = {基于形态的具身智能研究: 历史回顾与前沿进展},
  author = {刘, 华平 and 郭, 迪 and 孙, 富春},
  year = {2023},
  journal = {自动化学报},
  volume = {49},
  number = {AAS-CN-2022-0564},
  pages = {1},
  keywords = {ObsCite},
  annotation = {基于形态的具身智能综述},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@Liu2023jiyuxingtaideju-基于形态的具身智能研究 - 历史回顾与前沿进展.pdf}
}

@article{liu2023llm,
  title = {{{LLM}}+{{P}}: {{Empowering Large Language Models}} with {{Optimal Planning Proficiency}}},
  author = {Liu, Bo and Jiang, Yuqian and Zhang, Xiaohan and Liu, Qiang and Zhang, Shiqi and Biswas, Joydeep and Stone, Peter},
  year = {2023},
  journal = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2023llm-LLM+P - Empowering Large Language Models with Optimal Planning Proficiency.pdf}
}

@article{liu2024aligning,
  title = {Aligning {{Cyber Space}} with {{Physical World}}: {{A Comprehensive Survey}} on {{Embodied AI}}},
  author = {Liu, Yang and Chen, Weixing and Bai, Yongjie and Li, Guanbin and Gao, Wen and Lin, Liang},
  year = {2024},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2024aligning-Aligning Cyber Space with Physical World - A Comprehensive Survey on Embodied AI.pdf}
}

@article{liu2024coherent,
  title = {{{COHERENT}}: {{Collaboration}} of {{Heterogeneous Multi-Robot System}} with {{Large Language Models}}},
  author = {Liu, Kehui and Tang, Zixin and Wang, Dong and Wang, Zhigang and Zhao, Bin and Li, Xuelong},
  year = {2024},
  journal = {arXiv preprint arXiv:2409.15146},
  eprint = {2409.15146},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2024coherent-COHERENT - Collaboration of Heterogeneous Multi-Robot System with Large Language.pdf}
}

@article{liu2024large,
  title = {Large {{Language Model-Based Agents}} for {{Software Engineering}}: {{A Survey}}},
  author = {Liu, Junwei and Wang, Kaixin and Chen, Yixuan and Peng, Xin and Chen, Zhenpeng and Zhang, Lingming and Lou, Yiling},
  year = {2024},
  journal = {arXiv preprint arXiv:2409.02977},
  eprint = {2409.02977},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2024large-Large Language Model-Based Agents for Software Engineering - A Survey.pdf}
}

@inproceedings{liu2024moka,
  title = {Moka: {{Open-vocabulary}} Robotic Manipulation through Mark-Based Visual Prompting},
  booktitle = {First {{Workshop}} on {{Vision-Language Models}} for {{Navigation}} and {{Manipulation}} at {{ICRA}} 2024},
  author = {Liu, Fangchen and Fang, Kuan and Abbeel, Pieter and Levine, Sergey},
  year = {2024},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@liu2024moka-Moka - Open-vocabulary robotic manipulation through mark-based visual prompting.pdf}
}

@book{LiZhiTing2002qingshi,
  title = {清史},
  author = {{李治亭}},
  year = {2002},
  publisher = {上海：上海人民出版社}
}

@article{lo2020petlon,
  title = {The Petlon Algorithm to Plan Efficiently for Task-Level-Optimal Navigation},
  author = {Lo, Shih-Yun and Zhang, Shiqi and Stone, Peter},
  year = {2020},
  journal = {Journal of Artificial Intelligence Research},
  volume = {69},
  pages = {471--500},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@lo2020petlon-The petlon algorithm to plan efficiently for task-level-optimal navigation.pdf}
}

@inproceedings{luck2019dataefficient,
  title = {Data-Efficient {{Co-Adaptation}} of {{Morphology}} and {{Behaviour}} with {{Deep Reinforcement Learning}}},
  booktitle = CoRL,
  author = {Luck, Kevin Sebastian and Amor, Heni Ben and Calandra, Roberto},
  year = {2019},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@luck2019dataefficient-Data-efficient Co-Adaptation of Morphology and Behaviour with Deep.pdf}
}

@article{luck2021what,
  title = {What {{Robot}} Do {{I Need}}? {{Fast Co-Adaptation}} of {{Morphology}} and {{Control}} Using {{Graph Neural Networks}}},
  shorttitle = {What {{Robot}} Do {{I Need}}?},
  author = {Luck, Kevin Sebastian and Calandra, Roberto and Mistry, Michael},
  year = {2021},
  month = nov,
  journal = {arXiv},
  eprint = {2111.02371},
  urldate = {2022-02-16},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {embodied intelligence},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\YSPMHGFL\\2021 - arXiv - What Robot do I Need.pptx;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@luck2021what-What Robot do I Need - Fast Co-Adaptation of Morphology and Control using Graph.pdf}
}

@article{luck2021whata,
  title = {What Robot Do {{I}} Need? {{Fast}} Co-Adaptation of Morphology and Control Using Graph Neural Networks},
  author = {Luck, Kevin Sebastian and Calandra, Roberto and Mistry, Michael N.},
  year = {2021},
  journal = {CoRR},
  volume = {abs/2111.02371},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@luck2021whata-What robot do I need - Fast co-adaptation of morphology and control using graph.pdf}
}

@article{lukosevicius2009reservoir,
  title = {Reservoir Computing Approaches to Recurrent Neural Network Training},
  author = {Luko{\v s}evi{\v c}ius, Mantas and Jaeger, Herbert},
  year = {2009},
  journal = {Computer Science Review},
  volume = {3},
  number = {3},
  pages = {127--149},
  publisher = {Elsevier}
}

@inproceedings{lund2003coevolving,
  title = {Co-Evolving {{Control}} and {{Morphology}} with {{LEGO Robots}}},
  booktitle = {Morpho-Functional {{Machines}}: {{The New Species}}},
  author = {Lund, Henrik Hautop},
  editor = {Hara, Fumio and Pfeifer, Rolf},
  year = {2003},
  pages = {59--79},
  publisher = {Springer Japan},
  address = {Tokyo},
  abstract = {The Building Brains and Bodies approach to the design of task-fulfilling robots is introduced. In this approach, focus is on designing both controller and morphology of robots, and it thereby contrasts most research in adaptive robotics that puts emphasis on design of control exclusively. It is possible to co-evolve robot control and morphology in simulation, and this work suggests that there exists important correlations between different body parameters (e.g. wheel base diameter, body size, and sensory range) in order to achieve optimal performance on specific tasks. The evolved morphology can be constructed with LEGO, and the evolved controller can be downloaded to the LEGO MINDSTORMS RCX. Hence, the experiments suggest a path towards automatic building plans for LEGO MINDSTORMS robots. Further, it is possible to manipulate the morphology in a user-guided approach of building modular LEGO robots, which allow children to construct their own robots within 10 minutes. Finally, the experiments give suggestion to new research on building blocks with processing power.},
  isbn = {978-4-431-67869-4}
}

@inproceedings{luo2018neural,
  title = {Neural {{Architecture Optimization}}},
  booktitle = NeurIPS,
  author = {Luo, Renqian and Tian, Fei and Qin, Tao and Chen, Enhong and Liu, Tie-Yan},
  year = {2018},
  pages = {12},
  abstract = {Automatic neural architecture design has shown its potential in discovering powerful neural network architectures. Existing methods, no matter based on reinforcement learning or evolutionary algorithms (EA), conduct architecture search in a discrete space, which is highly inefficient. In this paper, we propose a simple and efficient method to automatic neural architecture design based on continuous optimization. We call this new approach neural architecture optimization (NAO). There are three key components in our proposed approach: (1) An encoder embeds/maps neural network architectures into a continuous space. (2) A predictor takes the continuous representation of a network as input and predicts its accuracy. (3) A decoder maps a continuous representation of a network back to its architecture. The performance predictor and the encoder enable us to perform gradient based optimization in the continuous space to find the embedding of a new architecture with potentially better accuracy. Such a better embedding is then decoded to a network by the decoder. Experiments show that the architecture discovered by our method is very competitive for image classification task on CIFAR-10 and language modeling task on PTB, outperforming or on par with the best results of previous architecture search methods with a significantly reduction of computational resources. Specifically we obtain 2.11\% test set error rate for CIFAR-10 image classification task and 56.0 test set perplexity of PTB language modeling task. The best discovered architectures on both tasks are successfully transferred to other tasks such as CIFAR-100 and WikiText-2. Furthermore, combined with the recent proposed weight sharing mechanism, we discover powerful architecture on CIFAR-10 (with error rate 3.53\%) and on PTB (with test set perplexity 56.6), with very limited computational resources (less than 10 GPU hours) for both tasks.},
  langid = {english},
  keywords = {differentiable,embedding,gradient},
  annotation = {NeurIPS},
  file = {C:\Users\lenovo\Zotero\storage\2UCSCKT7\Luo_2018_Neural Architecture Optimization.pdf}
}

@inproceedings{luo2020learning,
  title = {Learning {{Self-Correctable Policies}} and {{Value Functions}} from {{Demonstrations}} with {{Negative Sampling}}},
  booktitle = ICLR,
  author = {Luo, Yuping and Xu, Huazhe and Ma, Tengyu},
  year = {2020},
  publisher = {OpenReview.net},
  file = {C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@luo2020learning-Learning Self-Correctable Policies and Value Functions from Demonstrations with.pdf;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@luo2020learning-Learning Self-Correctable Policies and Value Functions from Demonstrations with2.pdf}
}

@article{lykov2023llmbrain,
  title = {{{LLM-BRAIn}}: {{AI-driven Fast Generation}} of {{Robot Behaviour Tree}} Based on {{Large Language Model}}},
  author = {Lykov, Artem and Tsetserukou, Dzmitry},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.19352},
  eprint = {2305.19352},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@lykov2023llmbrain-LLM-BRAIn - AI-driven Fast Generation of Robot Behaviour Tree based on Large.pdf}
}

@article{lykov2023llmmars,
  title = {{{LLM-MARS}}: {{Large Language Model}} for {{Behavior Tree Generation}} and {{NLP-enhanced Dialogue}} in {{Multi-Agent Robot Systems}}},
  author = {Lykov, Artem and Dronova, Maria and Naglov, Nikolay and Litvinov, Mikhail and Satsevich, Sergei and Bazhenov, Artem and Berman, Vladimir and Shcherbak, Aleksei and Tsetserukou, Dzmitry},
  year = {2023},
  journal = {arXiv preprint arXiv:2312.09348},
  eprint = {2312.09348},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@lykov2023llmmars-LLM-MARS - Large Language Model for Behavior Tree Generation and NLP-enhanced.pdf}
}

@article{ma2014strong,
  title = {Strong {{Simulation}}: {{Capturing Topology}} in {{Graph Pattern Matching}}},
  author = {Ma, Shuai and Cao, Yang and Fan, Wenfei and Huai, Jinpeng and Wo, Tianyu},
  year = {2014},
  month = jan,
  journal = {ACM Trans. Database Syst.},
  volume = {39},
  number = {1},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {0362-5915},
  doi = {10.1145/2528937},
  abstract = {Graph pattern matching is finding all matches in a data graph for a given pattern graph and is often defined in terms of subgraph isomorphism, an NP-complete problem. To lower its complexity, various extensions of graph simulation have been considered instead. These extensions allow graph pattern matching to be conducted in cubic time. However, they fall short of capturing the topology of data graphs, that is, graphs may have a structure drastically different from pattern graphs they match, and the matches found are often too large to understand and analyze. To rectify these problems, this article proposes a notion of strong simulation, a revision of graph simulation for graph pattern matching. (1) We identify a set of criteria for preserving the topology of graphs matched. We show that strong simulation preserves the topology of data graphs and finds a bounded number of matches. (2) We show that strong simulation retains the same complexity as earlier extensions of graph simulation by providing a cubic-time algorithm for computing strong simulation. (3) We present the locality property of strong simulation which allows us to develop an effective distributed algorithm to conduct graph pattern matching on distributed graphs. (4) We experimentally verify the effectiveness and efficiency of these algorithms using both real-life and synthetic data.},
  keywords = {data locality,dual simulation,graph simulation,ObsCite,Strong simulation,subgraph isomorphism},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ma2014strong-Strong Simulation - Capturing Topology in Graph Pattern Matching.pdf}
}

@article{ma2021diffaqua,
  title = {{{DiffAqua}}: {{A Differentiable Computational Design Pipeline}} for {{Soft Underwater Swimmers}} with {{Shape Interpolation}}},
  author = {Ma, Pingchuan and Du, Tao and Zhang, John Z and Wu, Kui and Spielberg, Andrew and Katzschmann, Robert K and Matusik, Wojciech},
  year = {2021},
  journal = TOG,
  volume = {40},
  number = {4},
  pages = {132},
  publisher = {ACM New York, NY, USA},
  keywords = {ObsCite}
}

@article{ma2024efficient,
  title = {Efficient and Scalable Reinforcement Learning for Large-Scale Network Control},
  author = {Ma, Chengdong and Li, Aming and Du, Yali and Dong, Hao and Yang, Yaodong},
  year = {2024},
  journal = {Nature Machine Intelligence},
  pages = {1--15},
  publisher = {Nature Publishing Group UK London},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ma2024efficient-Efficient and scalable reinforcement learning for large-scale network control.pdf}
}

@article{ma2024when,
  title = {When {{LLMs}} Step into the {{3D World}}: {{A Survey}} and {{Meta-Analysis}} of {{3D Tasks}} via {{Multi-modal Large Language Models}}},
  author = {Ma, Xianzheng and Bhalgat, Yash and Smart, Brandon and Chen, Shuai and Li, Xinghui and Ding, Jian and Gu, Jindong and Chen, Dave Zhenyu and Peng, Songyou and Bian, Jia-Wang and others},
  year = {2024},
  journal = {arXiv preprint arXiv:2405.10255},
  eprint = {2405.10255},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ma2024when-When LLMs step into the 3D World - A Survey and Meta-Analysis of 3D Tasks via.pdf}
}

@book{MaGeLiSi2022niujinrenzhikex,
  title = {牛津认知科学哲学手册(上)},
  author = {马戈利斯, 埃里克},
  year = {2022},
  month = jun,
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@MaGeLiSi2022niujinrenzhikex-牛津认知科学哲学手册(上).pdf}
}

@book{MaGeLiSi2022niujinrenzhikexa,
  title = {牛津认知科学哲学手册(下)},
  author = {马戈利斯, 埃里克},
  year = {2022},
  month = jun,
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@MaGeLiSi2022niujinrenzhikexa-牛津认知科学哲学手册(下).pdf}
}

@article{mahdavi2024leveraging,
  title = {Leveraging {{Environment Interaction}} for {{Automated PDDL Generation}} and {{Planning}} with {{Large Language Models}}},
  author = {Mahdavi, Sadegh and Aoki, Raquel and Tang, Keyi and Cao, Yanshuai},
  year = {2024},
  journal = {arXiv preprint arXiv:2407.12979},
  eprint = {2407.12979},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@mahdavi2024leveraging-Leveraging Environment Interaction for Automated PDDL Generation and Planning.pdf}
}

@inproceedings{makoviychuk2021isaac,
  title = {Isaac {{Gym}}: {{High Performance GPU Based Physics Simulation For Robot Learning}}},
  booktitle = NeurIPS,
  author = {Makoviychuk, Viktor and Wawrzyniak, Lukasz and Guo, Yunrong and Lu, Michelle and Storey, Kier and Macklin, Miles and Hoeller, David and Rudin, Nikita and Allshire, Arthur and Handa, Ankur and State, Gavriel},
  year = {2021},
  pages = {12},
  abstract = {Isaac Gym offers a high performance learning platform to train policies for a wide variety of robotics tasks entirely on GPU. Both physics simulation and neural network policy training reside on GPU and communicate by directly passing data from physics buffers to PyTorch tensors without ever going through CPU bottlenecks. This leads to blazing fast training times for complex robotics tasks on a single GPU with 2-3 orders of magnitude improvements compared to conventional RL training that uses a CPU based simulator and GPUs for neural networks. We host the results and videos at https://sites.google. com/view/isaacgym-nvidia and Isaac Gym can be downloaded at https: //developer.nvidia.com/isaac-gym. The benchmark and environments are available at https://github.com/NVIDIA-Omniverse/IsaacGymEnvs.},
  langid = {english},
  keywords = {ObsCite},
  file = {C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@makoviychuk2021isaac-Isaac Gym - High Performance GPU Based Physics Simulation For Robot Learning.pdf;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@makoviychuk2021isaac-Isaac Gym - High Performance GPU Based Physics Simulation For Robot Learning2.pdf}
}

@inproceedings{mandlekar2021what,
  title = {What Matters in Learning from Offline Human Demonstrations for Robot Manipulation},
  booktitle = CoRL,
  author = {Mandlekar, Ajay and Xu, Danfei and Wong, Josiah and Nasiriany, Soroush and Wang, Chen and Kulkarni, Rohun and {Fei-Fei}, Li and Savarese, Silvio and Zhu, Yuke and {Mart{\'i}n-Mart{\'i}n}, Roberto},
  year = {2021},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@mandlekar2021what-What matters in learning from offline human demonstrations for robot.pdf}
}

@inproceedings{mao2022pdsketch,
  title = {{{PDSketch}}: {{Integrated}} Domain Programming, Learning, and Planning},
  booktitle = NeurIPS,
  author = {Mao, Jiayuan and {Lozano-P{\'e}rez}, Tom{\'a}s and Tenenbaum, Josh and Kaelbling, Leslie},
  year = {2022},
  volume = {35},
  pages = {36972--36984},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@mao2022pdsketch-PDSketch - Integrated domain programming, learning, and planning.pdf}
}

@article{mao2024robomatrix,
  title = {{{RoboMatrix}}: {{A Skill-centric Hierarchical Framework}} for {{Scalable Robot Task Planning}} and {{Execution}} in {{Open-World}}},
  author = {Mao, Weixin and Zhong, Weiheng and Jiang, Zhou and Fang, Dong and Zhang, Zhongyue and Lan, Zihan and Jia, Fan and Wang, Tiancai and Fan, Haoqiang and Yoshie, Osamu},
  year = {2024},
  journal = {arXiv preprint arXiv:2412.00171},
  eprint = {2412.00171},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@mao2024robomatrix-RoboMatrix - A Skill-centric Hierarchical Framework for Scalable Robot Task.pdf}
}

@inproceedings{marbach2005online,
  title = {Online Optimization of Modular Robot Locomotion},
  booktitle = {{{IEEE International Conference Mechatronics}} and {{Automation}}, 2005},
  author = {Marbach, Daniel and Ijspeert, Auke Jan},
  year = {2005},
  volume = {1},
  pages = {248--253},
  publisher = {IEEE}
}

@inproceedings{martin-martin2019variable,
  title = {Variable Impedance Control in End-Effector Space: {{An}} Action Space for Reinforcement Learning in Contact-Rich Tasks},
  booktitle = IROS,
  author = {{Mart{\'i}n-Mart{\'i}n}, Roberto and Lee, Michelle A and Gardner, Rachel and Savarese, Silvio and Bohg, Jeannette and Garg, Animesh},
  year = {2019},
  pages = {1010--1017},
  publisher = {IEEE},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@martin-martin2019variable-Variable impedance control in end-effector space - An action space for.pdf}
}

@book{martin2009clean,
  title = {Clean Code: A Handbook of Agile Software Craftsmanship},
  shorttitle = {Clean Code},
  editor = {Martin, Robert C.},
  year = {2009},
  publisher = {Prentice Hall},
  address = {Upper Saddle River, NJ},
  isbn = {978-0-13-235088-4},
  langid = {english},
  lccn = {QA76.76.D47 C583 2009},
  keywords = {Agile software development,Computer software,Reliability},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@martin2009clean-Clean code - a handbook of agile software craftsmanship.pdf}
}

@article{masterman2024landscape,
  title = {The Landscape of Emerging Ai Agent Architectures for Reasoning, Planning, and Tool Calling: {{A}} Survey},
  author = {Masterman, Tula and Besen, Sandi and Sawtell, Mason and Chao, Alex},
  year = {2024},
  journal = {arXiv preprint arXiv:2404.11584},
  eprint = {2404.11584},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@masterman2024landscape-The landscape of emerging ai agent architectures for reasoning, planning, and.pdf}
}

@article{mateas2002behavior,
  title = {A Behavior Language for Story-Based Believable Agents},
  author = {Mateas, M. and Stern, A.},
  year = {2002},
  month = jul,
  journal = {IEEE Intelligent Systems},
  volume = {17},
  number = {4},
  pages = {39--47},
  issn = {1541-1672},
  doi = {10.1109/MIS.2002.1024751},
  urldate = {2023-08-25},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@mateas2002behavior-A behavior language for story-based believable agents.pdf}
}

@article{mautner2000evolving,
  title = {Evolving Robot Morphology and Control},
  author = {Mautner, Craig and Belew, Richard K.},
  year = {2000},
  month = sep,
  journal = {Artificial Life and Robotics},
  volume = {4},
  number = {3},
  pages = {130--136},
  issn = {1433-5298, 1614-7456},
  doi = {10.1007/BF02481333},
  urldate = {2022-03-01},
  abstract = {Most robotic approaches begin with a fixed robot hardware design and then experiment with control structures. We take a different approach that considers both the robot hardware and the control structure as variables in the evolutionary process. This paper reports the results of experiments which explore the placement of sensors and eflectors around the perimeter of a simulated agent's body, and the neural network (NNet) that controls them.},
  langid = {english},
  keywords = {embodied intelligence},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@mautner2000evolving-Evolving robot morphology and control.pdf}
}

@inproceedings{mazurek2020string,
  title = {String {{Plucking}} and {{Touching Sensing}} Using {{Transmissive Optical Sensors}} for {{Guzheng}}},
  booktitle = {2020 16th {{International Conference}} on {{Control}}, {{Automation}}, {{Robotics}} and {{Vision}} ({{ICARCV}})},
  author = {Mazurek, Przemyslaw and {Oszutowska-Mazurek}, Dorota},
  year = {2020},
  month = dec,
  pages = {1143--1149},
  publisher = {IEEE},
  address = {Shenzhen, China},
  doi = {10.1109/ICARCV50220.2020.9305480},
  urldate = {2022-10-31},
  abstract = {The article presents a solution for recording individual vibrations of the string for the guzheng zither. An optical transmission sensor was used inside which the string vibrates. The analytical solution is presented to describe the string in this type of sensor. The classification of sensors is proposed, which classes are characterized by different properties of vibration conversion into an optical signal. A prototype solution for guzheng is presented. The measuring method allows to register the touch of the string, which is important for further estimation of the string's state.},
  isbn = {978-1-72817-709-0},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@mazurek2020string-String Plucking and Touching Sensing using Transmissive Optical Sensors for.pdf}
}

@article{mcfarlane2018survey,
  title = {A Survey of Exploration Strategies in Reinforcement Learning},
  author = {McFarlane, Roger},
  year = {2018},
  journal = {McGill University},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@mcfarlane2018survey-A survey of exploration strategies in reinforcement learning.pdf}
}

@article{meister2020bestfirst,
  title = {Best-First Beam Search},
  author = {Meister, Clara and Vieira, Tim and Cotterell, Ryan},
  year = {2020},
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {8},
  pages = {795--809},
  publisher = {MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info {\dots}},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@meister2020bestfirst-Best-first beam search.pdf}
}

@article{meng2024llma,
  title = {{{LLM-A}}*: {{Large Language Model Enhanced Incremental Heuristic Search}} on {{Path Planning}}},
  author = {Meng, Silin and Wang, Yiwei and Yang, Cheng-Fu and Peng, Nanyun and Chang, Kai-Wei},
  year = {2024},
  journal = {arXiv preprint arXiv:2407.02511},
  eprint = {2407.02511},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@meng2024llma-LLM-A - Large Language Model Enhanced Incremental Heuristic Search on Path.pdf}
}

@book{mianxiangduixiang,
  title = {C++面向对象多线程编程},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@mianxiangduixiang-C++面向对象多线程编程.pdf}
}

@article{michelioudakis2024online,
  title = {Online Semi-Supervised Learning of Composite Event Rules by Combining Structure and Mass-Based Predicate Similarity},
  author = {Michelioudakis, Evangelos and Artikis, Alexander and Paliouras, Georgios},
  year = {2024},
  journal = {Machine Learning},
  volume = {113},
  number = {3},
  pages = {1445--1481},
  publisher = {Springer},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@michelioudakis2024online-Online semi-supervised learning of composite event rules by combining structure.pdf}
}

@article{mikolov2013efficient,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  year = {2013},
  month = sep,
  journal = {arXiv},
  eprint = {1301.3781},
  urldate = {2022-03-23},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@mikolov2013efficient-Efficient Estimation of Word Representations in Vector Space.pdf}
}

@inproceedings{millane2024nvblox,
  title = {Nvblox: {{Gpu-accelerated}} Incremental Signed Distance Field Mapping},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Millane, Alexander and Oleynikova, Helen and Wirbel, Emilie and Steiner, Remo and Ramasamy, Vikram and Tingdahl, David and Siegwart, Roland},
  year = {2024},
  pages = {2698--2705},
  publisher = {IEEE}
}

@article{miller1995wordnet,
  title = {{{WordNet}}: A Lexical Database for {{English}}},
  author = {Miller, George A},
  year = {1995},
  journal = {Communications of the ACM},
  volume = {38},
  number = {11},
  pages = {39--41},
  publisher = {ACM New York, NY, USA},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@miller1995wordnet-WordNet - a lexical database for English.pdf}
}

@article{minwang2022neural,
  title = {Neural Learning Control for Discrete-Time Nonlinear Systems in Pure-Feedback Form},
  author = {Min WANG, Haotian SHI, Cong WANG, Jun FU},
  year = {2022},
  journal = {SCIENCE CHINA Information Sciences},
  volume = {65},
  number = {2},
  pages = {122206-},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@minwang2022neural-Neural learning control for discrete-time nonlinear systems in pure-feedback.pdf}
}

@article{miriyev2020skills,
  title = {Skills for Physical Artificial Intelligence},
  author = {Miriyev, Aslan and Kova{\v c}, Mirko},
  year = {2020},
  month = nov,
  journal = NMI,
  volume = {2},
  number = {11},
  pages = {658--660},
  issn = {2522-5839},
  doi = {10.1038/s42256-020-00258-y},
  abstract = {Synthesizing robots via physical artificial intelligence is a multidisciplinary challenge for future robotics research. An education methodology is needed for researchers to develop a combination of skills in physical artificial intelligence.}
}

@inproceedings{misra2018mapping,
  title = {Mapping Instructions to Actions in 3d Environments with Visual Goal Prediction},
  booktitle = {Proceedings of the {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Misra, Dipendra and Bennett, Andrew and Blukis, Valts and Niklasson, Eyvind and Shatkhin, Max and Artzi, Yoav},
  year = {2018},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@misra2018mapping-Mapping instructions to actions in 3d environments with visual goal prediction.pdf}
}

@inproceedings{mitchell2019realtime,
  title = {Real-Time Planning as Decision-Making under Uncertainty},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Mitchell, Andrew and Ruml, Wheeler and Spaniol, Fabian and Hoffmann, Jorg and Petrik, Marek},
  year = {2019},
  volume = {33},
  pages = {2338--2345},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@mitchell2019realtime-Real-time planning as decision-making under uncertainty.pdf}
}

@article{mnih2015humanlevel,
  title = {Human-Level Control through Deep Reinforcement Learning},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  year = {2015},
  journal = {Nature},
  volume = {518},
  number = {7540},
  pages = {529--533},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@mnih2015humanlevel-Human-level control through deep reinforcement learning.pdf}
}

@inproceedings{mnih2016asynchronous,
  title = {Asynchronous {{Methods}} for {{Deep Reinforcement Learning}}},
  booktitle = ICML,
  author = {Mnih, Volodymyr and Badia, Adri{\`a} Puigdom{\`e}nech and Mirza, Mehdi and Graves, Alex and Harley, Tim and Lillicrap, Timothy P. and Silver, David and Kavukcuoglu, Koray},
  year = {2016},
  series = {{{ICML}}'16},
  pages = {1928--1937},
  publisher = {JMLR.org},
  address = {New York, NY, USA},
  abstract = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@mnih2016asynchronous-Asynchronous Methods for Deep Reinforcement Learning.pdf}
}

@inproceedings{moreno2020using,
  title = {Using Evolution to Design Modular Robots: {{An}} Empirical Approach to Select Module Designs},
  booktitle = {International {{Conference}} on the {{Applications}} of {{Evolutionary Computation}} ({{Part}} of {{EvoStar}})},
  author = {Moreno, Rodrigo and Faina, Andres},
  year = {2020},
  pages = {276--290},
  publisher = {Springer}
}

@article{morphgrower,
  title = {{{MORPHGROWER}}: {{A SYNCHRONIZED LAYER-BY-LAYER GROWING APPROACH FOR PLAUSIBLE AND DIVERSE NEURONAL MORPHOLOGY GENERATION}}},
  journal = {ArXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@morphgrower-MORPHGROWER - A SYNCHRONIZED LAYER-BY-LAYER GROWING APPROACH FOR PLAUSIBLE AND.pdf}
}

@article{morphological,
  title = {{{MORPHOLOGICAL MAZE}}: {{CONTROL RECONFIGURABLE SOFT ROBOTS WITH FINE-GRAINED MORPHOLOGY CHANGE}}},
  journal = {ArXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@morphological-MORPHOLOGICAL MAZE - CONTROL RECONFIGURABLE SOFT ROBOTS WITH FINE-GRAINED.pdf}
}

@inproceedings{mu2023embodiedgpt,
  title = {{{EmbodiedGPT}}: {{Vision-Language Pre-Training}} via {{Embodied Chain}} of {{Thought}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Mu, Yao and Zhang, Qinglong and Hu, Mengkang and Wang, Wenhai and Ding, Mingyu and Jin, Jun and Wang, Bin and Dai, Jifeng and Qiao, Yu and Luo, Ping},
  editor = {Oh, A. and Naumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.},
  year = {2023},
  volume = {36},
  pages = {25081--25094},
  publisher = {Curran Associates, Inc.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@mu2023embodiedgpt-EmbodiedGPT - Vision-Language Pre-Training via Embodied Chain of Thought.pdf}
}

@article{mu2024robocodex,
  title = {{{RoboCodeX}}: {{Multimodal Code Generation}} for {{Robotic Behavior Synthesis}}},
  author = {Mu, Yao and Chen, Junting and Zhang, Qinglong and Chen, Shoufa and Yu, Qiaojun and Ge, Chongjian and Chen, Runjian and Liang, Zhixuan and Hu, Mengkang and Tao, Chaofan and others},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.16117},
  eprint = {2402.16117},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@mu2024robocodex-RoboCodeX - Multimodal Code Generation for Robotic Behavior Synthesis.pdf}
}

@article{muller2017what,
  title = {What Is Morphological Computation? {{On}} How the Body Contributes to Cognition and Control},
  author = {M{\"u}ller, Vincent C and Hoffmann, Matej},
  year = {2017},
  journal = {Artificial life},
  volume = {23},
  number = {1},
  pages = {1--24},
  publisher = {MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info {\dots}}
}

@article{mundhenk2021symbolic,
  title = {Symbolic Regression via Neural-Guided Genetic Programming Population Seeding},
  author = {Mundhenk, T. Nathan and Landajuela, Mikel and Glatt, Ruben and Santiago, Cl{\'a}udio P. and Faissol, Daniel M. and Petersen, Brenden K.},
  year = {2021},
  journal = {arXiv},
  volume = {abs/2111.00053},
  keywords = {TBD},
  annotation = {Arxiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@mundhenk2021symbolic-Symbolic regression via neural-guided genetic programming population seeding.pdf}
}

@book{murphy2019introduction,
  title = {Introduction to {{AI}} Robotics},
  author = {Murphy, Robin R},
  year = {2019},
  publisher = {MIT press}
}

@inproceedings{nair2015massively,
  title = {Massively {{Parallel Methods}} for {{Deep Reinforcement Learning}}},
  booktitle = ICML,
  author = {Nair, Arun and Srinivasan, Praveen and Blackwell, Sam and Alcicek, Cagdas and Fearon, Rory and De Maria, Alessandro and Panneershelvam, Vedavyas and Suleyman, Mustafa and Beattie, Charles and Petersen, Stig and Legg, Shane and Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David},
  year = {2015},
  month = jul,
  series = {Deep {{Learning Workshop}}},
  urldate = {2022-04-18},
  abstract = {We present the first massively distributed architecture for deep reinforcement learning. This architecture uses four main components: parallel actors that generate new behaviour; parallel learners that are trained from stored experience; a distributed neural network to represent the value function or behaviour policy; and a distributed store of experience. We used our architecture to implement the Deep Q-Network algorithm (DQN) (Mnih et al., 2013). Our distributed algorithm was applied to 49 games from Atari 2600 games from the Arcade Learning Environment, using identical hyperparameters. Our performance surpassed non-distributed DQN in 41 of the 49 games and also reduced the wall-time required to achieve these results by an order of magnitude on most games.},
  langid = {english},
  annotation = {ICML Workshop},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@nair2015massively-Massively Parallel Methods for Deep Reinforcement Learning.pdf}
}

@inproceedings{nair2018overcoming,
  title = {Overcoming {{Exploration}} in {{Reinforcement Learning}} with {{Demonstrations}}},
  booktitle = ICRA,
  author = {Nair, Ashvin and McGrew, Bob and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  year = {2018},
  pages = {6292--6299},
  doi = {10.1109/ICRA.2018.8463162},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@nair2018overcoming-Overcoming Exploration in Reinforcement Learning with Demonstrations.pdf}
}

@misc{nandy2023generalized,
  title = {Generalized {{Causal Tree}} for {{Uplift Modeling}}},
  author = {Nandy, Preetam and Yu, Xiufan and Liu, Wanjun and Tu, Ye and Basu, Kinjal and Chatterjee, Shaunak},
  year = {2023},
  month = dec,
  number = {arXiv:2202.02416},
  eprint = {2202.02416},
  primaryclass = {stat},
  publisher = {arXiv},
  urldate = {2024-09-29},
  abstract = {Uplift modeling is crucial in various applications ranging from marketing and policymaking to personalized recommendations. The main objective is to learn optimal treatment allocations for a heterogeneous population. A primary line of existing work modifies the loss function of the decision tree algorithm to identify cohorts with heterogeneous treatment effects. Another line of work estimates the individual treatment effects separately for the treatment group and the control group using off-the-shelf supervised learning algorithms. The former approach that directly models the heterogeneous treatment effect is known to outperform the latter in practice. However, the existing tree-based methods are mostly limited to a single treatment and a single control use case, except for a handful of extensions to multiple discrete treatments. In this paper, we propose a generalization of tree-based approaches to tackle multiple discrete and continuous-valued treatments. We focus on a generalization of the well-known causal tree algorithm due to its desirable statistical properties, but our generalization technique can be applied to other tree-based approaches as well. The efficacy of our proposed method is demonstrated using experiments and real data examples.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Applications,Statistics - Machine Learning,Statistics - Methodology},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@nandy2023generalized-Generalized Causal Tree for Uplift Modeling.pdf}
}

@article{netanyahu2021phase,
  title = {{{PHASE}}: {{PHysically-grounded Abstract Social Events}} for {{Machine Social Perception}}},
  shorttitle = {{{PHASE}}},
  author = {Netanyahu, Aviv and Shu, Tianmin and Katz, Boris and Barbu, Andrei and Tenenbaum, Joshua B.},
  year = {2021},
  month = mar,
  journal = {arXiv},
  eprint = {2103.01933},
  urldate = {2022-03-24},
  abstract = {The ability to perceive and reason about social interactions in the context of physical environments is core to human social intelligence and human-machine cooperation. However, no prior dataset or benchmark has systematically evaluated physically grounded perception of complex social interactions that go beyond short actions, such as high-fiving, or simple group activities, such as gathering. In this work, we create a dataset of physically-grounded abstract social events, PHASE, that resemble a wide range of real-life social interactions by including social concepts such as helping another agent. PHASE consists of 2D animations of pairs of agents moving in a continuous space generated procedurally using a physics engine and a hierarchical planner. Agents have a limited field of view, and can interact with multiple objects, in an environment that has multiple landmarks and obstacles. Using PHASE, we design a social recognition task and a social prediction task. PHASE is validated with human experiments demonstrating that humans perceive rich interactions in the social events, and that the simulated agents behave similarly to humans. As a baseline model, we introduce a Bayesian inverse planning approach, SIMPLE (SIMulation, Planning and Local Estimation), which outperforms state-of-the-art feedforward neural networks. We hope that PHASE can serve as a difficult new challenge for developing new models that can recognize complex social interactions.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@netanyahu2021phase-PHASE - PHysically-grounded Abstract Social Events for Machine Social Perception.pdf}
}

@inproceedings{neuman2021robomorphic,
  title = {Robomorphic Computing: A Design Methodology for Domain-Specific Accelerators Parameterized by Robot Morphology},
  shorttitle = {Robomorphic Computing},
  booktitle = {Proceedings of the {{ACM International Conference}} on {{Architectural Support}} for {{Programming Languages}} and {{Operating Systems}} ({{ASPLOS}})},
  author = {Neuman, Sabrina M. and Plancher, Brian and Bourgeat, Thomas and Tambe, Thierry and Devadas, Srinivas and Reddi, Vijay Janapa},
  year = {2021},
  month = apr,
  pages = {674--686},
  publisher = {ACM},
  address = {Virtual USA},
  doi = {10.1145/3445814.3446746},
  urldate = {2022-02-18},
  abstract = {Robotics applications have hard time constraints and heavy computational burdens that can greatly benefit from domain-specific hardware accelerators. For the latency-critical problem of robot motion planning and control, there exists a performance gap of at least an order of magnitude between joint actuator response rates and state-of-the-art software solutions. Hardware acceleration can close this gap, but it is essential to define automated hardware design flows to keep the design process agile as applications and robot platforms evolve. To address this challenge, we introduce robomorphic computing: a methodology to transform robot morphology into a customized hardware accelerator morphology. We (i) present this design methodology, using robot topology and structure to exploit parallelism and matrix sparsity patterns in accelerator hardware; (ii) use the methodology to generate a parameterized accelerator design for the gradient of rigid body dynamics, a key kernel in motion planning; (iii) evaluate FPGA and synthesized ASIC implementations of this accelerator for an industrial manipulator robot; and (iv) describe how the design can be automatically customized for other robot models. Our FPGA accelerator achieves speedups of 8{\texttimes} and 86{\texttimes} over CPU and GPU when executing a single dynamics gradient computation. It maintains speedups of 1.9{\texttimes} to 2.9{\texttimes} over CPU and GPU, including computation and I/O round-trip latency, when deployed as a coprocessor to a host CPU for processing multiple dynamics gradient computations. ASIC synthesis indicates an additional 7.2{\texttimes} speedup for single computation latency. We describe how this principled approach generalizes to more complex robot platforms, such as quadrupeds and humanoids, as well as to other computational kernels in robotics, outlining a path forward for future robomorphic computing accelerators.},
  isbn = {978-1-4503-8317-2},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@neuman2021robomorphic-Robomorphic computing - a design methodology for domain-specific accelerators.pdf}
}

@inproceedings{neupane2018geese,
  title = {{{GEESE}}: Grammatical Evolution Algorithm for Evolution of Swarm Behaviors},
  booktitle = GECCO,
  author = {Neupane, Aadesh and Goodrich, Michael A and Mercer, Eric G},
  year = {2018},
  pages = {999--1006},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@neupane2018geese-GEESE - grammatical evolution algorithm for evolution of swarm behaviors.pdf}
}

@inproceedings{neupane2019learning,
  title = {Learning {{Swarm Behaviors}} Using {{Grammatical Evolution}} and {{Behavior Trees}}},
  booktitle = IJCAI,
  author = {Neupane, Aadesh and Goodrich, Michael},
  year = {2019},
  pages = {513--520},
  publisher = {IJCAI Organization},
  keywords = {ObsCite},
  annotation = {IJCAI},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@neupane2019learning-Learning Swarm Behaviors using Grammatical Evolution and Behavior Trees.pdf}
}

@article{neupane2023designing,
  title = {Designing {{Behavior Trees}} from {{Goal-Oriented LTLf Formulas}}},
  author = {Neupane, Aadesh and Goodrich, Michael A},
  year = {2023},
  journal = {arXiv preprint arXiv:2307.06399},
  eprint = {2307.06399},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@neupane2023designing-Designing Behavior Trees from Goal-Oriented LTLf Formulas.pdf}
}

@article{newaz2023decentralized,
  title = {Decentralized Multi-Robot Information Gathering from Unknown Spatial Fields},
  author = {Newaz, Abdullah Al Redwan and Alsayegh, Murtadha and Alam, Tauhidul and Bobadilla, Leonardo},
  year = {2023},
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {5},
  pages = {3070--3077},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@newaz2023decentralized-Decentralized multi-robot information gathering from unknown spatial fields.pdf}
}

@article{newell1956logic,
  title = {The Logic Theory Machine--{{A}} Complex Information Processing System},
  author = {Newell, A. and Simon, H.},
  year = {1956},
  month = sep,
  journal = {IEEE Transactions on Information Theory},
  volume = {2},
  number = {3},
  pages = {61--79},
  issn = {0018-9448},
  doi = {10.1109/TIT.1956.1056797},
  urldate = {2024-09-19},
  abstract = {In this paper we describe a complex information processing system, which we call the logic theory machine, that is capable of discovering proofs for theorems in symbolic logic. This system, in contrast to the systematic algorithms that are ordinarily employed in computation, relies heavily on heuristic methods similar to those that have been observed in human problem solving activity. The specification is written in a. formal language, of the nature of a pseudo-code, that is suitable for coding for digital computers. However, the present paper is concerned ezlusively with specification of the system, and not with its realization in a computer. The,logic theory machine is part of a program of research to understand complex informztion processing systems by specifying and synthesizing a substaniial variety of such systems for empirical study.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@newell1956logic-The logic theory machine--A complex information processing system.pdf}
}

@inproceedings{ng1999policy,
  title = {Policy Invariance under Reward Transformations: {{Theory}} and Application to Reward Shaping},
  booktitle = ICML,
  author = {Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  year = {1999},
  volume = {99},
  pages = {278--287},
  publisher = {Citeseer},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ng1999policy-Policy invariance under reward transformations - Theory and application to.pdf}
}

@inproceedings{nguyen2012computing,
  title = {On Computing Conformant Plans Using Classical Planners: {{A}} Generate-and-Complete Approach},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}}},
  author = {Nguyen, Khoi and Tran, Vien and Son, Tran and Pontelli, Enrico},
  year = {2012},
  volume = {22},
  pages = {190--198},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@nguyen2012computing-On computing conformant plans using classical planners - A generate-and-complete.pdf}
}

@incollection{nicolau2018understanding,
  title = {Understanding {{Grammatical Evolution}}: {{Grammar Design}}},
  shorttitle = {Understanding {{Grammatical Evolution}}},
  booktitle = {Handbook of {{Grammatical Evolution}}},
  author = {Nicolau, Miguel and Agapitos, Alexandros},
  editor = {Ryan, Conor and O'Neill, Michael and Collins, Jj},
  year = {2018},
  pages = {23--53},
  publisher = {Springer International Publishing},
  address = {Cham},
  urldate = {2022-04-21},
  abstract = {A frequently overlooked consideration when using Grammatical Evolution (GE) is grammar design. This is because there is an infinite number of grammars that can specify the same syntax. There are, however, certain aspects of grammar design that greatly affect the speed of convergence and quality of solutions generated with GE. In this chapter, general guidelines for grammar design are presented. These are domain-independent, and can be used when applying GE to any problem. An extensive analysis of their effect and results across a large set of experiments are reported.},
  isbn = {978-3-319-78716-9 978-3-319-78717-6},
  langid = {english},
  annotation = {Handbook},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@nicolau2018understanding-Understanding Grammatical Evolution - Grammar Design.pdf}
}

@inproceedings{nikolova2008route,
  title = {Route Planning under Uncertainty: {{The Canadian}} Traveller Problem.},
  booktitle = AAAI,
  author = {Nikolova, Evdokia and Karger, David R},
  year = {2008},
  pages = {969--974},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@nikolova2008route-Route planning under uncertainty - The Canadian traveller problem.pdf}
}

@inproceedings{ning2020generic,
  title = {A {{Generic Graph-Based Neural Architecture Encoding Scheme}} for {{Predictor-Based NAS}}},
  booktitle = ECCV,
  author = {Ning, Xuefei and Zheng, Yin and Zhao, Tianchen and Wang, Yu and Yang, Huazhong},
  editor = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael},
  year = {2020},
  volume = {12358},
  pages = {189--204},
  publisher = {Springer International Publishing},
  address = {Cham},
  urldate = {2022-03-12},
  abstract = {This work proposes a novel Graph-based neural ArchiTecture Encoding Scheme, a.k.a. GATES, to improve the predictor-based neural architecture search. Specifically, different from existing graphbased schemes, GATES models the operations as the transformation of the propagating information, which mimics the actual data processing of neural architecture. GATES is a more reasonable modeling of the neural architectures, and can encode architectures from both the ``operation on node'' and ``operation on edge'' cell search spaces consistently. Experimental results on various search spaces confirm GATES's effectiveness in improving the performance predictor. Furthermore, equipped with the improved performance predictor, the sample efficiency of the predictorbased neural architecture search (NAS) flow is boosted.},
  isbn = {978-3-030-58600-3 978-3-030-58601-0},
  langid = {english},
  keywords = {architecture encoding},
  annotation = {ECCV},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\IEBA6QKT\\2020 - ECCV - A Generic Graph-Based Neural Architecture Encoding Scheme for Predictor-Based.pptx;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@ning2020generic-A Generic Graph-Based Neural Architecture Encoding Scheme for Predictor-Based.pdf}
}

@inproceedings{ning2021evaluating,
  title = {Evaluating Efficient Performance Estimators of Neural Architecture},
  booktitle = NeurIPS,
  author = {Ning, Xuefei and Tang, Changcheng and Li, Wenshuo and Zhou, Zixuan and Liang, Shuang and Yang, Huazhong and Wang, Yu},
  editor = {Beygelzimer, A. and Dauphin, Y. and Liang, P. and Vaughan, J. Wortman},
  year = {2021},
  keywords = {one-shot,understanding,zero-shot},
  annotation = {NeurIPS},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ning2021evaluating-Evaluating efficient performance estimators of neural architecture.pdf}
}

@inproceedings{ning2023coimitation,
  title = {Co-{{Imitation Learning}} without {{Expert Demonstration}}},
  booktitle = {Workshop on {{Reincarnating Reinforcement Learning}} at {{ICLR}} 2023},
  author = {Ning, Kun-Peng and Xu, Hu and Zhu, Kun and Huang, Sheng-Jun},
  year = {2023},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ning2023coimitation-Co-Imitation Learning without Expert Demonstration.pdf}
}

@inproceedings{ning2023coimitationa,
  title = {Co-{{Imitation Learning}} without {{Expert Demonstration}}},
  booktitle = {Workshop on {{Reincarnating Reinforcement Learning}} at {{ICLR}} 2023},
  author = {Ning, Kun-Peng and Xu, Hu and Zhu, Kun and Huang, Sheng-Jun},
  year = {2023},
  keywords = {ObsCite}
}

@article{noguchi2021tool,
  title = {Tool as {{Embodiment}} for {{Recursive Manipulation}}},
  author = {Noguchi, Yuki and Matsushima, Tatsuya and Matsuo, Yutaka and Gu, Shixiang Shane},
  year = {2021},
  journal = {arXiv},
  keywords = {ObsCite},
  annotation = {将工具作为身体控制的一部分，引入一个额外的状态，用于指示现在应该使用手还是工具},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@noguchi2021tool-Tool as Embodiment for Recursive Manipulation.pdf}
}

@inproceedings{nottingham2023embodied,
  title = {Do {{Embodied Agents Dream}} of {{Pixelated Sheep}}: {{Embodied Decision Making}} Using {{Language Guided World Modelling}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Machine Learning}}},
  author = {Nottingham, Kolby and Ammanabrolu, Prithviraj and Suhr, Alane and Choi, Yejin and Hajishirzi, Hannaneh and Singh, Sameer and Fox, Roy},
  editor = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  year = {2023},
  month = jul,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {202},
  pages = {26311--26325},
  publisher = {PMLR},
  abstract = {Reinforcement learning (RL) agents typically learn tabula rasa, without prior knowledge of the world. However, if initialized with knowledge of high-level subgoals and transitions between subgoals, RL agents could utilize this Abstract World Model (AWM) for planning and exploration. We propose using few-shot large language models (LLMs) to hypothesize an AWM, that will be verified through world experience, to improve sample efficiency of RL agents. Our DECKARD agent applies LLM-guided exploration to item crafting in Minecraft in two phases: (1) the Dream phase where the agent uses an LLM to decompose a task into a sequence of subgoals, the hypothesized AWM; and (2) the Wake phase where the agent learns a modular policy for each subgoal and verifies or corrects the hypothesized AWM. Our method of hypothesizing an AWM with LLMs and then verifying the AWM based on agent experience not only increases sample efficiency over contemporary methods by an order of magnitude but is also robust to and corrects errors in the LLM, successfully blending noisy internet-scale information from LLMs with knowledge grounded in environment dynamics.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@nottingham2023embodied-Do Embodied Agents Dream of Pixelated Sheep - Embodied Decision Making using.pdf}
}

@article{nunemacher2002where,
  title = {Where {{Mathematics Comes From}}: {{How}} the {{Embodied Mind Brings Mathematics}} into {{Being}}},
  shorttitle = {Where {{Mathematics Comes From}}},
  author = {Nunemacher, Jeffrey and Lakoff, George and Nunez, Rafael},
  year = {2002},
  month = aug,
  journal = {The American Mathematical Monthly},
  volume = {109},
  number = {7},
  eprint = {3072449},
  eprinttype = {jstor},
  pages = {672},
  issn = {00029890},
  doi = {10.2307/3072449},
  urldate = {2022-05-23},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@nunemacher2002where-Where Mathematics Comes From - How the Embodied Mind Brings Mathematics into.pdf}
}

@inproceedings{nunes2018monte,
  title = {A {{Monte Carlo}} Tree Search Approach to Learning Decision Trees},
  booktitle = {2018 17th {{IEEE International Conference}} on {{Machine Learning}} and {{Applications}} ({{ICMLA}})},
  author = {Nunes, Cec{\'i}lia and De Craene, Mathieu and Langet, H{\'e}l{\`e}ne and Camara, Oscar and Jonsson, Anders},
  year = {2018},
  pages = {429--435},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@nunes2018monte-A Monte Carlo tree search approach to learning decision trees.pdf}
}

@article{nygaard2021realworld,
  title = {Real-World Embodied {{AI}} through a Morphologically Adaptive Quadruped Robot},
  author = {Nygaard, T{\o}nnes F. and Martin, Charles P. and Torresen, Jim and Glette, Kyrre and Howard, David},
  year = {2021},
  month = may,
  journal = NMI,
  volume = {3},
  number = {5},
  pages = {410--419},
  issn = {2522-5839},
  doi = {10.1038/s42256-021-00320-3},
  urldate = {2022-03-02},
  langid = {english},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@nygaard2021realworld-Real-world embodied AI through a morphologically adaptive quadruped robot.pdf}
}

@article{ogren2022behavior,
  title = {Behavior Trees in Robot Control Systems},
  author = {{\"O}gren, Petter and Sprague, Christopher I},
  year = {2022},
  journal = {Annual Review of Control, Robotics, and Autonomous Systems},
  volume = {5},
  pages = {81--107},
  publisher = {Annual Reviews},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ogren2022behavior-Behavior trees in robot control systems.pdf}
}

@article{ontanon2020overview,
  title = {An Overview of Distance and Similarity Functions for Structured Data},
  author = {Onta{\~n}{\'o}n, Santiago},
  year = {2020},
  month = oct,
  journal = {Artificial Intelligence Review},
  volume = {53},
  number = {7},
  pages = {5309--5351},
  issn = {1573-7462},
  doi = {10.1007/s10462-020-09821-w},
  abstract = {The notions of distance and similarity play a key role in many machine learning approaches, and artificial intelligence in general, since they can serve as an organizing principle by which individuals classify objects, form concepts and make generalizations. While distance functions for propositional representations have been thoroughly studied, work on distance functions for structured representations, such as graphs, frames or logical clauses, has been carried out in different communities and is much less understood. Specifically, a significant amount of work that requires the use of a distance or similarity function for structured representations of data usually employs ad-hoc functions for specific applications. Therefore, the goal of this paper is to provide an overview of this work to identify connections between the work carried out in different areas and point out directions for future work.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ontanon2020overview-An overview of distance and similarity functions for structured data.pdf}
}

@article{openai2023gpt4,
  title = {{{GPT-4 Technical Report}}},
  author = {{OpenAI}},
  year = {2023},
  journal = {ArXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@openai2023gpt4-GPT-4 Technical Report.pdf}
}

@article{oruganti2023iktbt,
  title = {{{IKT-BT}}: {{Indirect Knowledge Transfer Behavior Tree Framework}} for {{Multi-Robot Systems Through Communication Eavesdropping}}},
  author = {Oruganti, Sanjay and Parasuraman, Ramviyas and Pidaparti, Ramana},
  year = {2023},
  journal = {arXiv preprint arXiv:2312.11802},
  eprint = {2312.11802},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@oruganti2023iktbt-IKT-BT - Indirect Knowledge Transfer Behavior Tree Framework for Multi-Robot.pdf}
}

@inproceedings{ouessai2020improving,
  title = {Improving the Performance of Mcts-Based {$M$}rts Agents through Move Pruning},
  booktitle = {2020 {{IEEE Conference}} on {{Games}} ({{CoG}})},
  author = {Ouessai, Abdessamed and Salem, Mohammed and Mora, Antonio M},
  year = {2020},
  pages = {708--715},
  publisher = {IEEE}
}

@inproceedings{ouyang2022training,
  title = {Training Language Models to Follow Instructions with Human Feedback},
  booktitle = NeurIPS,
  author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F and Leike, Jan and Lowe, Ryan},
  editor = {Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
  year = {2022},
  volume = {35},
  pages = {27730--27744},
  publisher = {Curran Associates, Inc.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ouyang2022training-Training language models to follow instructions with human feedback.pdf}
}

@article{oyediran2024integration,
  title = {Integration of {{4D BIM}} and {{Robot Task Planning}}: {{Creation}} and {{Flow}} of {{Construction-Related Information}} for {{Action-Level Simulation}} of {{Indoor Wall Frame Installation}}},
  author = {Oyediran, Hafiz and Turner, William and Kim, Kyungki and Barrows, Matthew},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.03602},
  eprint = {2402.03602},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@oyediran2024integration-Integration of 4D BIM and Robot Task Planning - Creation and Flow of.pdf}
}

@phdthesis{ozkahraman2023multiagent,
  title = {Multi-{{Agent Mission Planning}} and {{Execution}} for {{Small Autonomous Underwater Vehicles}}},
  author = {{\"O}zkahraman, {\"O}zer},
  year = {2023},
  school = {KTH Royal Institute of Technology},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ozkahraman2023multiagent-Multi-Agent Mission Planning and Execution for Small Autonomous Underwater.pdf}
}

@article{packer2023memgpt,
  title = {{{MemGPT}}: {{Towards LLMs}} as {{Operating Systems}}},
  author = {Packer, Charles and Fang, Vivian and Patil, Shishir G and Lin, Kevin and Wooders, Sarah and Gonzalez, Joseph E},
  year = {2023},
  journal = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@packer2023memgpt-MemGPT - Towards LLMs as Operating Systems.pdf}
}

@article{pallagani2022plansformer,
  title = {Plansformer: {{Generating}} Symbolic Plans Using Transformers},
  author = {Pallagani, Vishal and Muppasani, Bharath and Murugesan, Keerthiram and Rossi, Francesca and Horesh, Lior and Srivastava, Biplav and Fabiano, Francesco and Loreggia, Andrea},
  year = {2022},
  journal = {arXiv preprint arXiv:2212.08681},
  eprint = {2212.08681},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@pallagani2022plansformer-Plansformer - Generating symbolic plans using transformers.pdf}
}

@inproceedings{pallagani2024prospects,
  title = {On the Prospects of Incorporating Large Language Models (Llms) in Automated Planning and Scheduling (Aps)},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}}},
  author = {Pallagani, Vishal and Muppasani, Bharath Chandra and Roy, Kaushik and Fabiano, Francesco and Loreggia, Andrea and Murugesan, Keerthiram and Srivastava, Biplav and Rossi, Francesca and Horesh, Lior and Sheth, Amit},
  year = {2024},
  volume = {34},
  pages = {432--444},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@pallagani2024prospects-On the prospects of incorporating large language models (llms) in automated.pdf}
}

@inproceedings{pan2022mate,
  title = {{{MATE}}: {{Benchmarking Multi-Agent Reinforcement Learning}} in {{Distributed Target Coverage Control}}},
  booktitle = NeurIPS,
  author = {Pan, Xuehai and Liu, Mickel and {zhong}, fangwei and Yang, Yaodong and Zhu, Song-Chun and Wang, Yizhou},
  year = {2022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@pan2022mate-MATE - Benchmarking Multi-Agent Reinforcement Learning in Distributed Target.pdf}
}

@article{pan2023logiclm,
  title = {Logic-Lm: {{Empowering}} Large Language Models with Symbolic Solvers for Faithful Logical Reasoning},
  author = {Pan, Liangming and Albalak, Alon and Wang, Xinyi and Wang, William Yang},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.12295},
  eprint = {2305.12295},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@pan2023logiclm-Logic-lm - Empowering large language models with symbolic solvers for faithful.pdf}
}

@article{pan2024unifying,
  title = {Unifying {{Large Language Models}} and {{Knowledge Graphs}}: {{A Roadmap}}},
  author = {Pan, Shirui and Luo, Linhao and Wang, Yufei and Chen, Chen and Wang, Jiapu and Wu, Xindong},
  year = {2024},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {36},
  number = {7},
  pages = {3580--3599},
  doi = {10.1109/TKDE.2024.3352100},
  keywords = {bidirectional reasoning,Chatbots,Cognition,Decoding,generative pre-training,knowledge graphs,Knowledge graphs,large language models,Natural language processing,Predictive models,roadmap,Task analysis,Training},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@pan2024unifying-Unifying Large Language Models and Knowledge Graphs - A Roadmap.pdf}
}

@article{pan2024visionlanguageaction,
  title = {Vision-{{Language-Action Model}} and {{Diffusion Policy Switching Enables Dexterous Control}} of an {{Anthropomorphic Hand}}},
  author = {Pan, Cheng and Junge, Kai and Hughes, Josie},
  year = {2024},
  journal = {arXiv preprint arXiv:2410.14022},
  eprint = {2410.14022},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@pan2024visionlanguageaction-Vision-Language-Action Model and Diffusion Policy Switching Enables Dexterous.pdf}
}

@article{pan2025omnimanip,
  title = {{{OmniManip}}: {{Towards General Robotic Manipulation}} via {{Object-Centric Interaction Primitives}} as {{Spatial Constraints}}},
  author = {Pan, Mingjie and Zhang, Jiyao and Wu, Tianshu and Zhao, Yinghao and Gao, Wenlong and Dong, Hao},
  year = {2025},
  journal = {arXiv preprint arXiv:2501.03841},
  eprint = {2501.03841},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@pan2025omnimanip-OmniManip - Towards General Robotic Manipulation via Object-Centric Interaction.pdf}
}

@inproceedings{panda2021nastransfer,
  title = {{{NASTransfer}}: {{Analyzing Architecture Transferability}} in {{Large Scale Neural Architecture Search}}},
  booktitle = AAAI,
  author = {Panda, Rameswar and Merler, Michele and Jaiswal, Mayoore S and Wu, Hui and Ramakrishnan, Kandan and Finkler, Ulrich and Chen, Chun-Fu Richard and Cho, Minsik and Feris, Rogerio and Kung, David and Bhattacharjee, Bishwaranjan},
  year = {2021},
  pages = {9},
  langid = {english},
  keywords = {ObsCite,transfer},
  annotation = {AAAI},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@panda2021nastransfer-NASTransfer - Analyzing Architecture Transferability in Large Scale Neural.pdf}
}

@inproceedings{pang2022graspnet,
  title = {{{GRASP-Net}}: {{Geometric}} Residual Analysis and Synthesis for Point Cloud Compression},
  booktitle = {Proceedings of the 1st {{International Workshop}} on {{Advances}} in {{Point Cloud Compression}}, {{Processing}} and {{Analysis}}},
  author = {Pang, Jiahao and Lodhi, Muhammad Asad and Tian, Dong},
  year = {2022},
  pages = {11--19}
}

@article{panmate,
  title = {{{MATE}}: {{Benchmarking Multi-Agent Reinforcement Learning}} in {{Distributed Target Coverage Control}}},
  author = {Pan, Xuehai and Liu, Mickel and Zhong, Fangwei and Yang, Yaodong and Zhu, Song-Chun and Wang, Yizhou},
  abstract = {We introduce the Multi-Agent Tracking Environment (MATE), a novel multi-agent environment simulates the target coverage control problems in the real world. MATE hosts an asymmetric cooperative-competitive game consisting of two groups of learning agents---``cameras'' and ``targets''---with opposing interests. Specifically, ``cameras'', a group of directional sensors, are mandated to actively control the directional perception area to maximize the coverage rate of targets. On the other side, ``targets'' are mobile agents that aim to transport cargo between multiple randomly assigned warehouses while minimizing the exposure to the camera sensor networks. To showcase the practicality of MATE, we benchmark the multi-agent reinforcement learning (MARL) algorithms from different aspects, including cooperation, communication, scalability, robustness, and asymmetric self-play. We start by reporting results for cooperative tasks using MARL algorithms (MAPPO, IPPO, QMIX, MADDPG) and the results after augmenting with multi-agent communication protocols (TarMAC, I2C). We then evaluate the effectiveness of the popular self-play techniques (PSRO, fictitious self-play) in an asymmetric zero-sum competitive game. This process of co-evolution between cameras and targets helps to realize a less exploitable camera network. We also observe the emergence of different roles of the target agents while incorporating I2C into target-target communication. MATE is written purely in Python and integrated with OpenAI Gym API to enhance user-friendliness. Our project is released at https://github.com/UnrealTracking/mate.},
  langid = {english}
}

@article{papagiannis2022pruning,
  title = {Pruning {{Stochastic Game Trees Using Neural Networks}} for {{Reduced Action Space Approximation}}},
  author = {Papagiannis, Tasos and Alexandridis, Georgios and Stafylopatis, Andreas},
  year = {2022},
  journal = {Mathematics},
  volume = {10},
  number = {9},
  pages = {1509},
  publisher = {MDPI}
}

@inproceedings{parisotto2016actormimic,
  title = {Actor-{{Mimic}}: {{Deep Multitask}} and {{Transfer Reinforcement Learning}}},
  booktitle = ICLR,
  author = {Parisotto, Emilio and Ba, Lei Jimmy and Salakhutdinov, Ruslan},
  editor = {Bengio, Yoshua and LeCun, Yann},
  year = {2016},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@parisotto2016actormimic-Actor-Mimic - Deep Multitask and Transfer Reinforcement Learning.pdf}
}

@inproceedings{park1994concurrent,
  title = {Concurrent Design Optimization of Mechanical Structure and Control for High Speed Robots},
  booktitle = {American Control Conference},
  author = {Park, J. H. and Asada, H.},
  year = {1994}
}

@inproceedings{park2022generative,
  title = {Generative {{GaitNet}}},
  booktitle = SIGGRAPH,
  author = {Park, Jungnam and Min, Sehee and Chang, Phil Sik and Lee, Jaedong and Park, Moon Seok and Lee, Jehee},
  year = {2022},
  series = {{{SIGGRAPH}} '22},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3528233.3530717},
  abstract = {Understanding the relation between anatomy and gait is key to successful predictive gait simulation. In this paper, we present Generative GaitNet, which is a novel network architecture based on deep reinforcement learning for controlling a comprehensive, full-body, musculoskeletal model with 304 Hill-type musculotendons. The Generative GaitNet is a pre-trained, integrated system of artificial neural networks learned in a 618-dimensional continuous domain of anatomy conditions (e.g., mass distribution, body proportion, bone deformity, and muscle deficits) and gait conditions (e.g., stride and cadence). The pre-trained GaitNet takes anatomy and gait conditions as input and generates a series of gait cycles appropriate to the conditions through physics-based simulation. We will demonstrate the efficacy and expressive power of Generative GaitNet to generate a variety of healthy and pathological human gaits in real-time physics-based simulation.},
  isbn = {978-1-4503-9337-9},
  keywords = {Clinical Gait Analysis,GaitNet,Musculoskeletal Simulation,ObsCite,Predictive Gait Simulation},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@park2022generative-Generative GaitNet.pdf}
}

@article{park2023generative,
  title = {Generative Agents: {{Interactive}} Simulacra of Human Behavior},
  author = {Park, Joon Sung and O'Brien, Joseph C and Cai, Carrie J and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  year = {2023},
  journal = {arXiv preprint arXiv:2304.03442},
  eprint = {2304.03442},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@park2023generative-Generative agents - Interactive simulacra of human behavior.pdf}
}

@inproceedings{parr1997reinforcement,
  title = {Reinforcement {{Learning}} with {{Hierarchies}} of {{Machines}}},
  booktitle = NeurIPS,
  author = {Parr, Ronald and Russell, Stuart},
  editor = {Jordan, M. and Kearns, M. and Solla, S.},
  year = {1997},
  volume = {10},
  publisher = {MIT Press},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@parr1997reinforcement-Reinforcement Learning with Hierarchies of Machines.pdf}
}

@article{pastor2021genetic,
  title = {Genetic {{Optimization}} of a {{Manipulator}}: {{Comparison}} between {{Straight}}, {{Rounded}}, and {{Curved Mechanism Links}}},
  author = {Pastor, Robert and Bobovsk{\`y}, Zdenko and Huczala, Daniel and Grushko, Stefan},
  year = {2021},
  journal = {Applied Sciences},
  volume = {11},
  number = {6},
  pages = {2471},
  publisher = {Multidisciplinary Digital Publishing Institute}
}

@article{pateria2021hierarchical,
  title = {Hierarchical Reinforcement Learning: {{A}} Comprehensive Survey},
  author = {Pateria, Shubham and Subagdja, Budhitama and Tan, Ah-hwee and Quek, Chai},
  year = {2021},
  journal = {ACM Computing Surveys (CSUR)},
  volume = {54},
  number = {5},
  pages = {1--35},
  publisher = {ACM New York, NY, USA},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@pateria2021hierarchical-Hierarchical reinforcement learning - A comprehensive survey.pdf}
}

@inproceedings{pathak2019learning,
  title = {Learning to {{Control Self-Assembling Morphologies}}: {{A Study}} of {{Generalization}} via {{Modularity}}},
  booktitle = NeurIPS,
  author = {Pathak, Deepak and Lu, Christopher and Darrell, Trevor and Isola, Phillip and Efros, Alexei A.},
  editor = {Wallach, Hanna M. and Larochelle, Hugo and Beygelzimer, Alina and {d'Alch{\'e}-Buc}, Florence and Fox, Emily B. and Garnett, Roman},
  year = {2019},
  pages = {2292--2302},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@pathak2019learning-Learning to Control Self-Assembling Morphologies - A Study of Generalization via.pdf}
}

@book{paul1981robot,
  title = {Robot Manipulators: Mathematics, Programming, and Control: The Computer Control of Robot Manipulators},
  author = {Paul, Richard P},
  year = {1981},
  publisher = {Richard Paul},
  keywords = {ObsCite}
}

@inproceedings{paul2002road,
  title = {The Road Less Travelled: Morphology in the Optimization of Biped Robot Locomotion},
  booktitle = IROS,
  author = {Paul, C. and Bongard, J. C.},
  year = {2002}
}

@inproceedings{paulino2022search,
  title = {Search Methods in Motion Planning for Mobile Robots},
  booktitle = {Intelligent {{Systems}} and {{Applications}}: {{Proceedings}} of the 2021 {{Intelligent Systems Conference}} ({{IntelliSys}}) {{Volume}} 3},
  author = {Paulino, Laura and Hannum, Correy and Varde, Aparna S and Conti, Christopher J},
  year = {2022},
  pages = {802--822},
  publisher = {Springer},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@paulino2022search-Search methods in motion planning for mobile robots.pdf}
}

@inproceedings{paxton2019representing,
  title = {Representing Robot Task Plans as Robust Logical-Dynamical Systems},
  booktitle = IROS,
  author = {Paxton, Chris and Ratliff, Nathan and Eppner, Clemens and Fox, Dieter},
  year = {2019},
  pages = {5588--5595},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@paxton2019representing-Representing robot task plans as robust logical-dynamical systems.pdf}
}

@article{peng2015dynamic,
  title = {Dynamic {{Terrain Traversal Skills Using Reinforcement Learning}}},
  author = {Peng, Xue Bin and Berseth, Glen and {van de Panne}, Michiel},
  year = {2015},
  journal = TOG,
  volume = {34},
  number = {4},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {0730-0301},
  doi = {10.1145/2766910},
  abstract = {The locomotion skills developed for physics-based characters most often target flat terrain. However, much of their potential lies with the creation of dynamic, momentum-based motions across more complex terrains. In this paper, we learn controllers that allow simulated characters to traverse terrains with gaps, steps, and walls using highly dynamic gaits. This is achieved using reinforcement learning, with careful attention given to the action representation, non-parametric approximation of both the value function and the policy; epsilon-greedy exploration; and the learning of a good state distance metric. The methods enable a 21-link planar dog and a 7-link planar biped to navigate challenging sequences of terrain using bounding and running gaits. We evaluate the impact of the key features of our skill learning pipeline on the resulting performance.},
  keywords = {computer animation,physics simulation},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\5PQJHD46\\2015 - TOG - Dynamic Terrain Traversal Skills Using Reinforcement Learning.zip;C\:\\Users\\lenovo\\Zotero\\storage\\CSFVZG2M\\2015 - TOG - Dynamic Terrain Traversal Skills Using Reinforcement Learning.mp4;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@peng2015dynamic-Dynamic Terrain Traversal Skills Using Reinforcement Learning.pdf}
}

@article{peng2016terrainadaptive,
  title = {Terrain-Adaptive Locomotion Skills Using Deep Reinforcement Learning},
  author = {Peng, Xue Bin and Berseth, Glen and {van de Panne}, Michiel},
  year = {2016},
  month = jul,
  journal = TOG,
  volume = {35},
  number = {4},
  pages = {1--12},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/2897824.2925881},
  urldate = {2022-02-12},
  langid = {english},
  keywords = {animation,core,locomotion,ObsCite},
  annotation = {TOG},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@peng2016terrainadaptive-Terrain-adaptive locomotion skills using deep reinforcement learning.pdf}
}

@phdthesis{peng2017developing,
  title = {Developing Locomotion Skills with Deep Reinforcement Learning},
  author = {Peng, Xue Bin},
  year = {2017},
  school = {University of British Columbia},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@peng2017developing-Developing locomotion skills with deep reinforcement learning.pdf}
}

@inproceedings{peng2017learning,
  title = {Learning {{Locomotion Skills Using DeepRL}}: {{Does}} the {{Choice}} of {{Action Space Matter}}?},
  booktitle = SIGGRAPH,
  author = {Peng, Xue Bin and {van de Panne}, Michiel},
  year = {2017},
  series = {{{SCA}} '17},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3099564.3099567},
  abstract = {The use of deep reinforcement learning allows for high-dimensional state descriptors, but little is known about how the choice of action representation impacts learning and the resulting performance. We compare the impact of four different action parameterizations (torques, muscle-activations, target joint angles, and target joint-angle velocities) in terms of learning time, policy robustness, motion quality, and policy query rates. Our results are evaluated on a gait-cycle imitation task for multiple planar articulated figures and multiple gaits. We demonstrate that the local feedback provided by higher-level action parameterizations can significantly impact the learning, robustness, and motion quality of the resulting policies.},
  isbn = {978-1-4503-5091-4},
  keywords = {locomotion skills,motion control,ObsCite,physics-based character animation},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@peng2017learning-Learning Locomotion Skills Using DeepRL - Does the Choice of Action Space Matter.pdf}
}

@article{peng2018deepmimic,
  title = {{{DeepMimic}}: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills},
  shorttitle = {{{DeepMimic}}},
  author = {Peng, Xue Bin and Abbeel, Pieter and Levine, Sergey and {van de Panne}, Michiel},
  year = {2018},
  month = aug,
  journal = TOG,
  volume = {37},
  number = {4},
  pages = {1--14},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3197517.3201311},
  urldate = {2022-02-16},
  langid = {english},
  keywords = {ObsCite},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\K5JSF8PD\\2018 - TOG - DeepMimic.pptx;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@peng2018deepmimic-DeepMimic - example-guided deep reinforcement learning of physics-based.pdf}
}

@article{peng2018sfv,
  title = {{{SFV}}: Reinforcement Learning of Physical Skills from Videos},
  shorttitle = {{{SFV}}},
  author = {Peng, Xue Bin and Kanazawa, Angjoo and Malik, Jitendra and Abbeel, Pieter and Levine, Sergey},
  year = {2018},
  month = dec,
  journal = TOG,
  volume = {37},
  number = {6},
  pages = {1--14},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3272127.3275014},
  urldate = {2022-02-28},
  abstract = {Data-driven character animation based on motion capture can produce highly naturalistic behaviors and, when combined with physics simulation, can provide for natural procedural responses to physical perturbations, environmental changes, and morphological discrepancies. Motion capture remains the most popular source of motion data, but collecting mocap data typically requires heavily instrumented environments and actors. In this paper, we propose a method that enables physically simulated characters to learn skills from videos (SFV). Our approach, based on deep pose estimation and deep reinforcement learning, allows data-driven animation to leverage the abundance of publicly available video clips from the web, such as those from YouTube. This has the potential to enable fast and easy design of character controllers simply by querying for video recordings of the desired behavior. The resulting controllers are robust to perturbations, can be adapted to new settings, can perform basic object interactions, and can be retargeted to new morphologies via reinforcement learning. We further demonstrate that our method can predict potential human motions from still images, by forward simulation of learned controllers initialized from the observed pose. Our framework is able to learn a broad range of dynamic skills, including locomotion, acrobatics, and martial arts. (Video               1               )},
  langid = {english},
  annotation = {TOG},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@peng2018sfv-SFV - reinforcement learning of physical skills from videos.pdf}
}

@article{peng2019advantageweighted,
  title = {Advantage-{{Weighted Regression}}: {{Simple}} and {{Scalable Off-Policy Reinforcement Learning}}},
  author = {Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  year = {2019},
  journal = {arXiv},
  pages = {18},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@peng2019advantageweighted-Advantage-Weighted Regression - Simple and Scalable Off-Policy Reinforcement.pdf}
}

@inproceedings{peng2019mcp,
  title = {{{MCP}}: {{Learning Composable Hierarchical Control}} with {{Multiplicative Compositional Policies}}},
  booktitle = NeurIPS,
  author = {Peng, Xue Bin and Chang, Michael and Zhang, Grace and Abbeel, Pieter and Levine, Sergey},
  year = {2019},
  pages = {21},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@peng2019mcp-MCP - Learning Composable Hierarchical Control with Multiplicative Compositional.pdf}
}

@inproceedings{peng2020learning,
  title = {Learning Agile Robotic Locomotion Skills by Imitating Animals},
  booktitle = RSS,
  author = {Peng, Xue Bin and Coumans, Erwin and Zhang, Tingnan and Lee, Tsang-Wei Edward and Tan, Jie and Levine, Sergey},
  year = {2020},
  month = jul,
  doi = {10.15607/RSS.2020.XVI.064},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@peng2020learning-Learning agile robotic locomotion skills by imitating animals.pdf}
}

@article{peng2021amp,
  title = {{{AMP}}: Adversarial Motion Priors for Stylized Physics-Based Character Control},
  shorttitle = {{{AMP}}},
  author = {Peng, Xue Bin and Ma, Ze and Abbeel, Pieter and Levine, Sergey and Kanazawa, Angjoo},
  year = {2021},
  month = aug,
  journal = TOG,
  volume = {40},
  number = {4},
  pages = {1--20},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3450626.3459670},
  urldate = {2022-02-15},
  abstract = {Synthesizing graceful and life-like behaviors for physically simulated characters has been a fundamental challenge in computer animation. Data-driven methods that leverage motion tracking are a prominent class of techniques for producing high fidelity motions for a wide range of behaviors. However, the effectiveness of these tracking-based methods often hinges on carefully designed objective functions, and when applied to large and diverse motion datasets, these methods require significant additional machinery to select the appropriate motion for the character to track in a given scenario. In this work, we propose to obviate the need to manually design imitation objectives and mechanisms for motion selection by utilizing a fully automated approach based on adversarial imitation learning. High-level task objectives that the character should perform can be specified by relatively simple reward functions, while the low-level style of the character's behaviors can be specified by a dataset of unstructured motion clips, without any explicit clip selection or sequencing. For example, a character traversing an obstacle course might utilize a task-reward that only considers forward progress, while the dataset contains clips of relevant behaviors such as running, jumping, and rolling. These motion clips are used to train an adversarial motion prior, which specifies style-rewards for training the character through reinforcement learning (RL). The adversarial RL procedure automatically selects which motion to perform, dynamically interpolating and generalizing from the dataset. Our system produces high-quality motions that are comparable to those achieved by state-of-the-art tracking-based techniques, while also being able to easily accommodate large datasets of unstructured motion clips. Composition of disparate skills emerges automatically from the motion prior, without requiring a high-level motion planner or other task-specific annotations of the motion clips. We demonstrate the effectiveness of our framework on a diverse cast of complex simulated characters and a challenging suite of motor control tasks.},
  langid = {english},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\HTPM3VXH\\2021 - TOG - AMP.pptx;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@peng2021amp-AMP - adversarial motion priors for stylized physics-based character control.pdf}
}

@article{peng2022ase,
  title = {{{ASE}}: {{Large-Scale Reusable Adversarial Skill Embeddings}} for {{Physically Simulated Characters}}},
  author = {Peng, Xue Bin and Guo, Yunrong and Halper, Lina and Levine, Sergey and Fidler, Sanja},
  year = {2022},
  month = jul,
  journal = TOG,
  volume = {41},
  number = {4},
  issn = {0730-0301},
  doi = {10.1145/3528223.3530110},
  abstract = {The incredible feats of athleticism demonstrated by humans are made possible in part by a vast repertoire of general-purpose motor skills, acquired through years of practice and experience. These skills not only enable humans to perform complex tasks, but also provide powerful priors for guiding their behaviors when learning new tasks. This is in stark contrast to what is common practice in physics-based character animation, where control policies are most typically trained from scratch for each task. In this work, we present a large-scale data-driven framework for learning versatile and reusable skill embeddings for physically simulated characters. Our approach combines techniques from adversarial imitation learning and unsupervised reinforcement learning to develop skill embeddings that produce life-like behaviors, while also providing an easy to control representation for use on new downstream tasks. Our models can be trained using large datasets of unstructured motion clips, without requiring any task-specific annotation or segmentation of the motion data. By leveraging a massively parallel GPU-based simulator, we are able to train skill embeddings using over a decade of simulated experiences, enabling our model to learn a rich and versatile repertoire of skills. We show that a single pre-trained model can be effectively applied to perform a diverse set of new tasks. Our system also allows users to specify tasks through simple reward functions, and the skill embedding then enables the character to automatically synthesize complex and naturalistic strategies in order to achieve the task objectives.},
  keywords = {adversarial imitation learning,character animation,ObsCite,reinforcement learning,unsupervised reinforcement learning},
  annotation = {使用对抗技能嵌入方法来学习不同任务间通用技能的学习},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@peng2022ase-ASE - Large-Scale Reusable Adversarial Skill Embeddings for Physically Simulated.pdf}
}

@article{pereira2015framework,
  title = {A Framework for Constrained and Adaptive Behavior-Based Agents},
  author = {Pereira, Renato de Pontes and Engel, Paulo Martins},
  year = {2015},
  journal = {arXiv preprint arXiv:1506.02312},
  eprint = {1506.02312},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@pereira2015framework-A framework for constrained and adaptive behavior-based agents.pdf}
}

@incollection{perez-liebana2018evolving,
  title = {Evolving Behaviour Tree Structures Using Grammatical Evolution},
  booktitle = {Handbook of {{Grammatical Evolution}}},
  author = {{Perez-Liebana}, Diego and Nicolau, Miguel},
  editor = {Ryan, Conor and O'Neill, Michael and Collins, {\relax JJ}},
  year = {2018},
  pages = {433--460},
  publisher = {Springer International Publishing},
  address = {Cham},
  abstract = {Behaviour Trees are control structures with many applications in computer science, including robotics, control systems, and computer games. They allow the specification of controllers from very broad behaviour definitions (close to the root of the tree) down to very specific technical implementations (near the leaves); this allows them to be understood and extended by both behaviour designers and technical programmers. This chapter describes the process of applying Grammatical Evolution (GE) to evolve Behaviour Trees for a real-time video-game: the Mario AI Benchmark. The results obtained show that these structures are quite amenable to artificial evolution using GE, and can provide a good balance between long-term (pathfinding) and short-term (reactiveness to hazards and power-ups) planning within the same structure.},
  isbn = {978-3-319-78717-6},
  annotation = {Handbook},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@perez-liebana2018evolving-Evolving behaviour tree structures using grammatical evolution.pdf}
}

@book{pfeifer2006how,
  title = {How the {{Body Shapes}} the {{Way We Think}}: {{A New View}} of {{Intelligence}}},
  author = {Pfeifer, Rolf and Bongard, Josh},
  year = {2006},
  publisher = {MIT press},
  keywords = {embodied intelligence,ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@pfeifer2006how-How the Body Shapes the Way We Think - A New View of Intelligence.pdf}
}

@article{piloto2022intuitive,
  title = {Intuitive Physics Learning in a Deep-Learning Model Inspired by Developmental Psychology},
  author = {Piloto, Luis S. and Weinstein, Ari and Battaglia, Peter and Botvinick, Matthew},
  year = {2022},
  month = jul,
  journal = {Nature Human Behaviour},
  volume = {6},
  number = {9},
  pages = {1257--1267},
  issn = {2397-3374},
  doi = {10.1038/s41562-022-01394-8},
  urldate = {2022-10-22},
  abstract = {Abstract             `Intuitive physics' enables our pragmatic engagement with the physical world and forms a key component of `common sense' aspects of thought. Current artificial intelligence systems pale in their understanding of intuitive physics, in comparison to even very young children. Here we address this gap between humans and machines by drawing on the field of developmental psychology. First, we introduce and open-source a machine-learning dataset designed to evaluate conceptual understanding of intuitive physics, adopting the violation-of-expectation (VoE) paradigm from developmental psychology. Second, we build a deep-learning system that learns intuitive physics directly from visual data, inspired by studies of visual cognition in children. We demonstrate that our model can learn a diverse set of physical concepts, which depends critically on object-level representations, consistent with findings from developmental psychology. We consider the implications of these results both for AI and for research on human cognition.},
  langid = {english},
  keywords = {ObsCite},
  file = {C:\Users\lenovo\Zotero\storage\6FVKESF8\Piloto_2022_Intuitive physics learning in a deep-learning model inspired by developmental.pdf}
}

@book{poli2008field,
  title = {A Field Guide to Genetic Programming},
  author = {Poli, Riccardo and Langdon, William and Mcphee, Nicholas},
  year = {2008},
  publisher = {Lulu Press}
}

@article{poole2013framework,
  title = {A Framework for Decision-Theoretic Planning {{I}}: {{Combining}} the Situation Calculus, Conditional Plans, Probability and Utility},
  author = {Poole, David L},
  year = {2013},
  journal = {arXiv preprint arXiv:1302.3597},
  eprint = {1302.3597},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@poole2013framework-A framework for decision-theoretic planning I - Combining the situation.pdf}
}

@article{power2021keep,
  title = {Keep It Simple: {{Data-efficient}} Learning for Controlling Complex Systems with Simple Models},
  author = {Power, Thomas and Berenson, Dmitry},
  year = {2021},
  journal = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {2},
  pages = {1184--1191},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@power2021keep-Keep it simple - Data-efficient learning for controlling complex systems with.pdf}
}

@article{pratt2001virtual,
  title = {Virtual Model Control: {{An}} Intuitive Approach for Bipedal Locomotion},
  author = {Pratt, Jerry and Chew, Chee-Meng and Torres, Ann and Dilworth, Peter and Pratt, Gill},
  year = {2001},
  journal = {The International Journal of Robotics Research},
  volume = {20},
  number = {2},
  pages = {129--143},
  publisher = {SAGE Publications},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@pratt2001virtual-Virtual model control - An intuitive approach for bipedal locomotion.pdf}
}

@inproceedings{puig2018virtualhome,
  title = {Virtualhome: {{Simulating}} Household Activities via Programs},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Puig, Xavier and Ra, Kevin and Boben, Marko and Li, Jiaman and Wang, Tingwu and Fidler, Sanja and Torralba, Antonio},
  year = {2018},
  pages = {8494--8502},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@puig2018virtualhome-Virtualhome - Simulating household activities via programs.pdf}
}

@article{puig2023habitat,
  title = {Habitat 3.0: {{A}} Co-Habitat for Humans, Avatars and Robots},
  author = {Puig, Xavier and Undersander, Eric and Szot, Andrew and Cote, Mikael Dallaire and Yang, Tsung-Yen and Partsey, Ruslan and Desai, Ruta and Clegg, Alexander William and Hlavac, Michal and Min, So Yeon and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2310.13724},
  eprint = {2310.13724},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@puig2023habitat-Habitat 3.0 - A co-habitat for humans, avatars and robots.pdf}
}

@inproceedings{puri2021cofrnets,
  title = {{{CoFrNets}}: {{Interpretable}} Neural Architecture Inspired by Continued Fractions},
  booktitle = NeurIPS,
  author = {Puri, Isha and Dhurandhar, Amit and Pedapati, Tejaswini and Shanmugam, Karthikeyan and Wei, Dennis and Varshney, Kush R.},
  editor = {Beygelzimer, A. and Dauphin, Y. and Liang, P. and Vaughan, J. Wortman},
  year = {2021},
  keywords = {architecture},
  annotation = {NeurIPS},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@puri2021cofrnets-CoFrNets - Interpretable neural architecture inspired by continued fractions.pdf}
}

@article{qian2023communicative,
  title = {Communicative Agents for Software Development},
  author = {Qian, Chen and Cong, Xin and Yang, Cheng and Chen, Weize and Su, Yusheng and Xu, Juyuan and Liu, Zhiyuan and Sun, Maosong},
  year = {2023},
  journal = {arXiv preprint arXiv:2307.07924},
  eprint = {2307.07924},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@qian2023communicative-Communicative agents for software development.pdf}
}

@inproceedings{qin2022neorl,
  title = {{{NeoRL}}: {{A Near Real-World Benchmark}} for {{Offline Reinforcement Learning}}},
  booktitle = NeurIPS,
  author = {Qin, Rong-Jun and Zhang, Xingyuan and Gao, Songyi and Chen, Xiong-Hui and Li, Zewen and Zhang, Weinan and Yu, Yang},
  year = {2022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@qin2022neorl-NeoRL - A Near Real-World Benchmark for Offline Reinforcement Learning.pdf}
}

@inproceedings{radosavovic2021stateonly,
  title = {State-{{Only Imitation Learning}} for {{Dexterous Manipulation}}},
  booktitle = IROS,
  author = {Radosavovic, Ilija and Wang, Xiaolong and Pinto, Lerrel and Malik, Jitendra},
  year = {2021},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@radosavovic2021stateonly-State-Only Imitation Learning for Dexterous Manipulation.pdf}
}

@article{raghavan2022generalizability,
  title = {Generalizability of Heterogeneous Treatment Effects Based on Causal Forests Applied to Two Randomized Clinical Trials of Intensive Glycemic Control},
  author = {Raghavan, Sridharan and Josey, Kevin and Bahn, Gideon and Reda, Domenic and Basu, Sanjay and Berkowitz, Seth A. and Emanuele, Nicholas and Reaven, Peter and Ghosh, Debashis},
  year = {2022},
  month = jan,
  journal = {Annals of Epidemiology},
  volume = {65},
  pages = {101--108},
  issn = {10472797},
  doi = {10.1016/j.annepidem.2021.07.003},
  urldate = {2024-09-29},
  abstract = {Purpose: Machine learning is an attractive tool for identifying heterogeneous treatment effects (HTE) of interventions but generalizability of machine learning derived HTE remains unclear. We examined generalizability of HTE detected using causal forests in two similarly designed randomized trials in type 2 diabetes patients. Methods: We evaluated published HTE of intensive versus standard glycemic control on all-cause mortality from the Action to Control Cardiovascular Risk in Diabetes study (ACCORD) in a second trial, the Veterans Affairs Diabetes Trial (VADT). We then applied causal forests to VADT, ACCORD, and pooled data from both studies and compared variable importance and subgroup effects across samples. Results: HTE in ACCORD did not replicate in similar subgroups in VADT, but variable importance was correlated between VADT and ACCORD (Kendall's tau-b 0.75). Applying causal forests to pooled individual-level data yielded seven subgroups with similar HTE across both studies, ranging from risk difference of all-cause mortality of 3.9\% (95\% CI -7.0, -0.8) to 4.7\% (95\% CI 1.8, 7.5). Conclusion: Machine learning detection of HTE subgroups from randomized trials may not generalize across study samples even when variable importance is correlated. Pooling individual-level data may overcome differences in study populations and/or differences in interventions that limit HTE generalizability.},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@raghavan2022generalizability-Generalizability of heterogeneous treatment effects based on causal forests.pdf}
}

@article{rahman2023accelerating,
  title = {Accelerating {{Policy Gradient}} by {{Estimating Value Function}} from {{Prior Computation}} in {{Deep Reinforcement Learning}}},
  author = {Rahman, Md Masudur and Xue, Yexiang},
  year = {2023},
  journal = {arXiv preprint arXiv:2302.01399},
  eprint = {2302.01399},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@rahman2023accelerating-Accelerating Policy Gradient by Estimating Value Function from Prior.pdf}
}

@article{rahwan2019machine,
  title = {Machine Behaviour},
  author = {Rahwan, Iyad and Cebrian, Manuel and Obradovich, Nick and Bongard, Josh and Bonnefon, Jean-Fran{\c c}ois and Breazeal, Cynthia and Crandall, Jacob W. and Christakis, Nicholas A. and Couzin, Iain D. and Jackson, Matthew O. and Jennings, Nicholas R. and Kamar, Ece and Kloumann, Isabel M. and Larochelle, Hugo and Lazer, David and McElreath, Richard and Mislove, Alan and Parkes, David C. and Pentland, Alex `Sandy' and Roberts, Margaret E. and Shariff, Azim and Tenenbaum, Joshua B. and Wellman, Michael},
  year = {2019},
  month = apr,
  journal = {Nature},
  volume = {568},
  number = {7753},
  pages = {477--486},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-019-1138-y},
  urldate = {2022-03-03},
  langid = {english},
  keywords = {behavior,ObsCite},
  annotation = {Nature},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@rahwan2019machine-Machine behaviour.pdf}
}

@inproceedings{raibert1991animation,
  title = {Animation of {{Dynamic Legged Locomotion}}},
  booktitle = SIGGRAPH,
  author = {Raibert, Marc H. and Hodgins, Jessica K.},
  year = {1991},
  series = {{{SIGGRAPH}} '91},
  pages = {349--358},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/122718.122755},
  abstract = {This paper is about the use of control algorithms to animate dynamic legged locomotion. Control could free the animator from specifying the details of joint and limb motion while producing both physically realistic and natural looking results. We implemented computer animations of a biped robot, a quadruped robot, and a kangaroo. Each creature was modeled as a linked set of rigid bodies with compliant actuators at its joints. Control algorithms regulated the running speed, organized use of the legs, and maintained balance. All motions were generated by numerically integrating equations of motion derived from the physical models. The resulting behavior included running at various speeds, traveling with several gaits (run, trot, bound, gallop, and hop), jumping, and traversing simple paths. Whereas the use of control permitted a variety of physically realistic animated behavior to be generated with limited human intervention, the process of designing the control algorithms was not automated: the algorithms were "tweaked" and adjusted for each new creature.},
  isbn = {0-89791-436-8},
  keywords = {computer animation,dynamical simulation,legged locomotion,motion control,physically realistic modeling,robotics},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@raibert1991animation-Animation of Dynamic Legged Locomotion.pdf}
}

@article{raibert1991animationa,
  title = {Animation of {{Dynamic Legged Locomotion}}},
  author = {Raibert, Marc H. and Hodgins, Jessica K.},
  year = {1991},
  journal = {SIGGRAPH Comput. Graph.},
  volume = {25},
  number = {4},
  pages = {349--358},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {0097-8930},
  doi = {10.1145/127719.122755},
  abstract = {This paper is about the use of control algorithms to animate dynamic legged locomotion. Control could free the animator from specifying the details of joint and limb motion while producing both physically realistic and natural looking results. We implemented computer animations of a biped robot, a quadruped robot, and a kangaroo. Each creature was modeled as a linked set of rigid bodies with compliant actuators at its joints. Control algorithms regulated the running speed, organized use of the legs, and maintained balance. All motions were generated by numerically integrating equations of motion derived from the physical models. The resulting behavior included running at various speeds, traveling with several gaits (run, trot, bound, gallop, and hop), jumping, and traversing simple paths. Whereas the use of control permitted a variety of physically realistic animated behavior to be generated with limited human intervention, the process of designing the control algorithms was not automated: the algorithms were "tweaked" and adjusted for each new creature.},
  keywords = {computer animation,dynamical simulation,legged locomotion,motion control,physically realistic modeling,robotics}
}

@article{ramirez2016heuristics,
  title = {Heuristics for Planning, Plan Recognition and Parsing},
  author = {Ramirez, Miquel and Geffner, Hector},
  year = {2016},
  journal = {arXiv preprint arXiv:1605.05807},
  eprint = {1605.05807},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ramirez2016heuristics-Heuristics for planning, plan recognition and parsing.pdf}
}

@article{reed2022generalist,
  title = {A Generalist Agent},
  author = {Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and {Barth-Maron}, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and others},
  year = {2022},
  journal = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@reed2022generalist-A generalist agent.pdf}
}

@book{reflections,
  title = {Reflections on the {{Foundations}} of {{Mathematics}}}
}

@article{ren2020query2box,
  title = {Query2box: {{Reasoning}} over Knowledge Graphs in Vector Space Using Box Embeddings},
  author = {Ren, Hongyu and Hu, Weihua and Leskovec, Jure},
  year = {2020},
  journal = {arXiv preprint arXiv:2002.05969},
  eprint = {2002.05969},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ren2020query2box-Query2box - Reasoning over knowledge graphs in vector space using box embeddings.pdf}
}

@article{ren2022comprehensive,
  title = {A {{Comprehensive Survey}} of {{Neural Architecture Search}}: {{Challenges}} and {{Solutions}}},
  shorttitle = {A {{Comprehensive Survey}} of {{Neural Architecture Search}}},
  author = {Ren, Pengzhen and Xiao, Yun and Chang, Xiaojun and Huang, Po-yao and Li, Zhihui and Chen, Xiaojiang and Wang, Xin},
  year = {2022},
  month = may,
  journal = {ACM Computing Surveys},
  volume = {54},
  number = {4},
  pages = {1--34},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3447582},
  urldate = {2022-03-10},
  abstract = {Deep learning has made substantial breakthroughs in many fields due to its powerful automatic representation capabilities. It has been proven that neural architecture design is crucial to the feature representation of data and the final performance. However, the design of the neural architecture heavily relies on the researchers' prior knowledge and experience. And due to the limitations of humans' inherent knowledge, it is difficult for people to jump out of their original thinking paradigm and design an optimal model. Therefore, an intuitive idea would be to reduce human intervention as much as possible and let the algorithm automatically design the neural architecture.                                Neural Architecture Search                              (               NAS               ) is just such a revolutionary algorithm, and the related research work is complicated and rich. Therefore, a comprehensive and systematic survey on the NAS is essential. Previously related surveys have begun to classify existing work mainly based on the key components of NAS: search space, search strategy, and evaluation strategy. While this classification method is more intuitive, it is difficult for readers to grasp the challenges and the landmark work involved. Therefore, in this survey, we provide a new perspective: beginning with an overview of the characteristics of the earliest NAS algorithms, summarizing the problems in these early NAS algorithms, and then providing solutions for subsequent related research work. In addition, we conduct a detailed and comprehensive analysis, comparison, and summary of these works. Finally, we provide some possible future research directions.},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ren2022comprehensive-A Comprehensive Survey of Neural Architecture Search - Challenges and Solutions.pdf}
}

@article{ren2023rmprt,
  title = {{{RM-PRT}}: {{Realistic Robotic Manipulation Simulator}} and {{Benchmark}} with {{Progressive Reasoning Tasks}}},
  author = {Ren, Pengzhen and Zhang, Kaidong and Zheng, Hetao and Li, Zixuan and Wen, Yuhang and Zhu, Fengda and Ma, Mas and Liang, Xiaodan},
  year = {2023},
  journal = {arXiv:},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ren2023rmprt-RM-PRT - Realistic Robotic Manipulation Simulator and Benchmark with Progressive.pdf}
}

@inproceedings{ren2024survey,
  title = {A {{Survey}} of {{Large Language Models}} for {{Graphs}}},
  booktitle = {Proceedings of the 30th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Ren, Xubin and Tang, Jiabin and Yin, Dawei and Chawla, Nitesh and Huang, Chao},
  year = {2024},
  month = aug,
  series = {{{KDD}} '24},
  volume = {36},
  pages = {6616--6626},
  publisher = {ACM},
  doi = {10.1145/3637528.3671460},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ren2024survey-A Survey of Large Language Models for Graphs.pdf}
}

@article{rengarajan2022reinforcement,
  title = {Reinforcement Learning with Sparse Rewards Using Guidance from Offline Demonstration},
  author = {Rengarajan, Desik and Vaidya, Gargi and Sarvesh, Akshay and Kalathil, Dileep and Shakkottai, Srinivas},
  year = {2022},
  journal = {arXiv preprint arXiv:2202.04628},
  eprint = {2202.04628},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@rengarajan2022reinforcement-Reinforcement learning with sparse rewards using guidance from offline.pdf}
}

@article{richens2024robust,
  title = {Robust Agents Learn Causal World Models},
  author = {Richens, Jonathan and Everitt, Tom},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.10877},
  eprint = {2402.10877},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@richens2024robust-Robust agents learn causal world models.pdf}
}

@inproceedings{rintanen2015impact,
  title = {Impact of Modeling Languages on the Theory and Practice in Planning Research},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Rintanen, Jussi},
  year = {2015},
  volume = {29},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@rintanen2015impact-Impact of modeling languages on the theory and practice in planning research.pdf}
}

@article{risi2021deep,
  title = {Deep {{Innovation Protection}}: {{Confronting}} the {{Credit Assignment Problem}} in {{Training Heterogeneous Neural Architectures}}},
  author = {Risi, Sebastian and Stanley, Kenneth O},
  year = {2021},
  journal = AAAI,
  pages = {9},
  langid = {english},
  keywords = {credit assignment,multiobjective optimization},
  annotation = {AAAI},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@risi2021deep-Deep Innovation Protection - Confronting the Credit Assignment Problem in.pdf}
}

@article{robot2023metaevolve,
  title = {Meta-{{Evolve}}: {{Continuous Robot Evolution}} for {{One-to-many Policy Transfer}}},
  author = {Robot, Meta},
  year = {2023},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@robot2023metaevolve-Meta-Evolve - Continuous Robot Evolution for One-to-many Policy Transfer.pdf}
}

@inproceedings{rocha2022plannie,
  title = {Plannie: {{A Benchmark Framework}} for {{Autonomous Robots Path Planning Algorithms Integrated}} to {{Simulated}} and {{Real Environments}}},
  booktitle = {2022 {{International Conference}} on {{Unmanned Aircraft Systems}} ({{ICUAS}})},
  author = {Rocha, Lidia and Vivaldini, Kelen},
  year = {2022},
  pages = {402--411},
  doi = {10.1109/ICUAS54217.2022.9836102},
  keywords = {Benchmark testing,Heuristic algorithms,Location awareness,Machine learning algorithms,Metaheuristics,Three-dimensional displays,Traveling salesman problems}
}

@inproceedings{rommerman2009robot,
  title = {Robot Design for Space Missions Using Evolutionary Computation},
  booktitle = CEC,
  author = {Rommerman, Malte and Kuhn, Daniel and Kirchner, Frank},
  year = {2009},
  month = may,
  pages = {2098--2105},
  publisher = {IEEE},
  address = {Trondheim, Norway},
  doi = {10.1109/CEC.2009.4983200},
  urldate = {2022-02-18},
  abstract = {In this work, we describe a learning system that uses the CMA-ES method from evolutionary computation to optimize the morphology and the walking patterns for a complex legged robot simultaneously.},
  isbn = {978-1-4244-2958-5 978-1-4244-2959-2},
  langid = {english},
  keywords = {evolution},
  annotation = {CEC},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@rommerman2009robot-Robot design for space missions using evolutionary computation.pdf}
}

@inproceedings{roos2019explainable,
  title = {Explainable {{Robotics Applied}} to {{Bipedal Walking Gait Development}}.},
  booktitle = {{{BNAIC}}/{{BENELEARN}}},
  author = {Roos, Nico and Sun, Zhenglong},
  year = {2019},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@roos2019explainable-Explainable Robotics Applied to Bipedal Walking Gait Development.pdf}
}

@article{rosendo2017tradeoff,
  title = {The Trade-off between Morphology and Control in the Co-Optimized Design of Robots},
  author = {Rosendo, Andre and Von Atzigen, Marco and Iida, Fumiya},
  year = {2017},
  journal = {PloS one},
  volume = {12},
  number = {10},
  pages = {e0186107},
  publisher = {Public Library of Science San Francisco, CA USA}
}

@article{ross2014reinforcement,
  title = {Reinforcement and Imitation Learning via Interactive No-Regret Learning},
  author = {Ross, Stephane and Bagnell, J Andrew},
  year = {2014},
  journal = {arXiv preprint arXiv:1406.5979},
  eprint = {1406.5979},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ross2014reinforcement-Reinforcement and imitation learning via interactive no-regret learning.pdf}
}

@inproceedings{rosser2020sim2real,
  title = {Sim2real Gap Is Non-Monotonic with Robot Complexity for Morphology-in-the-Loop Flapping Wing Design},
  booktitle = ICRA,
  author = {Rosser, Kent and Kok, Jia and Chahl, Javaan and Bongard, Josh},
  year = {2020},
  month = may,
  pages = {7001--7007},
  publisher = {IEEE},
  address = {Paris, France},
  doi = {10.1109/ICRA40945.2020.9196539},
  urldate = {2022-02-18},
  abstract = {Morphology of a robot design is important to its ability to achieve a stated goal and therefore applying machine learning approaches that incorporate morphology in the design space can provide scope for significant advantage. Our study is set in a domain known to be reliant on morphology: flapping wing flight. We developed a parameterised morphology design space that draws features from biological exemplars and apply automated design to produce a set of high performance robot morphologies in simulation. By performing sim2real transfer on a selection, for the first time we measured the shape of the reality gap for variations in design complexity. We found for the flapping wing that the reality gap changes non-monotonically with complexity, suggesting that certain morphology details narrow the gap more than others, and that such details could be identified and further optimised in a future end-to-end automated morphology design process.},
  isbn = {978-1-72817-395-5},
  langid = {english},
  keywords = {embodied intelligence},
  annotation = {ICRA},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@rosser2020sim2real-Sim2real gap is non-monotonic with robot complexity for morphology-in-the-loop.pdf}
}

@inproceedings{rovida2017extended,
  title = {Extended Behavior Trees for Quick Definition of Flexible Robotic Tasks},
  booktitle = IROS,
  author = {Rovida, Francesco and Grossmann, Bjarne and Kr{\"u}ger, Volker},
  year = {2017},
  pages = {6793--6800},
  doi = {10.1109/IROS.2017.8206598},
  abstract = {The requirement of flexibility in the modern industries demands robots that can be efficiently and quickly adapted to different tasks. A way to achieve such a flexible programming paradigm is to instruct robots with task goals and leave planning algorithms to deduct the correct sequence of actions to use in the specific context. A common approach is to connect the skills that realize a semantically defined operation in the planning domain - such as picking or placing an object - to specific executable functions. As a result the skills are treated as independent components, which results into suboptimal execution. In this paper we present an approach where the execution procedures and the planning domain are specified at the same time using solely extended Behavior Trees (eBT), a model formalized and discussed in this paper. At run-time, the robot can use the more abstract skills to plan a sequence using a PDDL planner, expand the sequence into a hierarchical tree, and re-organize it to optimize the time of execution and the use of resources. The optimization is demonstrated on a kitting operation in both simulation and lab environment, showing up to 20\% save in the final execution time.},
  keywords = {autonomous robots,behavior trees,hierarchical task networks,Optimization,planning,Planning,Production facilities,Programming,skills},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@rovida2017extended-Extended behavior trees for quick definition of flexible robotic tasks.pdf}
}

@article{roy2021machine,
  title = {From Machine Learning to Robotics: {{Challenges}} and Opportunities for Embodied Intelligence},
  author = {Roy, Nicholas and Posner, Ingmar and Barfoot, Tim D. and Beaudoin, Philippe and Bengio, Yoshua and Bohg, Jeannette and Brock, Oliver and Depatie, Isabelle and Fox, Dieter and Koditschek, Daniel E. and {Lozano-P{\'e}rez}, Tom{\'a}s and Mansinghka, Vikash and Pal, Christopher J. and Richards, Blake and Sadigh, Dorsa and Schaal, Stefan and Sukhatme, Gaurav S. and Th{\'e}rien, Denis and Toussaint, Marc and {van de Panne}, Michiel},
  year = {2021},
  journal = {arXiv},
  keywords = {core,embodied intelligence},
  annotation = {Arxiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@roy2021machine-From machine learning to robotics - Challenges and opportunities for embodied.pdf}
}

@article{roy2024flap,
  title = {Flap: {{Flow}} Adhering Planning with Constrained Decoding in Llms},
  author = {Roy, Shamik and Sengupta, Sailik and Bonadiman, Daniele and Mansour, Saab and Gupta, Arshit},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.05766},
  eprint = {2403.05766},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@roy2024flap-Flap - Flow adhering planning with constrained decoding in llms.pdf}
}

@article{roziere2023code,
  title = {Code {{Llama}}: {{Open Foundation Models}} for {{Code}}},
  author = {Rozi{\`e}re, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2308.12950},
  eprint = {2308.12950},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@roziere2023code-Code Llama - Open Foundation Models for Code.pdf}
}

@inproceedings{rudin2021learning,
  title = {Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning},
  booktitle = {Conference on {{Robot Learning}} ({{CoRL}})},
  author = {Rudin, Nikita and Hoeller, David and Reist, Philipp and Hutter, Marco},
  year = {2021},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@rudin2021learning-Learning to walk in minutes using massively parallel deep reinforcement learning.pdf}
}

@inproceedings{ruifeng2019research,
  title = {Research Progress and {{Application}} of {{Behavior Tree Technology}}},
  booktitle = {International {{Conference}} on {{Behavioral}}, {{Economic}} and {{Socio-Cultural Computing}} ({{BESC}})},
  author = {Ruifeng, Liu and Jiasheng, Wang and Haolong, Zhang and Mengfan, Tian},
  year = {2019},
  pages = {1--4},
  doi = {10.1109/BESC48373.2019.8963263},
  keywords = {AI,Behavior Tree,State Machine},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ruifeng2019research-Research progress and Application of Behavior Tree Technology.pdf}
}

@article{russellprinciples,
  title = {The {{Principles}} of {{Mathematics}}},
  author = {Russell, Bertrand},
  journal = {Bertrand Russell},
  pages = {832},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@russellprinciples-The Principles of Mathematics.pdf}
}

@article{russo2023measuring,
  title = {Measuring {{Performance}}: {{Metrics}} for {{Manipulator Design}}, {{Control}}, and {{Optimization}}},
  author = {Russo, Matteo},
  year = {2023},
  journal = {Robotics},
  volume = {12},
  number = {1},
  pages = {4},
  publisher = {MDPI},
  doi = {10.3390/robotics12010004},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@russo2023measuring-Measuring Performance - Metrics for Manipulator Design, Control, and Optimization.pdf}
}

@article{rusu2008robots,
  title = {Robots in the Kitchen: {{Exploiting}} Ubiquitous Sensing and Actuation},
  author = {Rusu, Radu Bogdan and Gerkey, Brian and Beetz, Michael},
  year = {2008},
  journal = {Robotics and Autonomous Systems},
  volume = {56},
  number = {10},
  pages = {844--856}
}

@inproceedings{ryan2003grammatical,
  title = {Grammatical Evolution: {{Evolving}} Programs for an Arbitrary Language},
  booktitle = GP,
  author = {Ryan, Conor and Collins, {\relax JJ} and Neill, Michael O.},
  year = {2003},
  pages = {83--96},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  isbn = {978-3-540-69758-9},
  annotation = {GP}
}

@book{ryan2018handbook,
  title = {Handbook of Grammatical Evolution},
  author = {Ryan, Conor and O'Neill, Michael and Collins, {\relax JJ}},
  year = {2018},
  publisher = {Springer},
  annotation = {Springer},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@ryan2018handbook-Handbook of grammatical evolution.pdf}
}

@incollection{sabbadin2020planning,
  title = {Planning in {{Artificial Intelligence}}},
  booktitle = {A {{Guided Tour}} of {{Artificial Intelligence Research}}: {{Volume II}}: {{AI Algorithms}}},
  author = {Sabbadin, R{\'e}gis and {Teichteil-K{\"o}nigsbuch}, Florent and Vidal, Vincent},
  editor = {Marquis, Pierre and Papini, Odile and Prade, Henri},
  year = {2020},
  pages = {285--312},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-06167-8_10},
  abstract = {In this chapter, we proposeSabbadin, R{\'e}gis a non-exhaustive review of past works of the AI community on classical planning and planning underTeichteil-K{\"o}nigsbuch, Florent uncertainty. We first present the classical propositional STRIPS planning language. Its extensions, based on the problem description language PDDL have become a standard in the community. We briefly deal with the structural analysis of planning problems, which has initiated theVidal, Vincent development of efficient planning algorithms and associated planners. Then, we describe the Markov Decision Processes framework (MDP), initially proposed in the Operations Research community before the AI community adopted it as a framework for planning under uncertainty. Eventually, we will describe innovative (approximate or exact) MDP solution algorithms as well as recent progresses in AI in terms of knowledge representation (logics, Bayesian networks) which have been used to increase the power of expression of the MDP framework.},
  isbn = {978-3-030-06167-8},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sabbadin2020planning-Planning in Artificial Intelligence.pdf}
}

@article{saberifar2020hardness,
  title = {The {{Hardness}} of {{Minimizing Design Cost Subject}} to {{Planning Problems}}},
  author = {Saberifar, Fatemeh Zahra and O'Kane, Jason M. and Shell, Dylan A.},
  editor = {Morales, Marco and Tapia, Lydia and {S{\'a}nchez-Ante}, Gildardo and Hutchinson, Seth},
  year = {2020},
  journal = WAFR,
  volume = {14},
  pages = {868--883},
  doi = {10.1007/978-3-030-44051-0_50},
  urldate = {2022-03-03},
  abstract = {Assuming one wants to design the most cost-effective robot for some task, how difficult is it to choose the robot's actuators? This paper addresses that question in algorithmic terms, considering the problem of identifying optimal sets of actuation capabilities to allow a robot to complete a given task. We consider various cost functions which model the cost needed to equip a robot with some capabilities, and show that the general form of this problem is NP-hard, confirming what many perhaps have suspected about this sort of design-time optimization. As a result, several questions of interest having both optimality and efficiency of solution is unlikely. However, we also show that, for some specific types of cost functions, the problem is either polynomial time solvable or fixed-parameter tractable.},
  langid = {english},
  keywords = {embodied intelligence,modularity},
  annotation = {WAFR},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@saberifar2020hardness-The Hardness of Minimizing Design Cost Subject to Planning Problems.pdf}
}

@inproceedings{safronov2019asynchronous,
  title = {Asynchronous Behavior Trees with Memory Aimed at Aerial Vehicles with Redundancy in Flight Controller},
  booktitle = {2019 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Safronov, Evgenii and Vilzmann, Michael and Tsetserukou, Dzmitry and Kondak, Konstantin},
  year = {2019},
  pages = {3113--3118},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@safronov2019asynchronous-Asynchronous behavior trees with memory aimed at aerial vehicles with.pdf}
}

@article{sakib2024consolidating,
  title = {Consolidating {{Trees}} of {{Robotic Plans Generated Using Large Language Models}} to {{Improve Reliability}}},
  author = {Sakib, Md Sadman and Sun, Yu},
  year = {2024},
  journal = {arXiv preprint arXiv:2401.07868},
  eprint = {2401.07868},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sakib2024consolidating-Consolidating Trees of Robotic Plans Generated Using Large Language Models to.pdf}
}

@book{saler2023using,
  title = {Using {{Backward Chained Behavior Trees}} to {{Control Cooperative Minecraft Agents}}},
  author = {Sal{\'e}r, Justin},
  year = {2023},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@saler2023using-Using Backward Chained Behavior Trees to Control Cooperative Minecraft Agents.pdf}
}

@inproceedings{sanchez-gonzalez2018graph,
  title = {Graph Networks as Learnable Physics Engines for Inference and Control},
  booktitle = ICML,
  author = {{Sanchez-Gonzalez}, Alvaro and Heess, Nicolas and Springenberg, Jost Tobias and Merel, Josh and Riedmiller, Martin and Hadsell, Raia and Battaglia, Peter},
  year = {2018},
  pages = {4470--4479},
  publisher = {PMLR},
  keywords = {ObsCite},
  file = {C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@sanchez-gonzalez2018graph-Graph networks as learnable physics engines for inference and control.pdf;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@sanchez-gonzalez2018graph-Graph networks as learnable physics engines for inference and control2.pdf}
}

@article{saparov2022language,
  title = {Language Models Are Greedy Reasoners: {{A}} Systematic Formal Analysis of Chain-of-Thought},
  author = {Saparov, Abulhair and He, He},
  year = {2022},
  journal = {arXiv preprint arXiv:2210.01240},
  eprint = {2210.01240},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@saparov2022language-Language models are greedy reasoners - A systematic formal analysis of.pdf}
}

@article{sato2021advantagenas,
  title = {{{AdvantageNAS}}: {{Efficient Neural Architecture Search}} with {{Credit Assignment}}},
  author = {Sato, Rei and Sakuma, Jun and Akimoto, Youhei},
  year = {2021},
  journal = AAAI,
  pages = {8},
  abstract = {Neural architecture search (NAS) is an approach for automatically designing a neural network architecture without human effort or expert knowledge. However, the high computational cost of NAS limits its use in commercial applications. Two recent NAS paradigms, namely one-shot and sparse propagation, which reduce the time and space complexities, respectively, provide clues for solving this problem. In this paper, we propose a novel search strategy for one-shot and sparse propagation NAS, namely AdvantageNAS, which further reduces the time complexity of NAS by reducing the number of search iterations. AdvantageNAS is a gradientbased approach that improves the search efficiency by introducing credit assignment in gradient estimation for architecture updates. Experiments on the NAS-Bench-201 and PTB dataset show that AdvantageNAS discovers an architecture with higher performance under a limited time budget compared to existing sparse propagation NAS. To further reveal the reliabilities of AdvantageNAS, we investigate it theoretically and find that it monotonically improves the expected loss and thus converges.},
  langid = {english},
  keywords = {differentiable,one-shot,sparse},
  annotation = {AAAI},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sato2021advantagenas-AdvantageNAS - Efficient Neural Architecture Search with Credit Assignment.pdf}
}

@article{scarselli2008graph,
  title = {The Graph Neural Network Model},
  author = {Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  year = {2008},
  journal = {IEEE transactions on neural networks},
  volume = {20},
  number = {1},
  pages = {61--80},
  publisher = {IEEE},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@scarselli2008graph-The graph neural network model.pdf}
}

@inproceedings{schaff2019jointly,
  title = {Jointly {{Learning}} to {{Construct}} and {{Control Agents}} Using {{Deep Reinforcement Learning}}},
  booktitle = ICRA,
  author = {Schaff, Charles and Yunis, David and Chakrabarti, Ayan and Walter, Matthew R.},
  year = {2019},
  month = may,
  pages = {9798--9805},
  publisher = {IEEE},
  address = {Montreal, QC, Canada},
  doi = {10.1109/ICRA.2019.8793537},
  urldate = {2022-03-01},
  abstract = {The physical design of a robot and the policy that controls its motion are inherently coupled, and should be determined according to the task and environment. In an increasing number of applications, data-driven and learningbased approaches, such as deep reinforcement learning, have proven effective at designing control policies. For most tasks, the only way to evaluate a physical design with respect to such control policies is empirical---i.e., by picking a design and training a control policy for it. Since training these policies is timeconsuming, it is computationally infeasible to train separate policies for all possible designs as a means to identify the best one. In this work, we address this limitation by introducing a method that performs simultaneous joint optimization of the physical design and control network. Our approach maintains a distribution over designs and uses reinforcement learning to optimize a control policy to maximize expected reward over the design distribution. We give the controller access to design parameters to allow it to tailor its policy to each design in the distribution. Throughout training, we shift the distribution towards higher-performing designs, eventually converging to a design and control policy that are jointly optimal. We evaluate our approach in the context of legged locomotion, and demonstrate that it discovers novel designs and walking gaits, outperforming baselines in both performance and efficiency.},
  isbn = {978-1-5386-6027-0},
  langid = {english},
  keywords = {embodied intelligence,ObsCite,reinforcement learning},
  annotation = {ICRA},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@schaff2019jointly-Jointly Learning to Construct and Control Agents using Deep Reinforcement.pdf}
}

@phdthesis{schaff2022neural,
  title = {Neural {{Approaches}} to {{Co-Optimization}} in {{Robotics}}},
  author = {Schaff, Charles},
  year = {2022},
  month = sep,
  eprint = {2209.00579},
  primaryclass = {cs},
  urldate = {2022-10-24},
  abstract = {Robots and intelligent systems that sense or interact with the world are increasingly being used to automate a wide array of tasks. The ability of these systems to complete these tasks depends on a large range of technologies such as the mechanical and electrical parts that make up the physical body of the robot and its sensors, perception algorithms to perceive the environment, and planning and control algorithms to produce meaningful actions. Therefore, it is often necessary to consider the interactions between these components when designing an embodied system. This thesis explores work on the task-driven co-optimization of robotics systems in an end-to-end manner, simultaneously optimizing the physical components of the system with inference or control algorithms directly for task performance. We start by considering the problem of optimizing a beacon-based localization system directly for localization accuracy. Designing such a system involves placing beacons throughout the environment and inferring location from sensor readings. In our work, we develop a deep learning approach to optimize both beacon placement and location inference directly for localization accuracy. We then turn our attention to the related problem of task-driven optimization of robots and their controllers. In our work, we start by proposing a data-efficient algorithm based on multi-task reinforcement learning. Our approach efficiently optimizes both physical design and control parameters directly for task performance by leveraging a design-conditioned controller capable of generalizing over the space of physical designs. We then follow this up with an extension to allow for the optimization over discrete morphological parameters such as the number and configuration of limbs. Finally, we conclude by exploring the fabrication and deployment of optimized soft robots.},
  archiveprefix = {arXiv},
  langid = {english},
  school = {toyota technological institute at chicago},
  keywords = {Computer Science - Robotics,ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@schaff2022neural-Neural Approaches to Co-Optimization in Robotics.pdf}
}

@article{schaff2022nlimb,
  title = {N-{{LIMB}}: {{Neural Limb Optimization}} for {{Efficient Morphological Design}}},
  shorttitle = {N-{{LIMB}}},
  author = {Schaff, Charles and Walter, Matthew R.},
  year = {2022},
  month = sep,
  journal = {arXiv},
  eprint = {2207.11773},
  primaryclass = {cs},
  urldate = {2022-10-06},
  abstract = {A robot's ability to complete a task is heavily dependent on its physical design. However, identifying an optimal physical design and its corresponding control policy is inherently challenging. The freedom to choose the number of links, their type, and how they are connected results in a combinatorial design space, and the evaluation of any design in that space requires deriving its optimal controller. In this work, we present N-LIMB, an efficient approach to optimizing the design and control of a robot over large sets of morphologies. Central to our framework is a universal, design-conditioned control policy capable of controlling a diverse sets of designs. This policy greatly improves the sample efficiency of our approach by allowing the transfer of experience across designs and reducing the cost to evaluate new designs. We train this policy to maximize expected return over a distribution of designs, which is simultaneously updated towards higher performing designs under the universal policy. In this way, our approach converges towards a design distribution peaked around high-performing designs and a controller that is effectively fine-tuned for those designs. We demonstrate the potential of our approach on a series of locomotion tasks across varying terrains and show the discovery novel and high-performing design-control pairs.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics,ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@schaff2022nlimb-N-LIMB - Neural Limb Optimization for Efficient Morphological Design.pdf}
}

@inproceedings{scheide2021behavior,
  title = {Behavior {{Tree Learning}} for {{Robotic Task Planning}} through {{Monte Carlo DAG Search}} over a {{Formal Grammar}}},
  booktitle = ICRA,
  author = {Scheide, Emily and Best, Graeme and Hollinger, Geoffrey A.},
  year = {2021},
  month = may,
  pages = {4837--4843},
  publisher = {IEEE},
  address = {Xi'an, China},
  doi = {10.1109/ICRA48506.2021.9561027},
  urldate = {2022-03-03},
  abstract = {We present an algorithm for learning behavior trees for robotic task planning, which alleviates the need for time-intensive or infeasible manual design of control architectures. Our method involves representing the search space of behavior trees as a formal grammar and searching over this grammar by means of a new generalization of Monte Carlo tree search (MCTS) for directed acyclic graphs (DAGs), named MCDAGS. Additionally, our method employs simulated annealing to expedite the aggregation of the most functional subtrees. We present simulated experiments for a marine target search and response scenario, and an abstract task selection problem. Our results demonstrate that the learned behavior trees compare favorably with a manually-designed tree, and outperform baseline learning methods. Overall, these results show that our method is a viable technique for the automatic design of behavior trees for robotic task planning.},
  isbn = {978-1-72819-077-8},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@scheide2021behavior-Behavior Tree Learning for Robotic Task Planning through Monte Carlo DAG Search.pdf}
}

@article{schick2023toolformer,
  title = {Toolformer: {{Language}} Models Can Teach Themselves to Use Tools},
  author = {Schick, Timo and {Dwivedi-Yu}, Jane and Dess{\`i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  year = {2023},
  journal = {arXiv preprint arXiv:2302.04761},
  eprint = {2302.04761},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@schick2023toolformer-Toolformer - Language models can teach themselves to use tools.pdf}
}

@article{schidler2024satbased,
  title = {{{SAT-based}} Decision Tree Learning for Large Data Sets},
  author = {Schidler, Andr{\'e} and Szeider, Stefan},
  year = {2024},
  journal = {Journal of Artificial Intelligence Research},
  volume = {80},
  pages = {875--918},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@schidler2024satbased-SAT-based decision tree learning for large data sets.pdf}
}

@article{schmidt2016selfsupervised,
  title = {Self-Supervised Visual Descriptor Learning for Dense Correspondence},
  author = {Schmidt, Tanner and Newcombe, Richard and Fox, Dieter},
  year = {2016},
  journal = {IEEE Robotics and Automation Letters},
  volume = {2},
  number = {2},
  pages = {420--427},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@schmidt2016selfsupervised-Self-supervised visual descriptor learning for dense correspondence.pdf}
}

@article{schrittwieser2020mastering,
  title = {Mastering {{Atari}}, {{Go}}, Chess and Shogi by Planning with a Learned Model},
  author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
  year = {2020},
  month = dec,
  journal = {Nature},
  volume = {588},
  number = {7839},
  pages = {604--609},
  issn = {1476-4687},
  doi = {10.1038/s41586-020-03051-4},
  abstract = {Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess1 and Go2, where a perfect simulator is available. However, in real-world problems, the dynamics governing the environment are often complex and unknown. Here we present the MuZero algorithm, which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. The MuZero algorithm learns an iterable model that produces predictions relevant to planning: the action-selection policy, the value function and the reward. When evaluated on 57 different Atari games3---the canonical video game environment for testing artificial intelligence techniques, in which model-based planning approaches have historically struggled4---the MuZero algorithm achieved state-of-the-art performance. When evaluated on Go, chess and shogi---canonical environments for high-performance planning---the MuZero algorithm matched, without any knowledge of the game dynamics, the superhuman performance of the AlphaZero algorithm5 that was supplied with the rules of the game.},
  keywords = {alpha zero,mcts,ObsCite,planning},
  annotation = {Nature},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@schrittwieser2020mastering-Mastering Atari, Go, chess and shogi by planning with a learned model.pdf}
}

@article{schubert2023generalist,
  title = {A {{Generalist Dynamics Model}} for {{Control}}},
  author = {Schubert, Ingmar and Zhang, Jingwei and Bruce, Jake and Bechtle, Sarah and Parisotto, Emilio and Riedmiller, Martin and Springenberg, Jost Tobias and Byravan, Arunkumar and Hasenclever, Leonard and Heess, Nicolas},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.10912},
  eprint = {2305.10912},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@schubert2023generalist-A Generalist Dynamics Model for Control.pdf}
}

@article{schulman2017proximal,
  title = {Proximal {{Policy Optimization Algorithms}}},
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  year = {2017},
  month = aug,
  journal = {arXiv},
  number = {arXiv:1707.06347},
  eprint = {1707.06347},
  primaryclass = {cs},
  urldate = {2022-05-27},
  abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a ``surrogate'' objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@schulman2017proximal-Proximal Policy Optimization Algorithms.pdf}
}

@inproceedings{schulte2014balancing,
  title = {Balancing Exploration and Exploitation in Classical Planning},
  booktitle = {Proceedings of the {{International Symposium}} on {{Combinatorial Search}}},
  author = {Schulte, Tim and Keller, Thomas},
  year = {2014},
  volume = {5},
  pages = {139--147}
}

@inproceedings{schumann2024velma,
  title = {Velma: {{Verbalization}} Embodiment of Llm Agents for Vision and Language Navigation in Street View},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Schumann, Raphael and Zhu, Wanrong and Feng, Weixi and Fu, Tsu-Jui and Riezler, Stefan and Wang, William Yang},
  year = {2024},
  volume = {38},
  pages = {18924--18933},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@schumann2024velma-Velma - Verbalization embodiment of llm agents for vision and language.pdf}
}

@article{seenu2020review,
  title = {Review on State-of-the-Art Dynamic Task Allocation Strategies for Multiple-Robot Systems},
  author = {Seenu, N and RM, Kuppan Chetty and Ramya, {\relax MM} and Janardhanan, Mukund Nilakantan},
  year = {2020},
  journal = {Industrial Robot: the international journal of robotics research and application},
  volume = {47},
  number = {6},
  pages = {929--942},
  publisher = {Emerald Publishing Limited},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@seenu2020review-Review on state-of-the-art dynamic task allocation strategies for.pdf}
}

@article{senior2020improved,
  title = {Improved Protein Structure Prediction Using Potentials from Deep Learning},
  author = {Senior, Andrew W. and Evans, Richard and Jumper, John and Kirkpatrick, James and Sifre, Laurent and Green, Tim and Qin, Chongli and {\v Z}{\'i}dek, Augustin and Nelson, Alexander W. R. and Bridgland, Alex and Penedones, Hugo and Petersen, Stig and Simonyan, Karen and Crossan, Steve and Kohli, Pushmeet and Jones, David T. and Silver, David and Kavukcuoglu, Koray and Hassabis, Demis},
  year = {2020},
  month = jan,
  journal = {Nature},
  volume = {577},
  number = {7792},
  pages = {706--710},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1923-7},
  abstract = {Protein structure prediction can be used to determine the three-dimensional shape of a protein from its amino acid sequence1. This problem is of fundamental importance as the structure of a protein largely determines its function2; however, protein structures can be difficult to determine experimentally. Considerable progress has recently been made by leveraging genetic information. It is possible to infer which amino acid residues are in contact by analysing covariation in homologous sequences, which aids in the prediction of protein structures3. Here we show that we can train a neural network to make accurate predictions of the distances between pairs of residues, which convey more information about the structure than contact predictions. Using this information, we construct a potential of mean force4 that can accurately describe the shape of a protein. We find that the resulting potential can be optimized by a simple gradient descent algorithm to generate structures without complex sampling procedures. The resulting system, named AlphaFold, achieves high accuracy, even for sequences with fewer homologous sequences. In the recent Critical Assessment of Protein Structure Prediction5 (CASP13)---a blind assessment of the state of the field---AlphaFold created high-accuracy structures (with template modelling (TM) scores6 of 0.7 or higher) for 24 out of 43 free modelling domains, whereas the next best method, which used sampling and contact information, achieved such accuracy for only 14 out of 43 domains. AlphaFold represents a considerable advance in protein-structure prediction. We expect this increased accuracy to enable insights into the function and malfunction of proteins, especially in cases for which no structures for homologous proteins have been experimentally determined7.},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@senior2020improved-Improved protein structure prediction using potentials from deep learning.pdf}
}

@inproceedings{shah2023lmnav,
  title = {Lm-Nav: {{Robotic}} Navigation with Large Pre-Trained Models of Language, Vision, and Action},
  booktitle = {Conference on {{Robot Learning}}},
  author = {Shah, Dhruv and Osi{\'n}ski, B{\textbackslash}la{\.z}ej and Levine, Sergey and others},
  year = {2023},
  pages = {492--504},
  publisher = {PMLR},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@shah2023lmnav-Lm-nav - Robotic navigation with large pre-trained models of language, vision,.pdf}
}

@inproceedings{shah2023navigation,
  title = {Navigation with Large Language Models: {{Semantic}} Guesswork as a Heuristic for Planning},
  booktitle = CoRL,
  author = {Shah, Dhruv and Equi, Michael Robert and Osi{\'n}ski, B{\l}a{\.z}ej and Xia, Fei and Ichter, Brian and Levine, Sergey},
  year = {2023},
  pages = {2683--2699},
  publisher = {PMLR},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@shah2023navigation-Navigation with large language models - Semantic guesswork as a heuristic for.pdf}
}

@inproceedings{shang2020active,
  title = {Active {{Impact Motion}} for a {{Quadruped Robot}}},
  booktitle = {International {{Conference}} on {{Automation Science}} and {{Engineering}} ({{CASE}})},
  author = {Shang, Linlin and Wang, Wei and Yi, Jianqiang},
  year = {2020},
  pages = {1049--1055},
  doi = {10.1109/CASE48305.2020.9216772},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@shang2020active-Active Impact Motion for a Quadruped Robot.pdf}
}

@article{shao2024assisting,
  title = {Assisting in Writing Wikipedia-like Articles from Scratch with Large Language Models},
  author = {Shao, Yijia and Jiang, Yucheng and Kanell, Theodore A and Xu, Peter and Khattab, Omar and Lam, Monica S},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.14207},
  eprint = {2402.14207},
  archiveprefix = {arXiv}
}

@book{shapiro2010embodied,
  title = {Embodied Cognition},
  author = {Shapiro, Lawrence},
  year = {2010},
  publisher = {Routledge}
}

@article{shapiro2014routledge,
  title = {The {{Routledge}} Handbook of Embodied Cognition},
  author = {Shapiro, Lawrence A},
  year = {2014},
  publisher = {Routledge New York}
}

@article{shen2023hugginggpt,
  title = {Hugginggpt: {{Solving}} Ai Tasks with Chatgpt and Its Friends in Huggingface},
  author = {Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  year = {2023},
  journal = {arXiv preprint arXiv:2303.17580},
  eprint = {2303.17580},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@shen2023hugginggpt-Hugginggpt - Solving ai tasks with chatgpt and its friends in huggingface.pdf}
}

@misc{shenqingkaohexi,
  title = {申请考核细则}
}

@article{shervashidze2011weisfeilerlehman,
  title = {Weisfeiler-Lehman Graph Kernels},
  author = {Shervashidze, Nino and Schweitzer, Pascal and {van Leeuwen}, Erik Jan and Mehlhorn, Kurt and Borgwardt, Karsten M.},
  year = {2011},
  journal = JMLR,
  volume = {12},
  pages = {2539--2561},
  annotation = {JMLR},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@shervashidze2011weisfeilerlehman-Weisfeiler-lehman graph kernels.pdf}
}

@article{shi2019twostream,
  title = {Two-{{Stream Adaptive Graph Convolutional Networks}} for {{Skeleton-Based Action Recognition}}},
  author = {Shi, Lei and Zhang, Yifan and Cheng, Jian and Lu, Hanqing},
  year = {2019},
  month = jul,
  journal = {arXiv},
  eprint = {1805.07694},
  urldate = {2022-03-21},
  abstract = {In skeleton-based action recognition, graph convolutional networks (GCNs), which model the human body skeletons as spatiotemporal graphs, have achieved remarkable performance. However, in existing GCN-based methods, the topology of the graph is set manually, and it is fixed over all layers and input samples. This may not be optimal for the hierarchical GCN and diverse samples in action recognition tasks. In addition, the second-order information (the lengths and directions of bones) of the skeleton data, which is naturally more informative and discriminative for action recognition, is rarely investigated in existing methods. In this work, we propose a novel two-stream adaptive graph convolutional network (2s-AGCN) for skeletonbased action recognition. The topology of the graph in our model can be either uniformly or individually learned by the BP algorithm in an end-to-end manner. This data-driven method increases the flexibility of the model for graph construction and brings more generality to adapt to various data samples. Moreover, a two-stream framework is proposed to model both the first-order and the second-order information simultaneously, which shows notable improvement for the recognition accuracy. Extensive experiments on the two large-scale datasets, NTU-RGBD and KineticsSkeleton, demonstrate that the performance of our model exceeds the state-of-the-art with a significant margin.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\SARPSBSE\\2019 - arXiv - Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action.pptx;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@shi2019twostream-Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action.pdf}
}

@article{shinn2024reflexion,
  title = {Reflexion: {{Language}} Agents with Verbal Reinforcement Learning},
  author = {Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  year = {2024},
  journal = {Advances in Neural Information Processing Systems},
  volume = {36},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@shinn2024reflexion-Reflexion - Language agents with verbal reinforcement learning.pdf}
}

@inproceedings{shiv2019novel,
  title = {Novel Positional Encodings to Enable Tree-Based Transformers},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Shiv, Vighnesh and Quirk, Chris},
  editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and d'{\null} {Alch{\'e}-Buc}, F. and Fox, E. and Garnett, R.},
  year = {2019},
  volume = {32},
  publisher = {Curran Associates, Inc.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@shiv2019novel-Novel positional encodings to enable tree-based transformers.pdf}
}

@article{shoeleh2017graph,
  title = {Graph Based Skill Acquisition and Transfer {{Learning}} for Continuous Reinforcement Learning Domains},
  author = {Shoeleh, Farzaneh and Asadpour, Masoud},
  year = {2017},
  month = feb,
  journal = {Pattern Recognition Letters},
  volume = {87},
  pages = {104--116},
  issn = {01678655},
  doi = {10.1016/j.patrec.2016.08.009},
  urldate = {2023-05-04},
  langid = {english},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@shoeleh2017graph-Graph based skill acquisition and transfer Learning for continuous.pdf}
}

@inproceedings{shoulson2011parameterizing,
  title = {Parameterizing {{Behavior Trees}}},
  booktitle = {Motion in {{Games}}},
  author = {Shoulson, Alexander and Garcia, Francisco M. and Jones, Matthew and Mead, Robert and Badler, Norman I.},
  editor = {Allbeck, Jan M. and Faloutsos, Petros},
  year = {2011},
  pages = {144--155},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  abstract = {This paper introduces and motivates the application of parameterization to behavior trees. As a framework, behavior trees are becoming more commonly used for agent controllers in interactive game environments. We describe a way by which behavior trees can be authored for acting upon functions with arguments, as opposed to being limited to nonparametric tasks. We expand upon this idea to provide a method by which a subtree itself can be encapsulated with an exposed parameter interface through a lookup node, which enables code reuse in a manner already exploited by object oriented programming languages. Parameterization also allows us to recast Smart Events (a mechanism for co-opting agents to perform a desired activity) as behavior trees that can act generically upon groups of typed agents. Finally, we introduce a tool called Topiary, which enables the graphically-oriented authoring of behavior trees with this functionality as part of a broader testbed for agent simulation.},
  isbn = {978-3-642-25090-3},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@shoulson2011parameterizing-Parameterizing Behavior Trees.pdf}
}

@inproceedings{shridhar2020alfred,
  title = {Alfred: {{A}} Benchmark for Interpreting Grounded Instructions for Everyday Tasks},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF}} Conference on Computer Vision and Pattern Recognition},
  author = {Shridhar, Mohit and Thomason, Jesse and Gordon, Daniel and Bisk, Yonatan and Han, Winson and Mottaghi, Roozbeh and Zettlemoyer, Luke and Fox, Dieter},
  year = {2020},
  pages = {10740--10749},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@shridhar2020alfred-Alfred - A benchmark for interpreting grounded instructions for everyday tasks.pdf}
}

@inproceedings{shridhar2023perceiveractor,
  title = {Perceiver-{{Actor}}: {{A Multi-Task Transformer}} for {{Robotic Manipulation}}},
  booktitle = CoRL,
  author = {Shridhar, Mohit and Manuelli, Lucas and Fox, Dieter},
  editor = {Liu, Karen and Kulic, Dana and Ichnowski, Jeff},
  year = {2023},
  month = dec,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {205},
  pages = {785--799},
  publisher = {PMLR},
  abstract = {Transformers have revolutionized vision and natural language processing with their ability to scale with large datasets. But in robotic manipulation, data is both limited and expensive. Can manipulation still benefit from Transformers with the right problem formulation? We investigate this question with PerAct, a language-conditioned behavior-cloning agent for multi-task 6-DoF manipulation. PerAct encodes language goals and RGB-D voxel observations with a Perceiver Transformer, and outputs discretized actions by ``detecting the next best voxel action''. Unlike frameworks that operate on 2D images, the voxelized 3D observation and action space provides a strong structural prior for efficiently learning 6-DoF actions. With this formulation, we train a single multi-task Transformer for 18 RLBench tasks (with 249 variations) and 7 real-world tasks (with 18 variations) from just a few demonstrations per task. Our results show that PerAct significantly outperforms unstructured image-to-action agents and 3D ConvNet baselines for a wide range of tabletop tasks.},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@shridhar2023perceiveractor-Perceiver-Actor - A Multi-Task Transformer for Robotic Manipulation.pdf}
}

@inproceedings{silver2014deterministic,
  title = {Deterministic {{Policy Gradient Algorithms}}},
  booktitle = ICML,
  author = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  year = {2014},
  series = {{{ICML}}'14},
  pages = {I--387--I--395},
  publisher = {JMLR.org},
  address = {Beijing, China},
  abstract = {In this paper we consider deterministic policy gradient algorithms for reinforcement learning with continuous actions. The deterministic policy gradient has a particularly appealing form: it is the expected gradient of the action-value function. This simple form means that the deterministic policy gradient can be estimated much more efficiently than the usual stochastic policy gradient. To ensure adequate exploration, we introduce an off-policy actor-critic algorithm that learns a deterministic target policy from an exploratory behaviour policy. We demonstrate that deterministic policy gradient algorithms can significantly outperform their stochastic counterparts in high-dimensional action spaces.},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\5ZWWMZ88\\Silver_2014_Deterministic Policy Gradient Algorithms2.pdf;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@silver2014deterministic-Deterministic Policy Gradient Algorithms.pdf}
}

@article{silver2016mastering,
  title = {Mastering the Game of {{Go}} with Deep Neural Networks and Tree Search},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Vedavyas and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy P. and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  year = {2016},
  journal = {Nature},
  volume = {529},
  number = {7587},
  pages = {484--489},
  doi = {10.1038/nature16961},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@silver2016mastering-Mastering the game of Go with deep neural networks and tree search.pdf}
}

@article{silver2017mastering,
  title = {Mastering the Game of {{Go}} without Human Knowledge},
  author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy P. and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
  year = {2017},
  journal = {Nature},
  volume = {550},
  number = {7676},
  pages = {354--359},
  doi = {10.1038/nature24270},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@silver2017mastering-Mastering the game of Go without human knowledge.pdf}
}

@article{silver2018general,
  title = {A General Reinforcement Learning Algorithm That Masters Chess, Shogi, and {{Go}} through Self-Play},
  author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
  year = {2018},
  month = dec,
  journal = {Science},
  volume = {362},
  number = {6419},
  pages = {1140--1144},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aar6404},
  urldate = {2022-04-19},
  langid = {english},
  keywords = {ObsCite},
  annotation = {Science},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@silver2018general-A general reinforcement learning algorithm that masters chess, shogi, and Go.pdf}
}

@article{silver2021reward,
  title = {Reward Is Enough},
  author = {Silver, David and Singh, Satinder and Precup, Doina and Sutton, Richard S},
  year = {2021},
  journal = AI,
  volume = {299},
  pages = {103535},
  publisher = {Elsevier},
  keywords = {ObsCite}
}

@inproceedings{silver2024generalized,
  title = {Generalized Planning in Pddl Domains with Pretrained Large Language Models},
  booktitle = AAAI,
  author = {Silver, Tom and Dan, Soham and Srinivas, Kavitha and Tenenbaum, Joshua B and Kaelbling, Leslie and Katz, Michael},
  year = {2024},
  volume = {38},
  pages = {20256--20264},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@silver2024generalized-Generalized planning in pddl domains with pretrained large language models.pdf}
}

@inproceedings{simeonov2022neural,
  title = {Neural Descriptor Fields: {{Se}} (3)-Equivariant Object Representations for Manipulation},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Simeonov, Anthony and Du, Yilun and Tagliasacchi, Andrea and Tenenbaum, Joshua B and Rodriguez, Alberto and Agrawal, Pulkit and Sitzmann, Vincent},
  year = {2022},
  pages = {6394--6400},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@simeonov2022neural-Neural descriptor fields - Se (3)-equivariant object representations for.pdf}
}

@article{sims1994evolving,
  title = {Evolving {{3D Morphology}} and {{Behavior}} by {{Competition}}},
  author = {Sims, Karl},
  year = {1994},
  journal = {Artificial Life IV},
  volume = {1},
  number = {4},
  pages = {353--372},
  keywords = {ObsCite},
  annotation = {最早利用进化学习框架实现了虚拟环境下形态与控制器的协同优化},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sims1994evolving-Evolving 3D Morphology and Behavior by Competition.pdf}
}

@inproceedings{sims1994evolvinga,
  title = {Evolving Virtual Creatures},
  booktitle = {Conference on {{Computer Graphics}} \& {{Interactive Techniques}}},
  author = {{Sims} and {Karl}},
  year = {1994},
  pages = {15--22},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sims1994evolvinga-Evolving virtual creatures.pdf}
}

@inproceedings{singh2022progprompt,
  title = {{{ProgPrompt}}: {{Generating Situated Robot Task Plans}} Using {{Large Language Models}}},
  shorttitle = {{{ProgPrompt}}},
  booktitle = ICRA,
  author = {Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  year = {2022},
  month = sep,
  eprint = {2209.11302},
  primaryclass = {cs},
  publisher = ICRA,
  urldate = {2023-10-18},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Robotics,ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@singh2022progprompt-ProgPrompt - Generating Situated Robot Task Plans using Large Language Models.pdf}
}

@article{singh2024twostep,
  title = {Twostep: {{Multi-agent}} Task Planning Using Classical Planners and Large Language Models},
  author = {Singh, Ishika and Traum, David and Thomason, Jesse},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.17246},
  eprint = {2403.17246},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@singh2024twostep-Twostep - Multi-agent task planning using classical planners and large language.pdf}
}

@inproceedings{siu2023stl,
  title = {{{STL}}: {{Surprisingly Tricky Logic}} (for {{System Validation}})},
  booktitle = IROS,
  author = {Siu, Ho Chit and Leahy, Kevin and Mann, Makai},
  year = {2023},
  pages = {8613--8620},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@siu2023stl-STL - Surprisingly Tricky Logic (for System Validation).pdf}
}

@article{skaltsis2023review,
  title = {A {{Review}} of {{Task Allocation Methods}} for {{UAVs}}},
  author = {Skaltsis, George Marios and Shin, Hyo-Sang and Tsourdos, Antonios},
  year = {2023},
  journal = {Journal of Intelligent \& Robotic Systems},
  volume = {109},
  number = {4},
  pages = {76},
  publisher = {Springer},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@skaltsis2023review-A Review of Task Allocation Methods for UAVs.pdf}
}

@article{smirnov2024generating,
  title = {Generating Consistent {{PDDL}} Domains with {{Large Language Models}}},
  author = {Smirnov, Pavel and Joublin, Frank and Ceravola, Antonello and Gienger, Michael},
  year = {2024},
  journal = {arXiv preprint arXiv:2404.07751},
  eprint = {2404.07751},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@smirnov2024generating-Generating consistent PDDL domains with Large Language Models.pdf}
}

@article{song2021flightmare,
  title = {Flightmare: {{A Flexible Quadrotor Simulator}}},
  shorttitle = {Flightmare},
  author = {Song, Yunlong and Naji, Selim and Kaufmann, Elia and Loquercio, Antonio and Scaramuzza, Davide},
  year = {2021},
  month = may,
  journal = CoRL,
  urldate = {2022-04-24},
  abstract = {State-of-the-art quadrotor simulators have a rigid and highly-specialized structure: either are they really fast, physically accurate, or photo-realistic. In this work, we propose a novel quadrotor simulator: Flightmare. Flightmare is composed of two main components: a configurable rendering engine built on Unity and a flexible physics engine for dynamics simulation. Those two components are totally decoupled and can run independently of each other. This makes our simulator extremely fast: rendering achieves speeds of up to 230 Hz, while physics simulation of up to 200,000 Hz on a laptop. In addition, Flightmare comes with several desirable features: (i) a large multi-modal sensor suite, including an interface to extract the 3D point-cloud of the scene; (ii) an API for reinforcement learning which can simulate hundreds of quadrotors in parallel; and (iii) integration with a virtual-reality headset for interaction with the simulated environment. We demonstrate the flexibility of Flightmare by using it for two different robotic tasks: quadrotor control using deep reinforcement learning and collision-free path planning in a complex 3D environment.},
  langid = {english},
  annotation = {CoRL},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@song2021flightmare-Flightmare - A Flexible Quadrotor Simulator.pdf}
}

@inproceedings{song2023llmplanner,
  title = {{{LLM-Planner}}: {{Few-Shot Grounded Planning}} for {{Embodied Agents}} with {{Large Language Models}}},
  shorttitle = {{{LLM-Planner}}},
  booktitle = {{{ICCV}}},
  author = {Song, Chan Hee and Wu, Jiaman and Washington, Clayton and Sadler, Brian M. and Chao, Wei-Lun and Su, Yu},
  year = {2023},
  pages = {2998--3009},
  urldate = {2024-01-02},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@song2023llmplanner-LLM-Planner - Few-Shot Grounded Planning for Embodied Agents with Large Language.pdf}
}

@article{sorokin2023designing,
  title = {On {{Designing}} a {{Learning Robot}}: {{Improving Morphology}} for {{Enhanced Task Performance}} and {{Learning}}},
  author = {Sorokin, Maks and Fu, Chuyuan and Tan, Jie and Liu, C Karen and Bai, Yunfei and Lu, Wenlong and Ha, Sehoon and Khansari, Mohi},
  year = {2023},
  journal = {arXiv preprint arXiv:2303.13390},
  eprint = {2303.13390},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sorokin2023designing-On Designing a Learning Robot - Improving Morphology for Enhanced Task.pdf}
}

@article{spelke2007core,
  title = {Core Knowledge},
  author = {Spelke, Elizabeth S. and Kinzler, Katherine D.},
  year = {2007},
  month = jan,
  journal = {Developmental Science},
  volume = {10},
  number = {1},
  pages = {89--96},
  issn = {1363755X, 14677687},
  doi = {10.1111/j.1467-7687.2007.00569.x},
  urldate = {2022-10-22},
  abstract = {Human cognition is founded, in part, on four systems for representing objects, actions, number, and space. It may be based, as well, on a fifth system for representing social partners. Each system has deep roots in human phylogeny and ontogeny, and it guides and shapes the mental lives of adults. Converging research on human infants, non-human primates, children and adults in diverse cultures can aid both understanding of these systems and attempts to overcome their limits.},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@spelke2007core-Core knowledge.pdf}
}

@inproceedings{spielberg2017functional,
  title = {Functional Co-Optimization of Articulated Robots},
  booktitle = ICRA,
  author = {Spielberg, Andrew and Araki, Brandon and Sung, Cynthia and Tedrake, Russ and Rus, Daniela},
  year = {2017},
  pages = {5035--5042},
  publisher = {IEEE},
  keywords = {ObsCite}
}

@inproceedings{spielberg2019learningintheloop,
  title = {Learning-{{In-The-Loop Optimization}}: {{End-To-End Control And Co-Design Of Soft Robots Through Learned Deep Latent Representations}}},
  booktitle = NeurIPS,
  author = {Spielberg, Andrew and Zhao, Allan and Hu, Yuanming and Du, Tao and Matusik, Wojciech and Rus, Daniela},
  year = {2019},
  pages = {11},
  publisher = {MIT Press},
  langid = {english},
  keywords = {embodied intelligence,ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@spielberg2019learningintheloop-Learning-In-The-Loop Optimization - End-To-End Control And Co-Design Of Soft.pdf}
}

@article{spielberg2021colearning,
  title = {Co-Learning of Task and Sensor Placement for Soft Robotics},
  author = {Spielberg, Andrew and Amini, Alexander and Chin, Lillian and Matusik, Wojciech and Rus, Daniela},
  year = {2021},
  journal = RA-L,
  volume = {6},
  number = {2},
  pages = {1208--1215},
  publisher = {IEEE},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@spielberg2021colearning-Co-learning of task and sensor placement for soft robotics.pdf}
}

@inproceedings{sprague2022adding,
  title = {Adding Neural Network Controllers to Behavior Trees without Destroying Performance Guarantees},
  booktitle = {2022 {{IEEE}} 61st {{Conference}} on {{Decision}} and {{Control}} ({{CDC}})},
  author = {Sprague, Christopher Iliffe and {\"O}gren, Petter},
  year = {2022},
  pages = {3989--3996},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sprague2022adding-Adding neural network controllers to behavior trees without destroying.pdf}
}

@article{sreedharan2023optimistic,
  title = {Optimistic Exploration in Reinforcement Learning Using Symbolic Model Estimates},
  author = {Sreedharan, Sarath and Katz, Michael},
  year = {2023},
  journal = NeurIPS,
  volume = {36},
  pages = {34519--34535},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sreedharan2023optimistic-Optimistic exploration in reinforcement learning using symbolic model estimates.pdf}
}

@article{sridharan2019reba,
  title = {{{REBA}}: {{A}} Refinement-Based Architecture for Knowledge Representation and Reasoning in Robotics},
  author = {Sridharan, Mohan and Gelfond, Michael and Zhang, Shiqi and Wyatt, Jeremy},
  year = {2019},
  journal = {Journal of Artificial Intelligence Research},
  volume = {65},
  pages = {87--180},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sridharan2019reba-REBA - A refinement-based architecture for knowledge representation and.pdf}
}

@inproceedings{srivastava2022behavior,
  title = {Behavior: {{Benchmark}} for Everyday Household Activities in Virtual, Interactive, and Ecological Environments},
  booktitle = {Conference on Robot Learning},
  author = {Srivastava, Sanjana and Li, Chengshu and Lingelbach, Michael and {Mart{\'i}n-Mart{\'i}n}, Roberto and Xia, Fei and Vainio, Kent Elliott and Lian, Zheng and Gokmen, Cem and Buch, Shyamal and Liu, Karen and others},
  year = {2022},
  pages = {477--490},
  publisher = {PMLR},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@srivastava2022behavior-Behavior - Benchmark for everyday household activities in virtual, interactive,.pdf}
}

@article{stanley2007compositional,
  title = {Compositional Pattern Producing Networks: {{A}} Novel Abstraction of Development},
  author = {Stanley, Kenneth O},
  year = {2007},
  journal = {Genetic programming and evolvable machines},
  volume = {8},
  number = {2},
  pages = {131--162},
  publisher = {Springer}
}

@article{starke2019neural,
  title = {Neural State Machine for Character-Scene Interactions},
  author = {Starke, Sebastian and Zhang, He and Komura, Taku and Saito, Jun},
  year = {2019},
  month = dec,
  journal = TOG,
  volume = {38},
  number = {6},
  pages = {1--14},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3355089.3356505},
  urldate = {2022-02-28},
  abstract = {We propose               Neural State Machine               , a novel data-driven framework to guide characters to achieve goal-driven actions with precise scene interactions. Even a seemingly simple task such as sitting on a chair is notoriously hard to model with supervised learning. This difficulty is because such a task involves complex planning with periodic and non-periodic motions reacting to the scene geometry to precisely position and orient the character. Our proposed deep auto-regressive framework enables modeling of multi-modal scene interaction behaviors purely from data. Given high-level instructions such as the goal location and the action to be launched there, our system computes a series of movements and transitions to reach the goal in the desired state. To allow characters to adapt to a wide range of geometry such as different shapes of furniture and obstacles, we incorporate an efficient data augmentation scheme to randomly switch the 3D geometry while maintaining the context of the original motion. To increase the precision to reach the goal during runtime, we introduce a control scheme that combines egocentric inference and goal-centric inference. We demonstrate the versatility of our model with various scene interaction tasks such as sitting on a chair, avoiding obstacles, opening and entering through a door, and picking and carrying objects generated in real-time just from a single model.},
  langid = {english},
  keywords = {neural network},
  annotation = {TOG},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@starke2019neural-Neural state machine for character-scene interactions.pdf}
}

@book{starzyk2008motivation,
  title = {Motivation in Embodied Intelligence},
  author = {Starzyk, Janusz A},
  year = {2008},
  publisher = {Citeseer},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@starzyk2008motivation-Motivation in embodied intelligence.pdf}
}

@inproceedings{stechly2023gpt4,
  title = {{{GPT-4 Doesn}}'t {{Know It}}'s {{Wrong}}: {{An Analysis}} of {{Iterative Prompting}} for {{Reasoning Problems}}},
  booktitle = {{{NeurIPS}} 2023 {{Foundation Models}} for {{Decision Making Workshop}}},
  author = {Stechly, Kaya and Marquez, Matthew and Kambhampati, Subbarao},
  year = {2023},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@stechly2023gpt4-GPT-4 Doesn't Know It's Wrong - An Analysis of Iterative Prompting for Reasoning.pdf}
}

@article{stensby2021cooptimising,
  title = {Co-Optimising {{Robot Morphology}} and {{Controller}} in a {{Simulated Open-Ended Environment}}},
  author = {Stensby, Emma Hjellbrekke and Ellefsen, Kai Olav and Glette, Kyrre},
  year = {2021},
  journal = {arXiv},
  volume = {12694},
  eprint = {2104.03062},
  pages = {34--49},
  doi = {10.1007/978-3-030-72699-7_3},
  urldate = {2022-03-01},
  abstract = {Designing robots by hand can be costly and time consuming, especially if the robots have to be created with novel materials, or be robust to internal or external changes. In order to create robots automatically, without the need for human intervention, it is necessary to optimise both the behaviour and the body design of the robot. However, when co-optimising the morphology and controller of a locomoting agent the morphology tends to converge prematurely, reaching a local optimum. Approaches such as explicit protection of morphological innovation have been used to reduce this problem, but it might also be possible to increase exploration of morphologies using a more indirect approach. We explore how changing the environment, where the agent locomotes, affects the convergence of morphologies. The agents' morphologies and controllers are co-optimised, while the environments the agents locomote in are evolved open-endedly with the Paired OpenEnded Trailblazer (POET). We compare the diversity, fitness and robustness of agents evolving in environments generated by POET to agents evolved in handcrafted curricula of environments. Our agents each contain of a population of individuals being evolved with a genetic algorithm. This population is called the agent-population. We show that agent-populations evolving in open-endedly evolving environments exhibit larger morphological diversity than agent-populations evolving in hand crafted curricula of environments. POET proved capable of creating a curriculum of environments which encouraged both diversity and quality in the populations. This suggests that POET may be capable of reducing premature convergence in co-optimisation of morphology and controllers.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {embodied intelligence},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@stensby2021cooptimising-Co-optimising Robot Morphology and Controller in a Simulated Open-Ended.pdf}
}

@inproceedings{stern2017efficient,
  type = {Conference Paper},
  title = {Efficient, Safe, and Probably Approximately Complete Learning of Action Models},
  booktitle = IJCAI,
  author = {Stern, Roni and Juba, Brendan},
  year = {2017},
  volume = {0},
  pages = {4405--4411},
  doi = {10.24963/ijcai.2017/615},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@stern2017efficient-Efficient, safe, and probably approximately complete learning of action models.pdf}
}

@article{sternberg1997concept,
  title = {The Concept of Intelligence and Its Role in Lifelong Learning and Success.},
  author = {Sternberg, Robert J},
  year = {1997},
  journal = {American psychologist},
  volume = {52},
  number = {10},
  pages = {1030},
  publisher = {American Psychological Association}
}

@techreport{stout2005intrinsically,
  title = {Intrinsically Motivated Reinforcement Learning: {{A}} Promising Framework for Developmental Robot Learning},
  author = {Stout, Andrew and Konidaris, George D and Barto, Andrew G},
  year = {2005},
  institution = {Massachusetts Univ Amherst Dept of Computer Science}
}

@inproceedings{styrud2022combining,
  title = {Combining Planning and Learning of Behavior Trees for Robotic Assembly},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Styrud, Jonathan and Iovino, Matteo and Norrl{\"o}f, Mikael and Bj{\"o}rkman, M{\aa}rten and Smith, Christian},
  year = {2022},
  pages = {11511--11517},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@styrud2022combining-Combining planning and learning of behavior trees for robotic assembly.pdf}
}

@inproceedings{su2023webtr,
  title = {{{WE-BTR}}: {{A Behavior Tree Recommendation Method Based}} on {{Word Embedding}}},
  booktitle = {2023 {{IEEE}} 35th {{International Conference}} on {{Tools}} with {{Artificial Intelligence}} ({{ICTAI}})},
  author = {Su, Hang and Li, Fu and Wang, Xueying and Li, Jinghua and Wu, Yunlong and Wang, Yanzhen},
  year = {2023},
  pages = {978--985},
  doi = {10.1109/ICTAI59109.2023.00146},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@su2023webtr-WE-BTR - A Behavior Tree Recommendation Method Based on Word Embedding.pdf}
}

@inproceedings{suarez2021neural,
  title = {The {{Neural MMO Platform}} for {{Massively Multiagent Research}}},
  booktitle = NeurIPS,
  author = {Suarez, Joseph and Du, Yilun and Zhu, Clare and Mordatch, Igor and Isola, Phillip},
  year = {2021},
  pages = {14},
  abstract = {Neural MMO is a computationally accessible research platform that combines large agent populations, long time horizons, open-ended tasks, and modular game systems. Existing environments feature subsets of these properties, but Neural MMO is the first to combine them all. We present Neural MMO as free and open source software with active support, ongoing development, documentation, and additional training, logging, and visualization tools to help users adapt to this new setting. Initial baselines on the platform demonstrate that agents trained in large populations explore more and learn a progression of skills. We raise other more difficult problems such as many-team cooperation as open research questions which Neural MMO is well-suited to answer. Finally, we discuss current limitations of the platform, potential mitigations, and plans for continued development.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\2TRYA7Y6\Suarez_2021_The Neural MMO Platform for Massively Multiagent Research.pdf}
}

@article{sumers2023cognitive,
  title = {Cognitive Architectures for Language Agents},
  author = {Sumers, Theodore R and Yao, Shunyu and Narasimhan, Karthik and Griffiths, Thomas L},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.02427},
  eprint = {2309.02427},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sumers2023cognitive-Cognitive architectures for language agents.pdf}
}

@inproceedings{sun2017deeply,
  title = {Deeply Aggrevated: {{Differentiable}} Imitation Learning for Sequential Prediction},
  booktitle = ICML,
  author = {Sun, Wen and Venkatraman, Arun and Gordon, Geoffrey J and Boots, Byron and Bagnell, J Andrew},
  year = {2017},
  pages = {3309--3318},
  publisher = {PMLR},
  keywords = {core,ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sun2017deeply-Deeply aggrevated - Differentiable imitation learning for sequential prediction.pdf}
}

@inproceedings{sun2018truncated,
  title = {Truncated {{Horizon Policy Search}}: {{Combining Reinforcement Learning}} \& {{Imitation Learning}}},
  booktitle = ICLR,
  author = {Sun, Wen and Bagnell, J. Andrew and Boots, Byron},
  year = {2018},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sun2018truncated-Truncated Horizon Policy Search - Combining Reinforcement Learning & Imitation.pdf}
}

@inproceedings{sun2019learning,
  title = {Learning {{Sparse Sharing Architectures}} for {{Multiple Tasks}}},
  booktitle = AAAI,
  author = {Sun, Tianxiang and Shao, Yunfan and Li, Xiaonan and Liu, Pengfei and Yan, Hang and Qiu, Xipeng and Huang, Xuanjing},
  year = {2019},
  month = nov,
  eprint = {1911.05034},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2022-12-01},
  abstract = {Most existing deep multi-task learning models are based on parameter sharing, such as hard sharing, hierarchical sharing, and soft sharing. How choosing a suitable sharing mechanism depends on the relations among the tasks, which is not easy since it is difficult to understand the underlying shared factors among these tasks. In this paper, we propose a novel parameter sharing mechanism, named Sparse Sharing. Given multiple tasks, our approach automatically finds a sparse sharing structure. We start with an over-parameterized base network, from which each task extracts a subnetwork. The subnetworks of multiple tasks are partially overlapped and trained in parallel. We show that both hard sharing and hierarchical sharing can be formulated as particular instances of the sparse sharing framework. We conduct extensive experiments on three sequence labeling tasks. Compared with single-task models and three typical multi-task learning baselines, our proposed approach achieves consistent improvement while requiring fewer parameters.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sun2019learning-Learning Sparse Sharing Architectures for Multiple Tasks.pdf}
}

@inproceedings{sun2020treegen,
  title = {Treegen: {{A}} Tree-Based Transformer Architecture for Code Generation},
  booktitle = {Proceedings of the {{AAAI}} Conference on Artificial Intelligence},
  author = {Sun, Zeyu and Zhu, Qihao and Xiong, Yingfei and Sun, Yican and Mou, Lili and Zhang, Lu},
  year = {2020},
  volume = {34},
  pages = {8984--8991},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sun2020treegen-Treegen - A tree-based transformer architecture for code generation.pdf}
}

@article{sun2021ernie,
  title = {Ernie 3.0: {{Large-scale}} Knowledge Enhanced Pre-Training for Language Understanding and Generation},
  author = {Sun, Yu and Wang, Shuohuan and Feng, Shikun and Ding, Siyu and Pang, Chao and Shang, Junyuan and Liu, Jiaxiang and Chen, Xuyi and Zhao, Yanbin and Lu, Yuxiang and others},
  year = {2021},
  journal = {arXiv preprint arXiv:2107.02137},
  eprint = {2107.02137},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sun2021ernie-Ernie 3.0 - Large-scale knowledge enhanced pre-training for language.pdf}
}

@article{sun2022symbolic,
  title = {Symbolic Physics Learner: {{Discovering}} Governing Equations via Monte Carlo Tree Search},
  author = {Sun, Fangzheng and Liu, Yang and Wang, Jian-Xun and Sun, Hao},
  year = {2022},
  journal = {arXiv preprint arXiv:2205.13134},
  eprint = {2205.13134},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sun2022symbolic-Symbolic physics learner - Discovering governing equations via monte carlo tree.pdf}
}

@inproceedings{sun2023adaplanner,
  title = {{{AdaPlanner}}: {{Adaptive Planning}} from {{Feedback}} with {{Language Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Sun, Haotian and Zhuang, Yuchen and Kong, Lingkai and Dai, Bo and Zhang, Chao},
  editor = {Oh, A. and Naumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.},
  year = {2023},
  volume = {36},
  pages = {58202--58245},
  publisher = {Curran Associates, Inc.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sun2023adaplanner-AdaPlanner - Adaptive Planning from Feedback with Language Models.pdf}
}

@inproceedings{sunada1994coordinated,
  title = {A Coordinated {{Jacobian}} Transpose Control for Mobile Multi-Limbed Robotic Systems},
  booktitle = ICRA,
  author = {Sunada, C. and Argaez, D. and Dubowsky, S. and Mavroidis, C.},
  year = {1994},
  month = may,
  pages = {1910-1915 vol.3},
  doi = {10.1109/ROBOT.1994.351182},
  abstract = {This analytic and experimental study proposes a control algorithm based on Jacobian control for coordinated position and force control for autonomous multi-limbed mobile robotic systems. The technique is called coordinated Jacobian transpose control, or CJTC. Such position/force control algorithms will be required if future robotic systems are to operate effectively in unstructured environments. Generalized control variables, GCV's, express in a consistent and coordinated manner the desired behavior of the forces exerted by the multi-limbed robot on the environment and a system's motions. The effectiveness of this algorithm is demonstrated in simulation and laboratory experiments on a climbing system.{$<>$}},
  keywords = {Control systems,Displacement control,Force control,Impedance,Jacobian matrices,Manipulators,Mechanical variables control,Mobile robots,Motion control,ObsCite,Robot kinematics},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sunada1994coordinated-A coordinated Jacobian transpose control for mobile multi-limbed robotic systems.pdf}
}

@inproceedings{sundaresan2020learning,
  title = {Learning Rope Manipulation Policies Using Dense Object Descriptors Trained on Synthetic Depth Data},
  booktitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Sundaresan, Priya and Grannen, Jennifer and Thananjeyan, Brijen and Balakrishna, Ashwin and Laskey, Michael and Stone, Kevin and Gonzalez, Joseph E and Goldberg, Ken},
  year = {2020},
  pages = {9411--9418},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sundaresan2020learning-Learning rope manipulation policies using dense object descriptors trained on.pdf}
}

@article{sutton1999mdps,
  title = {Between {{MDPs}} and Semi-{{MDPs}}: {{A}} Framework for Temporal Abstraction in Reinforcement Learning},
  author = {Sutton, Richard S. and Precup, Doina and Singh, Satinder},
  year = {1999},
  journal = AI,
  volume = {112},
  number = {1},
  pages = {181--211},
  keywords = {ObsCite},
  annotation = {AI},
  file = {C:\Users\lenovo\Zotero\storage\22EB8M79\Sutton_1999_Between MDPs and semi-MDPs.pdf}
}

@inproceedings{sutton1999policy,
  title = {Policy {{Gradient Methods}} for {{Reinforcement Learning}} with {{Function Approximation}}},
  booktitle = NeurIPS,
  author = {Sutton, Richard S. and McAllester, David and Singh, Satinder and Mansour, Yishay},
  year = {1999},
  series = {{{NIPS}}'99},
  pages = {1057--1063},
  publisher = {MIT Press},
  address = {Cambridge, MA, USA},
  abstract = {Function approximation is essential to reinforcement learning, but the standard approach of approximating a value function and determining a policy from it has so far proven theoretically intractable. In this paper we explore an alternative approach in which the policy is explicitly represented by its own function approximator, independent of the value function, and is updated according to the gradient of expected reward with respect to the policy parameters. Williams's REINFORCE method and actor-critic methods are examples of this approach. Our main new result is to show that the gradient can be written in a form suitable for estimation from experience aided by an approximate action-value or advantage function. Using this result, we prove for the first time that a version of policy iteration with arbitrary differentiable function approximation is convergent to a locally optimal policy.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sutton1999policy-Policy Gradient Methods for Reinforcement Learning with Function Approximation.pdf}
}

@book{sutton2018reinforcement,
  title = {Reinforcement Learning: {{An}} Introduction},
  author = {Sutton, Richard S and Barto, Andrew G},
  year = {2018},
  publisher = {MIT press},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@sutton2018reinforcement-Reinforcement learning - An introduction.pdf}
}

@phdthesis{tadewos2021automatic,
  title = {Automatic {{Tasking}} of {{Multi-Agent Systems Using Behavior Tree}}},
  author = {Tadewos, Tadewos G},
  year = {2021},
  school = {North Carolina Agricultural and Technical State University},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@tadewos2021automatic-Automatic Tasking of Multi-Agent Systems Using Behavior Tree.pdf}
}

@article{tadewos2022specificationguided,
  title = {Specification-Guided Behavior Tree Synthesis and Execution for Coordination of Autonomous Systems},
  author = {Tadewos, Tadewos G and Newaz, Abdullah Al Redwan and Karimoddini, Ali},
  year = {2022},
  journal = {Expert Systems with Applications},
  volume = {201},
  pages = {117022},
  publisher = {Elsevier},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@tadewos2022specificationguided-Specification-guided behavior tree synthesis and execution for coordination of.pdf}
}

@article{tadewos2022specificationguideda,
  title = {Specification-Guided Behavior Tree Synthesis and Execution for Coordination of Autonomous Systems},
  author = {Tadewos, Tadewos G and Newaz, Abdullah Al Redwan and Karimoddini, Ali},
  year = {2022},
  journal = {Expert Systems with Applications},
  volume = {201},
  pages = {117022},
  publisher = {Elsevier}
}

@article{tadewos2023automatic,
  title = {Automatic Decentralized Behavior Tree Synthesis and Execution for Coordination of Intelligent Vehicles},
  author = {Tadewos, Tadewos G and Shamgah, Laya and Karimoddini, Ali},
  year = {2023},
  journal = {Knowledge-Based Systems},
  volume = {260},
  pages = {110181},
  publisher = {Elsevier},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@tadewos2023automatic-Automatic decentralized behavior tree synthesis and execution for coordination.pdf}
}

@article{tai2015improved,
  title = {Improved Semantic Representations from Tree-Structured Long Short-Term Memory Networks},
  author = {Tai, Kai Sheng and Socher, Richard and Manning, Christopher D},
  year = {2015},
  journal = {arXiv preprint arXiv:1503.00075},
  eprint = {1503.00075},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@tai2015improved-Improved semantic representations from tree-structured long short-term memory.pdf}
}

@article{tai2016survey,
  title = {A {{Survey}} of {{Deep Network Solutions}} for {{Learning Control}} in {{Robotics}}: {{From Reinforcement}} to {{Imitation}}},
  author = {Tai, Lei and Zhang, Jingwei and Liu, Ming and Boedecker, Joschka and Burgard, Wolfram},
  year = {2016},
  journal = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@tai2016survey-A Survey of Deep Network Solutions for Learning Control in Robotics - From.pdf}
}

@article{taitler20242023,
  title = {The 2023 {{International Planning Competition}}},
  author = {Taitler, Ayal and Alford, Ron and Espasa, Joan and Behnke, Gregor and Fi{\v s}er, Daniel and Gimelfarb, Michael and Pommerening, Florian and Sanner, Scott and Scala, Enrico and Schreiber, Dominik and Segovia-Aguas, Javier and Seipp, Jendrik},
  year = {2024},
  month = apr,
  journal = {AI Mag.},
  volume = {45},
  number = {2},
  pages = {280--296},
  publisher = {American Association for Artificial Intelligence},
  address = {USA},
  issn = {0738-4602},
  doi = {10.1002/aaai.12169},
  abstract = {In this article, we present an overview of the 2023 International Planning Competition. It featured five distinct tracks designed to assess cutting-edge methods and explore the frontiers of planning within these settings: the classical (deterministic) track, the numeric track, the Hierarchical Task Networks (HTN) track, the learning track, and the probabilistic and reinforcement learning track. Each of these tracks evaluated planning methodologies through one or more subtracks, with the goal of pushing the boundaries of current planner performance. To achieve this objective, the competition introduced a combination of well-established challenges and entirely novel ones. Within this article, each track offers an exploration of its historical context, justifies its relevance within the planning landscape, discusses emerging domains and trends, elucidates the evaluation methodology, and ultimately presents the results.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@taitler20242023-The 2023 International Planning Competition.pdf}
}

@inproceedings{tamar2016value,
  title = {Value {{Iteration Networks}}},
  booktitle = NeurIPS,
  author = {Tamar, Aviv and Wu, Yi and Thomas, Garrett and Levine, Sergey and Abbeel, Pieter},
  year = {2016},
  urldate = {2022-04-19},
  abstract = {We introduce the value iteration network (VIN): a fully differentiable neural network with a `planning module' embedded within. VINs can learn to plan, and are suitable for predicting outcomes that involve planning-based reasoning, such as policies for reinforcement learning. Key to our approach is a novel differentiable approximation of the value-iteration algorithm, which can be represented as a convolutional neural network, and trained end-to-end using standard backpropagation. We evaluate VIN based policies on discrete and continuous path-planning domains, and on a natural-language based search task. We show that by learning an explicit planning computation, VIN policies generalize better to new, unseen domains.},
  langid = {english},
  annotation = {NeurIPS}
}

@article{tan2011stable,
  title = {Stable {{Proportional-Derivative Controllers}}},
  author = {Tan, Jie and Liu, Karen and Turk, Greg},
  year = {2011},
  journal = {IEEE Computer Graphics and Applications},
  volume = {31},
  number = {4},
  pages = {34--44},
  doi = {10.1109/MCG.2011.30},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@tan2011stable-Stable Proportional-Derivative Controllers.pdf}
}

@article{tang2023graphgpt,
  title = {{{GraphGPT}}: {{Graph Instruction Tuning}} for {{Large Language Models}}},
  author = {Tang, Jiabin and Yang, Yuhao and Wei, Wei and Shi, Lei and Su, Lixin and Cheng, Suqi and Yin, Dawei and Huang, Chao},
  year = {2023},
  journal = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@tang2023graphgpt-GraphGPT - Graph Instruction Tuning for Large Language Models.pdf}
}

@inproceedings{tang2024mars,
  title = {Mars: {{Situated Inductive Reasoning}} in an {{Open-World Environment}}},
  booktitle = NeurIPS,
  author = {Tang, Xiaojuan and Li, Jiaqi and Liang, Yitao and Zhu, Song-chun and Zhang, Muhan and Zheng, Zilong},
  year = {2024},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@tang2024mars-Mars - Situated Inductive Reasoning in an Open-World Environment2.pdf}
}

@article{tao2023reinforcement,
  title = {A {{Reinforcement Learning-based Approach}} to {{Testing GUI}} of {{Moblie Applications}}},
  author = {Tao, Chuanqi and Gao, Yuemeng and Guo, Hongjing and Gao, Jerry},
  year = {2023},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@tao2023reinforcement-A Reinforcement Learning-based Approach to Testing GUI of Moblie Applications.pdf}
}

@article{tassa2018deepmind,
  title = {Deepmind Control Suite},
  author = {Tassa, Yuval and Doron, Yotam and Muldal, Alistair and Erez, Tom and Li, Yazhe and Casas, Diego de Las and Budden, David and Abdolmaleki, Abbas and Merel, Josh and Lefrancq, Andrew and others},
  year = {2018},
  journal = {arXiv preprint arXiv:1801.00690},
  eprint = {1801.00690},
  archiveprefix = {arXiv}
}

@article{teamfair+2022humanlevel,
  title = {Human-Level Play in the Game of {{Diplomacy}} by Combining Language Models with Strategic Reasoning},
  author = {Team (FAIR){\dag}, Meta Fundamental AI Research Diplomacy and Bakhtin, Anton and Brown, Noam and Dinan, Emily and Farina, Gabriele and Flaherty, Colin and Fried, Daniel and Goff, Andrew and Gray, Jonathan and Hu, Hengyuan and others},
  year = {2022},
  journal = {Science},
  volume = {378},
  number = {6624},
  pages = {1067--1074},
  publisher = {American Association for the Advancement of Science},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@teamfair+2022humanlevel-Human-level play in the game of Diplomacy by combining language models with.pdf}
}

@article{thakur2023verigen,
  title = {{{VeriGen}}: {{A Large Language Model}} for {{Verilog Code Generation}}},
  author = {Thakur, Shailja and Ahmad, Baleegh and Pearce, Hammond and Tan, Benjamin and {Dolan-Gavitt}, Brendan and Karri, Ramesh and Garg, Siddharth},
  year = {2023},
  journal = {arXiv preprint arXiv:2308.00708},
  eprint = {2308.00708},
  archiveprefix = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@thakur2023verigen-VeriGen - A Large Language Model for Verilog Code Generation.pdf}
}

@inproceedings{todorov2012mujoco,
  title = {{{MuJoCo}}: {{A}} Physics Engine for Model-Based Control},
  booktitle = IROS,
  author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  year = {2012},
  pages = {5026--5033},
  doi = {10.1109/IROS.2012.6386109},
  keywords = {ObsCite}
}

@inproceedings{togninalli2019wasserstein,
  title = {Wasserstein {{Weisfeiler}}--{{Lehman}} Graph Kernels},
  booktitle = NeurIPS,
  author = {Togninalli, Matteo and Ghisu, Elisabetta and {Llinares-L{\'o}pez}, Felipe and Rieck, Bastian and Borgwardt, Karsten},
  editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and {d'Alch{\'e}-Buc}, F. and Fox, E. and Garnett, R.},
  year = {2019},
  pages = {6436--6446},
  publisher = {Curran Associates, Inc.},
  keywords = {ObsCite},
  annotation = {NeurIPS},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@togninalli2019wasserstein-Wasserstein Weisfeiler–Lehman graph kernels.pdf}
}

@book{tolle2016dangxiadeliliang,
  title = {当下的力量},
  author = {Tolle, Eckhart},
  year = {2016},
  publisher = {中信出版社},
  isbn = {978-7-5086-6176-6},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@tolle2016dangxiadeliliang-当下的力量.epub}
}

@inproceedings{toma2021pathbench,
  title = {{{PathBench}}: {{A Benchmarking Platform}} for {{Classical}} and {{Learned Path Planning Algorithms}}},
  booktitle = {2021 18th {{Conference}} on {{Robots}} and {{Vision}} ({{CRV}})},
  author = {Toma, Alexandru-Iosif and Hsueh, Hao-Ya and Jaafar, Hussein Ali and Murai, Riku and Kelly, Paul H.J. and Saeedi, Sajad},
  year = {2021},
  pages = {79--86},
  doi = {10.1109/CRV52889.2021.00019},
  keywords = {Benchmark testing,Benchmarking,Machine Learning,Measurement,Path planning,Path Planning,Three-dimensional displays,Tools,Training,Visualization}
}

@article{torreno2017cooperative,
  title = {Cooperative Multi-Agent Planning: {{A}} Survey},
  author = {Torreno, Alejandro and Onaindia, Eva and Komenda, Anton{\'i}n and {\v S}tolba, Michal},
  year = {2017},
  journal = {ACM Computing Surveys (CSUR)},
  volume = {50},
  number = {6},
  pages = {1--32},
  publisher = {ACM New York, NY, USA},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@torreno2017cooperative-Cooperative multi-agent planning - A survey.pdf}
}

@inproceedings{trabucco2022anymorph,
  title = {{{AnyMorph}}: {{Learning}} Transferable Polices by Inferring Agent Morphology},
  booktitle = ICML,
  author = {Trabucco, Brandon and Phielipp, Mariano and Berseth, Glen},
  editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  year = {2022-07-17/2022-07-23},
  series = {Proceedings of Machine Learning Research},
  volume = {162},
  pages = {21677--21691},
  publisher = {PMLR},
  abstract = {The prototypical approach to reinforcement learning involves training policies tailored to a particular agent from scratch for every new morphology. Recent work aims to eliminate the re-training of policies by investigating whether a morphology-agnostic policy, trained on a diverse set of agents with similar task objectives, can be transferred to new agents with unseen morphologies without re-training. This is a challenging problem that required previous approaches to use hand-designed descriptions of the new agent's morphology. Instead of hand-designing this description, we propose a data-driven method that learns a representation of morphology directly from the reinforcement learning objective. Ours is the first reinforcement learning algorithm that can train a policy to generalize to new agent morphologies without requiring a description of the agent's morphology in advance. We evaluate our approach on the standard benchmark for agent-agnostic control, and improve over the current state of the art in zero-shot generalization to new agents. Importantly, our method attains good performance without an explicit description of morphology.},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@trabucco2022anymorph-AnyMorph - Learning transferable polices by inferring agent morphology.pdf}
}

@inproceedings{tran2019learning,
  title = {Learning Triggers for Heterogeneous Treatment Effects},
  booktitle = AAAI,
  author = {Tran, Christopher and Zheleva, Elena},
  year = {2019},
  volume = {33},
  pages = {5183--5190},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@tran2019learning-Learning triggers for heterogeneous treatment effects.pdf}
}

@inproceedings{tran2023neurosymbolic,
  title = {Neurosymbolic Reasoning and Learning with Restricted Boltzmann Machines},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Tran, Son N and d'Avila Garcez, Artur},
  year = {2023},
  volume = {37},
  pages = {6558--6565}
}

@article{tucker2021emergent,
  title = {Emergent {{Discrete Communication}} in {{Semantic Spaces}}},
  author = {Tucker, Mycal and Li, Huao and Agrawal, Siddharth and Hughes, Dana and Sycara, Katia and Lewis, Michael and Shah, Julie},
  year = {2021},
  month = nov,
  journal = {arXiv},
  eprint = {2108.01828},
  urldate = {2022-03-24},
  abstract = {Neural agents trained in reinforcement learning settings can learn to communicate among themselves via discrete tokens, accomplishing as a team what agents would be unable to do alone. However, the current standard of using one-hot vectors as discrete communication tokens prevents agents from acquiring more desirable aspects of communication such as zero-shot understanding. Inspired by word embedding techniques from natural language processing, we propose neural agent architectures that enables them to communicate via discrete tokens derived from a learned, continuous space. We show in a decision theoretic framework that our technique optimizes communication over a wide range of scenarios, whereas one-hot tokens are only optimal under restrictive assumptions. In self-play experiments, we validate that our trained agents learn to cluster tokens in semantically-meaningful ways, allowing them communicate in noisy environments where other techniques fail. Lastly, we demonstrate both that agents using our method can effectively respond to novel human communication and that humans can understand unlabeled emergent agent communication, outperforming the use of one-hot communication.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@tucker2021emergent-Emergent Discrete Communication in Semantic Spaces.pdf}
}

@article{tunyasuvunakool2021highly,
  title = {Highly Accurate Protein Structure Prediction for the Human Proteome},
  author = {Tunyasuvunakool, Kathryn and Adler, Jonas and Wu, Zachary and Green, Tim and Zielinski, Michal and {\v Z}{\'i}dek, Augustin and Bridgland, Alex and Cowie, Andrew and Meyer, Clemens and Laydon, Agata and Velankar, Sameer and Kleywegt, Gerard J. and Bateman, Alex and Evans, Richard and Pritzel, Alexander and Figurnov, Michael and Ronneberger, Olaf and Bates, Russ and Kohl, Simon A. A. and Potapenko, Anna and Ballard, Andrew J. and {Romera-Paredes}, Bernardino and Nikolov, Stanislav and Jain, Rishub and Clancy, Ellen and Reiman, David and Petersen, Stig and Senior, Andrew W. and Kavukcuoglu, Koray and Birney, Ewan and Kohli, Pushmeet and Jumper, John and Hassabis, Demis},
  year = {2021},
  month = aug,
  journal = {Nature},
  volume = {596},
  number = {7873},
  pages = {590--596},
  issn = {1476-4687},
  doi = {10.1038/s41586-021-03828-1},
  abstract = {Protein structures can provide invaluable information, both for reasoning about biological processes and for enabling interventions such as structure-based drug development or targeted mutagenesis. After decades of effort, 17\% of the total residues in human protein sequences are covered by an experimentally determined structure1. Here we markedly expand the structural coverage of the proteome by applying the state-of-the-art machine learning method, AlphaFold2, at a scale that covers almost the entire human proteome (98.5\% of human proteins). The resulting dataset covers 58\% of residues with a confident prediction, of which a subset (36\% of all residues) have very high confidence. We introduce several metrics developed by building on the AlphaFold model and use them to interpret the dataset, identifying strong multi-domain predictions as well as regions that are likely to be disordered. Finally, we provide some case studies to illustrate how high-quality predictions could be used to generate biological hypotheses. We are making our predictions freely available to the community and anticipate that routine large-scale and high-accuracy structure prediction will become an important tool~that will allow new questions to be addressed from a structural perspective.},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@tunyasuvunakool2021highly-Highly accurate protein structure prediction for the human proteome.pdf}
}

@inproceedings{turchetta2022learning,
  title = {Learning {{Long-Term Crop Management Strategies}} with {{CyclesGym}}},
  booktitle = NeurIPS,
  author = {Turchetta, Matteo and Corinzia, Luca and Sussex, Scott and Burton, Amanda and Herrera, Juan and Athanasiadis, Ioannis N. and Buhmann, Joachim M. and Krause, Andreas},
  year = {2022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@turchetta2022learning-Learning Long-Term Crop Management Strategies with CyclesGym.pdf}
}

@inproceedings{valmeekam2023can,
  title = {Can {{Large Language Models Really Improve}} by {{Self-critiquing Their Own Plans}}?},
  booktitle = {{{NeurIPS}} 2023 {{Foundation Models}} for {{Decision Making Workshop}}},
  author = {Valmeekam, Karthik and Marquez, Matthew and Kambhampati, Subbarao},
  year = {2023},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@valmeekam2023can-Can Large Language Models Really Improve by Self-critiquing Their Own Plans.pdf}
}

@inproceedings{valmeekam2023planbench,
  title = {{{PlanBench}}: {{An Extensible Benchmark}} for {{Evaluating Large Language Models}} on {{Planning}} and {{Reasoning}} about {{Change}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Valmeekam, Karthik and Marquez, Matthew and Olmo, Alberto and Sreedharan, Sarath and Kambhampati, Subbarao},
  editor = {Oh, A. and Naumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.},
  year = {2023},
  volume = {36},
  pages = {38975--38987},
  publisher = {Curran Associates, Inc.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@valmeekam2023planbench-PlanBench - An Extensible Benchmark for Evaluating Large Language Models on.pdf}
}

@inproceedings{valmeekam2023planning,
  title = {On the {{Planning Abilities}} of {{Large Language Models}} - {{A Critical Investigation}}},
  booktitle = NeurIPS,
  author = {Valmeekam, Karthik and Marquez, Matthew and Sreedharan, Sarath and Kambhampati, Subbarao},
  year = {2023},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@valmeekam2023planning-On the Planning Abilities of Large Language Models - A Critical Investigation.pdf}
}

@article{varghese2020survey,
  title = {A {{Survey}} of {{Multi-Task Deep Reinforcement Learning}}},
  author = {Varghese, Nelson Vithayathil and Mahmoud, Qusay H.},
  year = {2020},
  month = aug,
  journal = {Electronics},
  volume = {9},
  number = {9},
  pages = {1363},
  issn = {2079-9292},
  doi = {10.3390/electronics9091363},
  urldate = {2023-02-03},
  abstract = {Driven by the recent technological advancements within the field of artificial intelligence research, deep learning has emerged as a promising representation learning technique across all of the machine learning classes, especially within the reinforcement learning arena. This new direction has given rise to the evolution of a new technological domain named deep reinforcement learning, which combines the representational learning power of deep learning with existing reinforcement learning methods. Undoubtedly, the inception of deep reinforcement learning has played a vital role in optimizing the performance of reinforcement learning-based intelligent agents with model-free based approaches. Although these methods could improve the performance of agents to a greater extent, they were mainly limited to systems that adopted reinforcement learning algorithms focused on learning a single task. At the same moment, the aforementioned approach was found to be relatively data-inefficient, particularly when reinforcement learning agents needed to interact with more complex and rich data environments. This is primarily due to the limited applicability of deep reinforcement learning algorithms to many scenarios across related tasks from the same environment. The objective of this paper is to survey the research challenges associated with multi-tasking within the deep reinforcement arena and present the state-of-the-art approaches by comparing and contrasting recent solutions, namely DISTRAL (DIStill \& TRAnsfer Learning), IMPALA(Importance Weighted Actor-Learner Architecture) and PopArt that aim to address core challenges such as scalability, distraction dilemma, partial observability, catastrophic forgetting and negative knowledge transfer.},
  langid = {english},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@varghese2020survey-A Survey of Multi-Task Deep Reinforcement Learning.pdf}
}

@inproceedings{vaswani2017attention,
  title = {Attention Is {{All}} You {{Need}}},
  booktitle = NeurIPS,
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  editor = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  year = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@vaswani2017attention-Attention is All you Need.pdf}
}

@article{vecerik2017leveraging,
  title = {Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards},
  author = {Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  year = {2017},
  journal = {arXiv},
  volume = {preprint arXiv:1707.08817},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@vecerik2017leveraging-Leveraging demonstrations for deep reinforcement learning on robotics problems.pdf}
}

@inproceedings{vecerik2024robotap,
  title = {Robotap: {{Tracking}} Arbitrary Points for Few-Shot Visual Imitation},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Vecerik, Mel and Doersch, Carl and Yang, Yi and Davchev, Todor and Aytar, Yusuf and Zhou, Guangyao and Hadsell, Raia and Agapito, Lourdes and Scholz, Jon},
  year = {2024},
  pages = {5397--5403},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@vecerik2024robotap-Robotap - Tracking arbitrary points for few-shot visual imitation.pdf}
}

@inproceedings{veenstra2020how,
  title = {How Different Encodings Affect Performance and Diversification When Evolving the Morphology and Control of {{2D}} Virtual Creatures},
  booktitle = ALIFE,
  author = {Veenstra, Frank and Glette, Kyrre},
  year = {2020},
  pages = {592--601},
  publisher = {MIT Press}
}

@inproceedings{velde2019body,
  title = {Body Symmetry in Morphologically Evolving Modular Robots},
  booktitle = {International {{Conference}} on the {{Applications}} of {{Evolutionary Computation}} ({{Part}} of {{EvoStar}})},
  author = {Velde, T and Rossi, Claudio and Eiben, {\relax AE}},
  year = {2019},
  pages = {583--598},
  publisher = {Springer}
}

@article{venkata2023ktbt,
  title = {Kt-Bt: {{A}} Framework for Knowledge Transfer through Behavior Trees in Multirobot Systems},
  author = {Venkata, Sanjay Sarma Oruganti and Parasuraman, Ramviyas and Pidaparti, Ramana},
  year = {2023},
  journal = {IEEE Transactions on Robotics},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@venkata2023ktbt-Kt-bt - A framework for knowledge transfer through behavior trees in multirobot.pdf}
}

@inproceedings{vinitsky2022nocturne,
  title = {Nocturne: A Scalable Driving Benchmark for Bringing Multi-Agent Learning One Step Closer to the Real World},
  booktitle = NeurIPS,
  author = {Vinitsky, Eugene and Lichtl{\'e}, Nathan and Yang, Xiaomeng and Amos, Brandon and Foerster, Jakob Nicolaus},
  year = {2022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@vinitsky2022nocturne-Nocturne - a scalable driving benchmark for bringing multi-agent learning one.pdf}
}

@article{vinyals2019grandmaster,
  title = {Grandmaster Level in {{StarCraft II}} Using Multi-Agent Reinforcement Learning},
  author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H. and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John P. and Jaderberg, Max and Vezhnevets, Alexander S. and Leblond, R{\'e}mi and Pohlen, Tobias and Dalibard, Valentin and Budden, David and Sulsky, Yury and Molloy, James and Paine, Tom L. and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Wu, Yuhuai and Ring, Roman and Yogatama, Dani and W{\"u}nsch, Dario and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Kavukcuoglu, Koray and Hassabis, Demis and Apps, Chris and Silver, David},
  year = {2019},
  month = nov,
  journal = {Nature},
  volume = {575},
  number = {7782},
  pages = {350--354},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1724-z},
  abstract = {Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions1--3, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems4. Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players. We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent reinforcement learning algorithm that uses data from both human and agent games within a diverse league of continually adapting strategies and counter-strategies, each represented by deep neural networks5,6. We evaluated our agent, AlphaStar, in the full game of StarCraft II, through a series of online games against human players. AlphaStar was rated at Grandmaster level for all three StarCraft races and above 99.8\% of officially ranked human players.},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@vinyals2019grandmaster-Grandmaster level in StarCraft II using multi-agent reinforcement learning.pdf}
}

@inproceedings{wagener2022mocapact,
  title = {{{MoCapAct}}: {{A Multi-Task Dataset}} for {{Simulated Humanoid Control}}},
  booktitle = NeurIPS,
  author = {Wagener, Nolan and Kolobov, Andrey and Frujeri, Felipe Vieira and Loynd, Ricky and Cheng, Ching-An and Hausknecht, Matthew},
  year = {2022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wagener2022mocapact-MoCapAct - A Multi-Task Dataset for Simulated Humanoid Control.pdf}
}

@misc{wager2017estimation,
  title = {Estimation and {{Inference}} of {{Heterogeneous Treatment Effects}} Using {{Random Forests}}},
  author = {Wager, Stefan and Athey, Susan},
  year = {2017},
  month = jul,
  number = {arXiv:1510.04342},
  eprint = {1510.04342},
  primaryclass = {math, stat},
  publisher = {arXiv},
  urldate = {2024-09-29},
  abstract = {Many scientific and engineering challenges---ranging from personalized medicine to customized marketing recommendations---require an understanding of treatment effect heterogeneity. In this paper, we develop a non-parametric causal forest for estimating heterogeneous treatment effects that extends Breiman's widely used random forest algorithm. In the potential outcomes framework with unconfoundedness, we show that causal forests are pointwise consistent for the true treatment effect, and have an asymptotically Gaussian and centered sampling distribution. We also discuss a practical method for constructing asymptotic confidence intervals for the true treatment effect that are centered at the causal forest estimates. Our theoretical results rely on a generic Gaussian theory for a large family of random forest algorithms. To our knowledge, this is the first set of results that allows any type of random forest, including classification and regression forests, to be used for provably valid statistical inference. In experiments, we find causal forests to be substantially more powerful than classical methods based on nearest-neighbor matching, especially in the presence of irrelevant covariates.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wager2017estimation-Estimation and Inference of Heterogeneous Treatment Effects using Random Forests.pdf}
}

@article{wake2025vlmdriven,
  title = {{{VLM-driven Behavior Tree}} for {{Context-aware Task Planning}}},
  author = {Wake, Naoki and Kanehira, Atsushi and Takamatsu, Jun and Sasabuchi, Kazuhiro and Ikeuchi, Katsushi},
  year = {2025},
  journal = {arXiv preprint arXiv:2501.03968},
  eprint = {2501.03968},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wake2025vlmdriven-VLM-driven Behavior Tree for Context-aware Task Planning.pdf}
}

@article{walter2007ground,
  title = {Ground Forces Applied by Galloping Dogs},
  author = {Walter, Rebecca M and Carrier, David R},
  year = {2007},
  journal = {Journal of Experimental Biology},
  volume = {210},
  number = {2},
  pages = {208--216},
  publisher = {Company of Biologists},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@walter2007ground-Ground forces applied by galloping dogs.pdf}
}

@inproceedings{wan2022handmethat,
  title = {{{HandMeThat}}: {{Human-Robot Communication}} in {{Physical}} and {{Social Environments}}},
  booktitle = NeurIPS,
  author = {Wan, Yanming and Mao, Jiayuan and Tenenbaum, Joshua B.},
  year = {2022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wan2022handmethat-HandMeThat - Human-Robot Communication in Physical and Social Environments.pdf}
}

@article{wang2015design,
  title = {Design Principles for Energy-Efficient Legged Locomotion and Implementation on the {{MIT}} Cheetah Robot},
  author = {{Wang} and {Albert} and {Michael} and {Chuah} and {Meng} and {Yee} and {Hyun} and {Dong} and {Jin} and {Otten}},
  year = {2015},
  journal = {IEEE/ASME transactions on mechatronics: A joint publication of the IEEE Industrial Electronics Society and the ASME Dynamic Systems and Control Division},
  volume = {20},
  number = {3},
  pages = {1117--1129}
}

@article{wang2017learning,
  title = {Learning to Reinforcement Learn},
  author = {Wang, Jane X. and {Kurth-Nelson}, Zeb and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z. and Munos, Remi and Blundell, Charles and Kumaran, Dharshan and Botvinick, Matt},
  year = {2017},
  month = jan,
  journal = {arXiv},
  eprint = {1611.05763},
  primaryclass = {cs, stat},
  urldate = {2023-02-03},
  abstract = {In recent years deep reinforcement learning (RL) systems have attained superhuman performance in a number of challenging task domains. However, a major limitation of such applications is their demand for massive amounts of training data. A critical present objective is thus to develop deep RL methods that can adapt rapidly to new tasks. In the present work we introduce a novel approach to this challenge, which we refer to as deep meta-reinforcement learning. Previous work has shown that recurrent networks can support meta-learning in a fully supervised context. We extend this approach to the RL setting. What emerges is a system that is trained using one RL algorithm, but whose recurrent dynamics implement a second, quite separate RL procedure. This second, learned RL algorithm can differ from the original one in arbitrary ways. Importantly, because it is learned, it is configured to exploit structure in the training domain. We unpack these points in a series of seven proof-of-concept experiments, each of which examines a key aspect of deep meta-RL. We consider prospects for extending and scaling up the approach, and also point out some potentially important implications for neuroscience.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,ObsCite,Statistics - Machine Learning},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2017learning-Learning to reinforcement learn.pdf}
}

@inproceedings{wang2017object,
  title = {Object Behavior Simulation Based on Behavior Tree and Multi-Agent Model},
  booktitle = {2017 {{IEEE}} 2nd {{Information Technology}}, {{Networking}}, {{Electronic}} and {{Automation Control Conference}} ({{ITNEC}})},
  author = {Wang, Yiran and Wang, Lei and Liu, Jinghao},
  year = {2017},
  pages = {833--836},
  doi = {10.1109/ITNEC.2017.8284851},
  keywords = {behavior tree,multi-agent model,public security,steering,visualized presentation},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2017object-Object behavior simulation based on behavior tree and multi-agent model.pdf}
}

@inproceedings{wang2018nervenet,
  title = {Nervenet: {{Learning}} Structured Policy with Graph Neural Networks},
  booktitle = ICLR,
  author = {Wang, Tingwu and Liao, Renjie and Ba, Jimmy and Fidler, Sanja},
  year = {2018},
  volume = {30},
  keywords = {ObsCite},
  annotation = {using graph neural network to model structural information of the agents to improve policy and transferability},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2018nervenet-Nervenet - Learning structured policy with graph neural networks.pdf}
}

@inproceedings{wang2019neural,
  title = {Neural {{Graph Evolution}}: {{Towards Efficient Automatic Robot Design}}},
  shorttitle = {Neural {{Graph Evolution}}},
  booktitle = ICLR,
  author = {Wang, Tingwu and Zhou, Yuhao and Fidler, Sanja and Ba, Jimmy},
  year = {2019},
  month = jun,
  urldate = {2022-02-16},
  langid = {english},
  keywords = {embodied intelligence,ObsCite},
  annotation = {an ES-based method that uses GNNs to enable weight sharing between an agent and\\
its offspring},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2019neural-Neural Graph Evolution - Towards Efficient Automatic Robot Design.pdf}
}

@article{wang2019paired,
  title = {Paired Open-Ended Trailblazer (Poet): {{Endlessly}} Generating Increasingly Complex and Diverse Learning Environments and Their Solutions},
  author = {Wang, Rui and Lehman, Joel and Clune, Jeff and Stanley, Kenneth O},
  year = {2019},
  journal = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2019paired-Paired open-ended trailblazer (poet) - Endlessly generating increasingly complex.pdf}
}

@article{wang2019redmax,
  title = {{{RedMax}}: Efficient \& Flexible Approach for Articulated Dynamics},
  shorttitle = {{{RedMax}}},
  author = {Wang, Ying and Weidner, Nicholas J. and Baxter, Margaret A. and Hwang, Yura and Kaufman, Danny M. and Sueda, Shinjiro},
  year = {2019},
  month = aug,
  journal = TOG,
  volume = {38},
  number = {4},
  pages = {1--10},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3306346.3322952},
  urldate = {2022-05-11},
  abstract = {It is well known that the dynamics of articulated rigid bodies can be solved in O (n) time using a recursive method, where n is the number of joints. However, when elasticity is added between the bodies (e.g., damped springs), with linearly implicit integration, the sti{\dbend}ness matrix in the equations of motion breaks the tree topology of the system, making the recursive O (n) method inapplicable. In such cases, the only alternative has been to form and solve the system matrix, which takes O (n3) time. We propose a new approach that is capable of solving the linearly implicit equations of motion in near linear time. Our method, which we call R{\dbend}{\dbend}M{\dbend}{\dbend}, is built using a combined reduced/maximal coordinate formulation. This hybrid model enables direct {\dbend}exibility to apply arbitrary combinations of constraints and contact modeling in both reduced and maximal coordinates, as well as mixtures of implicit and explicit forces in either coordinate representation. We highlight R{\dbend}{\dbend}M{\dbend}{\dbend}'s {\dbend}exibility with seamless integration of deformable objects with two-way coupling, at a standard additional cost. We further highlight its {\dbend}exibility by constructing an e{\dbend}cient internal (joint) and external (environment) frictional contact solver that can leverage bilateral joint constraints for rapid evaluation of frictional articulated dynamics. CCS Concepts: {$\bullet$} Computing methodologies {$\rightarrow$} Physical simulation.},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2019redmax-RedMax - efficient & flexible approach for articulated dynamics.pdf}
}

@article{wang2019tree,
  title = {Tree Transformer: {{Integrating}} Tree Structures into Self-Attention},
  author = {Wang, Yau-Shian and Lee, Hung-Yi and Chen, Yun-Nung},
  year = {2019},
  journal = {arXiv preprint arXiv:1909.06639},
  eprint = {1909.06639},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2019tree-Tree transformer - Integrating tree structures into self-attention.pdf}
}

@inproceedings{wang2020tcts,
  title = {{{TCTS}}: {{A Task-Consistent Two-Stage Framework}} for {{Person Search}}},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Wang, Cheng and Ma, Bingpeng and Chang, Hong and Shan, Shiguang and Chen, Xilin},
  year = {2020},
  month = jun,
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2020tcts-TCTS - A Task-Consistent Two-Stage Framework for Person Search.pdf}
}

@article{wang2020transfer,
  title = {Transfer Stacking from Low-to High-Fidelity: {{A}} Surrogate-Assisted Bi-Fidelity Evolutionary Algorithm},
  shorttitle = {Transfer Stacking from Low-to High-Fidelity},
  author = {Wang, Handing and Jin, Yaochu and Yang, Cuie and Jiao, Licheng},
  year = {2020},
  month = jul,
  journal = {Applied Soft Computing},
  volume = {92},
  pages = {106276},
  issn = {15684946},
  doi = {10.1016/j.asoc.2020.106276},
  urldate = {2022-03-01},
  abstract = {Optimization of many real-world optimization problems relies on numerical simulations for function evaluations. In some cases, both high- and low-fidelity simulations are available, where the high fidelity evaluation is accurate but time-consuming, whereas the low-fidelity evaluation is less accurate but computationally cheap. To find an acceptable optimum within a limited budget, it is economical for evolutionary algorithms to use both high- and low-fidelity evaluations in a single optimization search. This paper proposes a novel surrogate-assisted evolutionary algorithm using the transfer stacking technique for bi-fidelity optimization. To this end, a radial basis function network is firstly built to approximate the high-fidelity fitness function as additional low-fidelity evaluation, then a surrogate model transferring the original and additional low-fidelity evaluations to the expensive high-fidelity evaluation is adapted to guide the search. The simulation results on a series of bi-fidelity optimization benchmark problems with resolution, stochastic, and instability errors and a beneficiation processes optimization problem show that the proposed algorithm is both effective and efficient for solving bi-fidelity optimization problems, when their low-fidelity evaluations have resolution and stochastic errors.},
  langid = {english},
  file = {C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@wang2020transfer-Transfer stacking from low-to high-fidelity - A surrogate-assisted bi-fidelity.pdf;D\:\\Study\\Data\\zotfile\\Applied Soft Computing2020_Transfer stacking from low-to high-fidelity - A surrogate-assisted bi-fidelity @wang2020transfer.docx}
}

@article{wang2022codesign,
  title = {Co-Design of {{Embodied Neural Intelligence}} via {{Constrained Evolution}}},
  author = {Wang, Zhiquan and Benes, Bedrich and Qureshi, Ahmed Hussain and Mousas, Christos},
  year = {2022},
  journal = {arXiv},
  volume = {abs/2205.10688},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2022codesign-Co-design of Embodied Neural Intelligence via Constrained Evolution.pdf}
}

@article{wang2022recommendation,
  title = {Recommendation Algorithm in {{TikTok}}: {{Strengths}}, Dilemmas, and Possible Directions},
  author = {Wang, Pengda},
  year = {2022},
  journal = {Int'l J. Soc. Sci. Stud.},
  volume = {10},
  pages = {60},
  publisher = {HeinOnline},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2022recommendation-Recommendation algorithm in TikTok - Strengths, dilemmas, and possible directions.pdf}
}

@inproceedings{wang2023dexgraspnet,
  title = {Dexgraspnet: {{A}} Large-Scale Robotic Dexterous Grasp Dataset for General Objects Based on Simulation},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Wang, Ruicheng and Zhang, Jialiang and Chen, Jiayi and Xu, Yinzhen and Li, Puhao and Liu, Tengyu and Wang, He},
  year = {2023},
  pages = {11359--11366},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2023dexgraspnet-Dexgraspnet - A large-scale robotic dexterous grasp dataset for general objects.pdf}
}

@inproceedings{wang2023learning,
  title = {Learning {{Hierarchical Robot Skills Represented}} by {{Behavior Trees}} from {{Natural Language}}},
  booktitle = {International {{Conference}} on {{Cooperative Information Systems}}},
  author = {Wang, Kaiyi and Zhao, Yongjia and Dai, Shuling and Yang, Minghao and He, Yichen and Zhang, Ning},
  year = {2023},
  pages = {366--383},
  publisher = {Springer},
  abstract = {Learning from natural language is a programming-free and user friendly teaching method that allows users without programming knowledge or demonstration capabilities to instruct robots, which has great value in industry and daily life. The manipulation skills of robots are often hierarchical skills composed of low-level primitive skills, so they can be conveniently represented by behavior trees (BTs). Based on this idea, we propose NL2BT, a framework for generating behavior trees from natural language and controlling robots to complete hierarchical tasks in real time. The framework consists of two language processing stages, an initial behavior tree library composed of primitive skill subtrees, and a BT-Generation algorithm. To validate the effectiveness of NL2BT, we use it to build a Chinese natural language system for instructing robots in performing 3C assembly tasks, which is a significant application of Industry 4.0. We also discuss the positive impact of real-time teaching, visual student models, and the synonymous skill module in the framework. In addition to the demonstrated application, NL2BT can be easily migrated to other languages and hierarchical task learning scenarios.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2023learning-Learning Hierarchical Robot Skills Represented by Behavior Trees from Natural.pdf}
}

@article{wang2023planandsolve,
  title = {Plan-and-Solve Prompting: {{Improving}} Zero-Shot Chain-of-Thought Reasoning by Large Language Models},
  author = {Wang, Lei and Xu, Wanyu and Lan, Yihuai and Hu, Zhiqiang and Lan, Yunshi and Lee, Roy Ka-Wei and Lim, Ee-Peng},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.04091},
  eprint = {2305.04091},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2023planandsolve-Plan-and-solve prompting - Improving zero-shot chain-of-thought reasoning by.pdf}
}

@article{wang2023prompt,
  title = {Prompt Learning for Action Recognition},
  author = {Wang, Xijun and Xian, Ruiqi and Guan, Tianrui and Manocha, Dinesh},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.12437},
  eprint = {2305.12437},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2023prompt-Prompt learning for action recognition.pdf}
}

@article{wang2023softzoo,
  title = {{{SoftZoo}}: {{A Soft Robot Co-design Benchmark For Locomotion In Diverse Environments}}},
  author = {Wang, Tsun-Hsuan and Ma, Pingchuan and Spielberg, Andrew and Xian, Zhou and Zhang, Hao and Tenenbaum, Joshua B. and Rus, Daniela and Gan, Chuang},
  year = {2023},
  journal = {arXiv},
  volume = {abs/2303.09555},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2023softzoo-SoftZoo - A Soft Robot Co-design Benchmark For Locomotion In Diverse Environments.pdf}
}

@inproceedings{wang2023voyager,
  title = {Voyager: {{An Open-Ended Embodied Agent}} with {{Large Language Models}}},
  booktitle = {{{NeurIPS}} 2023 {{Workshop IMOL}}},
  author = {Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  year = {2023},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2023voyager-Voyager - An Open-Ended Embodied Agent with Large Language Models.pdf}
}

@inproceedings{wang2024embodiedscan,
  title = {Embodiedscan: {{A}} Holistic Multi-Modal 3d Perception Suite towards Embodied Ai},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Wang, Tai and Mao, Xiaohan and Zhu, Chenming and Xu, Runsen and Lyu, Ruiyuan and Li, Peisen and Chen, Xiao and Zhang, Wenwei and Chen, Kai and Xue, Tianfan and others},
  year = {2024},
  pages = {19757--19767},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2024embodiedscan-Embodiedscan - A holistic multi-modal 3d perception suite towards embodied ai.pdf}
}

@inproceedings{wang2024enabling,
  title = {Enabling {{Behaviour Tree Verification}} via a {{Translation}} to {{BIP}}},
  booktitle = {Formal {{Aspects}} of {{Component Software}}},
  author = {Wang, Qiang and Dai, Huadong and Zhao, Yongxin and Zhang, Min and Bliudze, Simon},
  editor = {Marmsoler, Diego and Sun, Meng},
  year = {2024},
  pages = {3--20},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  abstract = {A formal verification method for behavior tree (BT) is proposed. The method is based on a compositional model transformation of BT into the formal component-based system design framework BIP (Behavior-Interaction-Priority). The transformation encodes each BT node as an individual BIP component that is formally defined by an extended finite state automaton (FSA), and each BT edge as a set of interactions that describes the allowed coordination between components. The correctness proof of the model transformation is presented, and a prototype tool-chain has been implemented that enables the automated verification of BT. Two practical case studies show that the tool-chain can not only verify the correctness of BT, but also detect the potential design flaws automatically.},
  isbn = {978-3-031-71261-6},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2024enabling-Enabling Behaviour Tree Verification via a Translation to BIP.pdf}
}

@article{wang2024grutopia,
  title = {{{GRUtopia}}: {{Dream General Robots}} in a {{City}} at {{Scale}}},
  author = {Wang, Hanqing and Chen, Jiahe and Huang, Wensi and Ben, Qingwei and Wang, Tai and Mi, Boyu and Huang, Tao and Zhao, Siheng and Chen, Yilun and Yang, Sizhe and others},
  year = {2024},
  journal = {arXiv preprint arXiv:2407.10943},
  eprint = {2407.10943},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2024grutopia-GRUtopia - Dream General Robots in a City at Scale.pdf}
}

@article{wang2024large,
  title = {Large Language Models for Robotics: {{Opportunities}}, Challenges, and Perspectives},
  author = {Wang, Jiaqi and Wu, Zihao and Li, Yiwei and Jiang, Hanqi and Shu, Peng and Shi, Enze and Hu, Huawen and Ma, Chong and Liu, Yiheng and Wang, Xuhui and others},
  year = {2024},
  journal = {arXiv preprint arXiv:2401.04334},
  eprint = {2401.04334},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2024large-Large language models for robotics - Opportunities, challenges, and perspectives.pdf}
}

@article{wang2024litesearch,
  title = {{{LiteSearch}}: {{Efficacious Tree Search}} for {{LLM}}},
  author = {Wang, Ante and Song, Linfeng and Tian, Ye and Peng, Baolin and Yu, Dian and Mi, Haitao and Su, Jinsong and Yu, Dong},
  year = {2024},
  journal = {arXiv preprint arXiv:2407.00320},
  eprint = {2407.00320},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2024litesearch-LiteSearch - Efficacious Tree Search for LLM.pdf}
}

@article{wang2024llm,
  title = {{{LLM}}{\textasciicircum} 3: {{Large Language Model-based Task}} and {{Motion Planning}} with {{Motion Failure Reasoning}}},
  author = {Wang, Shu and Han, Muzhi and Jiao, Ziyuan and Zhang, Zeyu and Wu, Ying Nian and Zhu, Song-Chun and Liu, Hangxin},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.11552},
  eprint = {2403.11552},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2024llm-LLM^ 3 - Large Language Model-based Task and Motion Planning with Motion Failure.pdf}
}

@inproceedings{wang2024omnijarvis,
  title = {{{OmniJARVIS}}: {{Unified Vision-Language-Action Tokenization Enables Open-World Instruction Following Agents}}},
  booktitle = NeurIPS,
  author = {Wang, Zihao and Cai, Shaofei and Mu, Zhancun and Lin, Haowei and Zhang, Ceyao and Liu, Xuejie and Li, Qing and Liu, Anji and Ma, Xiaojian and Liang, Yitao},
  year = {2024},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2024omnijarvis-OmniJARVIS - Unified Vision-Language-Action Tokenization Enables Open-World.pdf}
}

@article{wang2024oop,
  title = {{{OOP}}: {{Object-Oriented Programming Evaluation Benchmark}} for {{Large Language Models}}},
  author = {Wang, Shuai and Ding, Liang and Shen, Li and Luo, Yong and Du, Bo and Tao, Dacheng},
  year = {2024},
  journal = {arXiv preprint arXiv:2401.06628},
  eprint = {2401.06628},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2024oop-OOP - Object-Oriented Programming Evaluation Benchmark for Large Language Models.pdf}
}

@article{wang2024retask,
  title = {Re-{{TASK}}: {{Revisiting LLM Tasks}} from {{Capability}}, {{Skill}}, and {{Knowledge Perspectives}}},
  author = {Wang, Zhihu and Zhao, Shiwan and Wang, Yu and Huang, Heyuan and Shi, Jiaxin and Xie, Sitao and Wang, Zhixing and Zhang, Yubo and Li, Hongyan and Yan, Junchi},
  year = {2024},
  journal = {arXiv preprint arXiv:2408.06904},
  eprint = {2408.06904},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2024retask-Re-TASK - Revisiting LLM Tasks from Capability, Skill, and Knowledge Perspectives.pdf}
}

@article{wang2024survey,
  title = {A Survey on Large Language Model Based Autonomous Agents},
  author = {Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and Zhao, Wayne Xin and Wei, Zhewei and Wen, Jirong},
  year = {2024},
  month = mar,
  journal = {Frontiers of Computer Science},
  volume = {18},
  number = {6},
  pages = {186345},
  issn = {2095-2236},
  doi = {10.1007/s11704-024-40231-1},
  abstract = {Autonomous agents have long been a research focus in academic and industry communities. Previous research often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of Web knowledge, large language models (LLMs) have shown potential in human-level intelligence, leading to a surge in research on LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of LLM-based autonomous agents from a holistic perspective. We first discuss the construction of LLM-based autonomous agents, proposing a unified framework that encompasses much of previous work. Then, we present a overview of the diverse applications of LLM-based autonomous agents in social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wang2024survey-A survey on large language model based autonomous agents.pdf}
}

@article{WangJi2019xingshihuafangfa,
  title = {形式化方法概貌},
  author = {王戟, 詹乃军, 冯新宇, 刘志明},
  year = {2019},
  journal = {软件学报},
  volume = {30},
  number = {1},
  pages = {33},
  publisher = {科学出版社},
  doi = {10.13328/j.cnki.jos.005652},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@WangJi2019xingshihuafangfa-形式化方法概貌.pdf}
}

@article{watkins1992qlearning,
  title = {Q-Learning},
  author = {Watkins, Christopher J. C. H. and Dayan, Peter},
  year = {1992},
  month = may,
  journal = {Machine Learning},
  volume = {8},
  number = {3},
  pages = {279--292},
  issn = {1573-0565},
  doi = {10.1007/BF00992698},
  abstract = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@watkins1992qlearning-Q-learning.pdf}
}

@article{webb2023emergent,
  title = {Emergent Analogical Reasoning in Large Language Models},
  author = {Webb, Taylor and Holyoak, Keith J and Lu, Hongjing},
  year = {2023},
  journal = {Nature Human Behaviour},
  volume = {7},
  number = {9},
  pages = {1526--1541},
  publisher = {Nature Publishing Group UK London},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@webb2023emergent-Emergent analogical reasoning in large language models.pdf}
}

@inproceedings{wei2022chainofthought,
  title = {Chain-of-{{Thought Prompting Elicits Reasoning}} in {{Large Language Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and {ichter}, brian and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny},
  editor = {Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
  year = {2022},
  volume = {35},
  pages = {24824--24837},
  publisher = {Curran Associates, Inc.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wei2022chainofthought-Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf}
}

@inproceedings{wei2022honor,
  title = {Honor of {{Kings Arena}}: An {{Environment}} for {{Generalization}} in {{Competitive Reinforcement Learning}}},
  booktitle = NeurIPS,
  author = {Wei, Hua and Chen, Jingxiao and Ji, Xiyang and Qin, Hongyang and Deng, Minwen and Li, Siqin and Wang, Liang and Zhang, Weinan and Yu, Yong and Linc, Liu and Huang, Lanxiao and Ye, Deheng and FU, {\relax QIANG} and Wei, Yang},
  year = {2022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wei2022honor-Honor of Kings Arena - an Environment for Generalization in Competitive.pdf}
}

@article{weigmann2012does,
  title = {Does Intelligence Require a Body? {{The}} Growing Discipline of Embodied Cognition Suggests That to Understand the World, We Must Experience the World},
  author = {Weigmann, Katrin},
  year = {2012},
  journal = {EMBO reports},
  volume = {13},
  number = {12},
  pages = {1066--1069},
  publisher = {John Wiley \& Sons, Ltd Chichester, UK}
}

@inproceedings{wen2020neural,
  title = {Neural {{Predictor}} for {{Neural Architecture Search}}},
  booktitle = ECCV,
  author = {Wen, Wei and Liu, Hanxiao and Chen, Yiran and Li, Hai and Bender, Gabriel and Kindermans, Pieter-Jan},
  year = {2020},
  pages = {16},
  abstract = {Neural Architecture Search methods are effective but often use complex algorithms to come up with the best architecture. We propose an approach with three basic steps that is conceptually much simpler. First we train N random architectures to generate N (architecture, validation accuracy) pairs and use them to train a regression model that predicts accuracies for architectures. Next, we use this regression model to predict the validation accuracies of a large number of random architectures. Finally, we train the top-K predicted architectures and deploy the model with the best validation result. While this approach seems simple, it is more than 20{\texttimes} as sample efficient as Regularized Evolution on the NASBench-101 benchmark. On ImageNet, it approaches the efficiency of more complex and restrictive approaches based on weight sharing such as ProxylessNAS while being fully (embarrassingly) parallelizable and friendly to hyper-parameter tuning.},
  langid = {english},
  annotation = {ECCV},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wen2020neural-Neural Predictor for Neural Architecture Search.pdf}
}

@inproceedings{wen2021mrpb,
  title = {{{MRPB}} 1.0: {{A}} Unified Benchmark for the Evaluation of Mobile Robot Local Planning Approaches},
  booktitle = {2021 {{IEEE}} International Conference on Robotics and Automation ({{ICRA}})},
  author = {Wen, Jian and Zhang, Xuebo and Bi, Qingchen and Pan, Zhangchao and Feng, Yanghe and Yuan, Jing and Fang, Yongchun},
  year = {2021},
  pages = {8238--8244},
  publisher = {IEEE}
}

@article{wen2024tinyvla,
  title = {Tinyvla: {{Towards}} Fast, Data-Efficient Vision-Language-Action Models for Robotic Manipulation},
  author = {Wen, Junjie and Zhu, Yichen and Li, Jinming and Zhu, Minjie and Wu, Kun and Xu, Zhiyuan and Liu, Ning and Cheng, Ran and Shen, Chaomin and Peng, Yaxin and others},
  year = {2024},
  journal = {arXiv preprint arXiv:2409.12514},
  eprint = {2409.12514},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wen2024tinyvla-Tinyvla - Towards fast, data-efficient vision-language-action models for robotic.pdf}
}

@inproceedings{weng2022envpool,
  title = {{{EnvPool}}: {{A Highly Parallel Reinforcement Learning Environment Execution Engine}}},
  booktitle = NeurIPS,
  author = {Weng, Jiayi and Lin, Min and Huang, Shengyi and Liu, Bo and Makoviichuk, Denys and Makoviychuk, Viktor and Liu, Zichen and Song, Yufan and Luo, Ting and Jiang, Yukun and Xu, Zhongwen and YAN, Shuicheng},
  year = {2022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@weng2022envpool-EnvPool - A Highly Parallel Reinforcement Learning Environment Execution Engine.pdf}
}

@article{white2021bananas,
  title = {{{BANANAS}}: {{Bayesian Optimization}} with {{Neural Architectures}} for {{Neural Architecture Search}}},
  author = {White, Colin and Neiswanger, Willie and Savani, Yash},
  year = {2021},
  journal = AAAI,
  pages = {9},
  langid = {english},
  keywords = {bayesian optimization},
  annotation = {AAAI},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@white2021bananas-BANANAS - Bayesian Optimization with Neural Architectures for Neural.pdf}
}

@inproceedings{white2021how,
  title = {How Powerful Are Performance Predictors in Neural Architecture Search?},
  booktitle = NeurIPS,
  author = {White, Colin and Zela, Arber and Ru, Binxin and Liu, Yang and Hutter, Frank},
  editor = {Beygelzimer, A. and Dauphin, Y. and Liang, P. and Vaughan, J. Wortman},
  year = {2021},
  keywords = {understanding},
  annotation = {NeurIPS},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@white2021how-How powerful are performance predictors in neural architecture search.pdf}
}

@article{whitman2021learning,
  title = {Learning Modular Robot Control Policies},
  author = {Whitman, Julian and Travers, Matthew and Choset, Howie},
  year = {2021},
  journal = {arXiv},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@whitman2021learning-Learning modular robot control policies.pdf}
}

@inproceedings{wijaya2023behavior,
  title = {Behavior {{Tree}} of {{Agents}} in {{Multi-Agent System}} on {{Action Video Game}}},
  booktitle = {2023 {{International Conference}} on {{Electrical Engineering}} and {{Informatics}} ({{ICEEI}})},
  author = {Wijaya, Danny Kusuma and Prihatmanto, Ary Setijadi and Yusuf, Rahadian},
  year = {2023},
  pages = {1--4},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wijaya2023behavior-Behavior Tree of Agents in Multi-Agent System on Action Video Game.pdf}
}

@article{willard2023efficient,
  title = {Efficient Guided Generation for Large Language Models},
  author = {Willard, Brandon T and Louf, R{\'e}mi},
  year = {2023},
  journal = {arXiv e-prints},
  pages = {arXiv--2307},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@willard2023efficient-Efficient guided generation for large language models.pdf}
}

@article{wilson2011embodied,
  title = {Embodied Cognition},
  author = {Wilson, Robert A and Foglia, Lucia},
  year = {2011}
}

@article{wissow2023scaleadaptive,
  title = {Scale-{{Adaptive Balancing}} of {{Exploration}} and {{Exploitation}} in {{Classical Planning}}},
  author = {Wissow, Stephen and Asai, Masataro},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.09840},
  eprint = {2305.09840},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wissow2023scaleadaptive-Scale-Adaptive Balancing of Exploration and Exploitation in Classical Planning.pdf}
}

@article{wittner2024optimizations,
  title = {Optimizations for the {{Additive Heuristic}} in {{Fast Downward}}},
  author = {Wittner, Simona},
  year = {2024},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wittner2024optimizations-Optimizations for the Additive Heuristic in Fast Downward.pdf}
}

@article{won2019learning,
  title = {Learning {{Body Shape Variation}} in {{Physics-Based Characters}}},
  author = {Won, Jungdam and Lee, Jehee},
  year = {2019},
  month = nov,
  journal = TOG,
  volume = {38},
  number = {6},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {0730-0301},
  doi = {10.1145/3355089.3356499},
  abstract = {Recently, deep reinforcement learning (DRL) has attracted great attention in designing controllers for physics-based characters. Despite the recent success of DRL, the learned controller is viable for a single character. Changes in body size and proportions require learning controllers from scratch. In this paper, we present a new method of learning parametric controllers for body shape variation. A single parametric controller enables us to simulate and control various characters having different heights, weights, and body proportions. The users are allowed to create new characters through body shape parameters, and they can control the characters immediately. Our characters can also change their body shapes on the fly during simulation. The key to the success of our approach includes the adaptive sampling of body shapes that tackles the challenges in learning parametric controllers, which relies on the marginal value function that measures control capabilities of body shapes. We demonstrate parametric controllers for various physically simulated characters such as bipeds, quadrupeds, and underwater animals.},
  keywords = {character animation,deep learning,locomotion control,neural network,physics-based simulation and control,reinforcement learning},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@won2019learning-Learning Body Shape Variation in Physics-Based Characters.pdf}
}

@article{wu2017posture,
  title = {Posture Self-Stabilizer of a Biped Robot Based on Training Platform and Reinforcement Learning},
  author = {Wu, Weiguo and Gao, Liyang},
  year = {2017},
  month = dec,
  journal = {Robotics and Autonomous Systems},
  volume = {98},
  pages = {42--55},
  issn = {0921-8890},
  doi = {10.1016/j.robot.2017.09.001},
  urldate = {2023-05-24},
  abstract = {In order to solve the problem of stability control for biped robots, the concept of stability training is proposed by using a training platform to exert random disturbance with amplitude limitation on robots that are to be trained. In this work, an approach to achieve a posture stabilizing capability based on stability training and reinforcement learning is explored and verified by simulations. An automatic abstraction method for state space is proposed by using the Gauss basis function and inner evaluation indexes to speed up the learning process. Hierarchical structure stabilizer using the Monte Carlo method is designed according to the concept of variable ZMP. Training samples are extracted from the state transition of the stability training process using balance controllers based on the robot dynamic model. The stabilizers are trained with and without applying the automatic abstraction of state space. Then simulation tests of them are conducted under conditions where the training platform exerts amplitude-limited random disturbances on the robot. Also, the influence of the model errors is studied by introducing deviations of the CoM position during the simulation tests. By comparing the simulation results of two learning stabilizers and the model-based balance controller, it is demonstrated that the designed stabilizer can achieve approximate success rate of the ideal model-based balance controller and exert all the driving ability of the robot under the large disturbance condition of {\textpm}30{$^\circ$} inclination of the platform. Also, the effects of the model error can be overcome by retraining using state transition data with the model error.},
  langid = {english},
  keywords = {Evolutionary robotics,Learning and adaptive systems,Legged robots,Self-stabilizer,Stability training,State space automatic abstraction},
  file = {C:\Users\lenovo\Zotero\storage\WDLKNQHV\S0921889017301550.html}
}

@inproceedings{wu2021micros,
  title = {{{micROS}}.{{BT}}: {{An Event-Driven Behavior Tree Framework}} for {{Swarm Robots}}},
  booktitle = {2021 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Wu, Yunlong and Li, Jinghua and Dai, Huadong and Yi, Xiaodong and Wang, Yanzhen and Yang, Xuejun},
  year = {2021},
  pages = {9146--9153},
  doi = {10.1109/IROS51168.2021.9636460},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wu2021micros-micROS.BT - An Event-Driven Behavior Tree Framework for Swarm Robots.pdf}
}

@article{wu2021neural,
  title = {Neural {{Architecture Search}} as {{Sparse Supernet}}},
  author = {Wu, Yan and Liu, Aoming and Huang, Zhiwu and Zhang, Siwei and Gool, Luc Van},
  year = {2021},
  journal = AAAI,
  pages = {9},
  abstract = {This paper aims at enlarging the problem of Neural Architecture Search (NAS) from Single-Path and Multi-Path Search to automated Mixed-Path Search. In particular, we model the NAS problem as a sparse supernet using a new continuous architecture representation with a mixture of sparsity constraints. The sparse supernet enables us to automatically achieve sparsely-mixed paths upon a compact set of nodes. To optimize the proposed sparse supernet, we exploit a hierarchical accelerated proximal gradient algorithm within a bi-level optimization framework. Extensive experiments on Convolutional Neural Network and Recurrent Neural Network search demonstrate that the proposed method is capable of searching for compact, general and powerful neural architectures.},
  langid = {english},
  keywords = {differentiable,sparse},
  annotation = {AAAI},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wu2021neural-Neural Architecture Search as Sparse Supernet.pdf}
}

@article{wu2022prioritized,
  title = {Prioritized Experience-Based Reinforcement Learning with Human Guidance for Autonomous Driving},
  author = {Wu, Jingda and Huang, Zhiyu and Huang, Wenhui and Lv, Chen},
  year = {2022},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  publisher = {IEEE},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wu2022prioritized-Prioritized experience-based reinforcement learning with human guidance for.pdf}
}

@inproceedings{wu2022task,
  title = {Task Allocation with Load Management in Multi-Agent Teams},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Wu, Haochen and Ghadami, Amin and Bayrak, Alparslan Emrah and Smereka, Jonathon M and Epureanu, Bogdan I},
  year = {2022},
  pages = {8823--8830},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wu2022task-Task allocation with load management in multi-agent teams.pdf}
}

@article{wu2024neurosymbolic,
  title = {Neuro-Symbolic Recommendation Model Based on Logic Query},
  author = {Wu, Maonian and Chen, Bang and Zhu, Shaojun and Zheng, Bo and Peng, Wei and Zhang, Mingyi},
  year = {2024},
  journal = {Knowledge-Based Systems},
  volume = {284},
  pages = {111311},
  publisher = {Elsevier},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wu2024neurosymbolic-Neuro-symbolic recommendation model based on logic query.pdf}
}

@inproceedings{wu2024symbolllm,
  title = {Symbol-{{LLM}}: Leverage Language Models for Symbolic System in Visual Human Activity Reasoning},
  booktitle = NeurIPS,
  author = {Wu, Xiaoqian and Li, Yong-Lu and Sun, Jianhua and Lu, Cewu},
  year = {2024},
  volume = {36},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@wu2024symbolllm-Symbol-LLM - leverage language models for symbolic system in visual human.pdf}
}

@phdthesis{WuChenShu2015jiyuqunzhiganzh,
  title = {基于群智感知的无线室内定位},
  author = {{吴陈沭}},
  year = {2015},
  school = {清华大学}
}

@misc{xavierpuigrobothow,
  title = {{{RobotHow}}},
  author = {Xavier Puig, Kevin Ra, Marko Boben}
}

@article{xi2023rise,
  title = {The Rise and Potential of Large Language Model Based Agents: {{A}} Survey},
  author = {Xi, Zhiheng and Chen, Wenxiang and Guo, Xin and He, Wei and Ding, Yiwen and Hong, Boyang and Zhang, Ming and Wang, Junzhe and Jin, Senjie and Zhou, Enyu and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.07864},
  eprint = {2309.07864},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xi2023rise-The rise and potential of large language model based agents - A survey.pdf}
}

@article{xi2024agentgym,
  title = {{{AgentGym}}: {{Evolving Large Language Model-based Agents}} across {{Diverse Environments}}},
  author = {Xi, Zhiheng and Ding, Yiwen and Chen, Wenxiang and Hong, Boyang and Guo, Honglin and Wang, Junzhe and Yang, Dingwen and Liao, Chenyang and Guo, Xin and He, Wei and others},
  year = {2024},
  journal = {arXiv preprint arXiv:2406.04151},
  eprint = {2406.04151},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xi2024agentgym-AgentGym - Evolving Large Language Model-based Agents across Diverse Environments.pdf}
}

@article{xiao2024grootvl,
  title = {{{GrootVL}}: {{Tree Topology}} Is {{All You Need}} in {{State Space Model}}},
  author = {Xiao, Yicheng and Song, Lin and Huang, Shaoli and Wang, Jiangshan and Song, Siyu and Ge, Yixiao and Li, Xiu and Shan, Ying},
  year = {2024},
  journal = {arXiv preprint arXiv:2406.02395},
  eprint = {2406.02395},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xiao2024grootvl-GrootVL - Tree Topology is All You Need in State Space Model.pdf}
}

@inproceedings{xie2021dynamics,
  title = {Dynamics Randomization Revisited: {{A}} Case Study for Quadrupedal Locomotion},
  booktitle = ICRA,
  author = {Xie, Zhaoming and Da, Xingye and {van de Panne}, Michiel and Babich, Buck and Garg, Animesh},
  year = {2021},
  pages = {4955--4961},
  publisher = {IEEE},
  doi = {10.1109/ICRA48506.2021.9560837},
  keywords = {ObsCite}
}

@inproceedings{xie2023selfevaluation,
  title = {Self-{{Evaluation Guided Beam Search}} for {{Reasoning}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Xie, Yuxi and Kawaguchi, Kenji and Zhao, Yiran and Zhao, James Xu and Kan, Min-Yen and He, Junxian and Xie, Michael},
  editor = {Oh, A. and Naumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.},
  year = {2023},
  volume = {36},
  pages = {41618--41650},
  publisher = {Curran Associates, Inc.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xie2023selfevaluation-Self-Evaluation Guided Beam Search for Reasoning.pdf}
}

@article{xie2024humanlike,
  title = {A {{Human-Like Reasoning Framework}} for {{Multi-Phases Planning Task}} with {{Large Language Models}}},
  author = {Xie, Chengxing and Zou, Difan},
  year = {2024},
  journal = {arXiv preprint arXiv:2405.18208},
  eprint = {2405.18208},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xie2024humanlike-A Human-Like Reasoning Framework for Multi-Phases Planning Task with Large.pdf}
}

@book{XiMeng2020renzhi,
  title = {认知: 人行为背后的思维与智能},
  author = {{西蒙}},
  year = {2020},
  publisher = {中国人民大学出版社},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@XiMeng2020renzhi-认知 - 人行为背后的思维与智能.pdf}
}

@article{xin2023legoprover,
  title = {{{LEGO-Prover}}: {{Neural Theorem Proving}} with {{Growing Libraries}}},
  author = {Xin, Huajian and Wang, Haiming and Zheng, Chuanyang and Li, Lin and Liu, Zhengying and Cao, Qingxing and Huang, Yinya and Xiong, Jing and Shi, Han and Xie, Enze and others},
  year = {2023},
  journal = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xin2023legoprover-LEGO-Prover - Neural Theorem Proving with Growing Libraries.pdf}
}

@article{xiong2023universal,
  title = {Universal {{Morphology Control}} via {{Contextual Modulation}}},
  author = {Xiong, Zheng and Beck, Jacob and Whiteson, Shimon},
  year = {2023},
  journal = {arXiv},
  volume = {abs/2302.11070},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xiong2023universal-Universal Morphology Control via Contextual Modulation.pdf}
}

@article{xiong2024converging,
  title = {Converging {{Paradigms}}: {{The Synergy}} of {{Symbolic}} and {{Connectionist AI}} in {{LLM-Empowered Autonomous Agents}}},
  author = {Xiong, Haoyi and Wang, Zhiyuan and Li, Xuhong and Bian, Jiang and Xie, Zeke and Mumtaz, Shahid and Barnes, Laura E.},
  year = {2024},
  journal = {arXiv preprint arXiv:2407.08516},
  eprint = {2407.08516},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xiong2024converging-Converging Paradigms - The Synergy of Symbolic and Connectionist AI in.pdf}
}

@inproceedings{xu2019how,
  title = {How Powerful Are Graph Neural Networks?},
  booktitle = ICLR,
  author = {Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
  year = {2019},
  publisher = {OpenReview.net},
  annotation = {ICLR},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xu2019how-How powerful are graph neural networks.pdf}
}

@inproceedings{xu2020joint,
  title = {Joint Inference of Reward Machines and Policies for Reinforcement Learning},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}} ({{ICAPS}})},
  author = {Xu, Zhe and Gavran, Ivan and Ahmad, Yousef and Majumdar, Rupak and Neider, Daniel and Topcu, Ufuk and Wu, Bo},
  year = {2020},
  volume = {30},
  pages = {590--598},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xu2020joint-Joint inference of reward machines and policies for reinforcement learning.pdf}
}

@inproceedings{xu2021endtoend,
  title = {An End-to-End Differentiable Framework for Contact-Aware Robot Design},
  booktitle = RSS,
  author = {Xu, Jie and Chen, Tao and Zlokapa, Lara and Foshey, Michael and Matusik, Wojciech and Sueda, Shinjiro and Agrawal, Pulkit},
  editor = {Shell, Dylan A. and Toussaint, Marc and Hsieh, M. Ani},
  year = {2021},
  doi = {10.15607/RSS.2021.XVII.008},
  keywords = {embodied intelligence,ObsCite},
  annotation = {RSS},
  file = {C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@xu2021endtoend-An end-to-end differentiable framework for contact-aware robot design.pdf;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@xu2021endtoend-An end-to-end differentiable framework for contact-aware robot design2.pdf;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@xu2021endtoend-An end-to-end differentiable framework for contact-aware robot design3.pdf}
}

@inproceedings{xu2022safebench,
  title = {{{SafeBench}}: {{A Benchmarking Platform}} for {{Safety Evaluation}} of {{Autonomous Vehicles}}},
  booktitle = NeurIPS,
  author = {Xu, Chejian and Ding, Wenhao and Lyu, Weijie and Liu, Zuxin and Wang, Shuai and He, Yihan and Hu, Hanjiang and Zhao, Ding and Li, Bo},
  year = {2022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xu2022safebench-SafeBench - A Benchmarking Platform for Safety Evaluation of Autonomous Vehicles.pdf}
}

@article{xu2023rewoo,
  title = {Rewoo: {{Decoupling}} Reasoning from Observations for Efficient Augmented Language Models},
  author = {Xu, Binfeng and Peng, Zhiyuan and Lei, Bowen and Mukherjee, Subhabrata and Liu, Yuchen and Xu, Dongkuan},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.18323},
  eprint = {2305.18323},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xu2023rewoo-Rewoo - Decoupling reasoning from observations for efficient augmented language.pdf}
}

@article{xu2023wizardlm,
  title = {{{WizardLM}}: {{Empowering Large Language Models}} to {{Follow Complex Instructions}}},
  shorttitle = {{{WizardLM}}},
  author = {Xu, Can and Sun, Qingfeng and Zheng, Kai and Geng, Xiubo and Zhao, Pu and Feng, Jiazhan and Tao, Chongyang and Jiang, Daxin},
  year = {2023},
  month = jun,
  journal = {arXiv},
  eprint = {2304.12244},
  primaryclass = {cs},
  urldate = {2023-10-28},
  abstract = {Training large language models (LLMs) with open-domain instruction following data brings colossal success. However, manually creating such instruction data is very time-consuming and labor-intensive. Moreover, humans may struggle to produce high-complexity instructions. In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans. Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM. Human evaluations on a complexity-balanced test bed and Vicuna's testset show that instructions from Evol-Instruct are superior to human-created ones. By analyzing the human evaluation results of the high complexity part, we demonstrate that outputs from our WizardLM model are preferred to outputs from OpenAI ChatGPT. In GPT-4 automatic evaluation, WizardLM achieves more than 90\% capacity of ChatGPT on 17 out of 29 skills. Even though WizardLM still lags behind ChatGPT in some aspects, our findings suggest that fine-tuning with AI-evolved instructions is a promising direction for enhancing LLMs. Our code and data are public at https://github.com/nlpxucan/WizardLM.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xu2023wizardlm-WizardLM - Empowering Large Language Models to Follow Complex Instructions.pdf}
}

@inproceedings{xu2023xskill,
  title = {{{XSkill}}: {{Cross Embodiment Skill Discovery}}},
  booktitle = {Proceedings of {{The}} 7th {{Conference}} on {{Robot Learning}}},
  author = {Xu, Mengda and Xu, Zhenjia and Chi, Cheng and Veloso, Manuela and Song, Shuran},
  editor = {Tan, Jie and Toussaint, Marc and Darvish, Kourosh},
  year = {2023},
  month = nov,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {229},
  pages = {3536--3555},
  publisher = {PMLR},
  abstract = {Human demonstration videos are a widely available data source for robot learning and an intuitive user interface for expressing desired behavior. However, directly extracting reusable robot manipulation skills from unstructured human videos is challenging due to the big embodiment difference and unobserved action parameters. To bridge this embodiment gap, this paper introduces XSkill, an imitation learning framework that 1) discovers a cross-embodiment representation called skill prototypes purely from unlabeled human and robot manipulation videos, 2) transfers the skill representation to robot actions using conditional diffusion policy, and finally, 3) composes the learned skill to accomplish unseen tasks specified by a human prompt video. Our experiments in simulation and real-world environments show that the discovered skill prototypes facilitate both skill transfer and composition for unseen tasks, resulting in a more general and scalable imitation learning framework.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xu2023xskill-XSkill - Cross Embodiment Skill Discovery.pdf}
}

@article{xu2024faithful,
  title = {Faithful {{Logical Reasoning}} via {{Symbolic Chain-of-Thought}}},
  author = {Xu, Jundong and Fei, Hao and Pan, Liangming and Liu, Qian and Lee, Mong-Li and Hsu, Wynne},
  year = {2024},
  journal = {arXiv preprint arXiv:2405.18357},
  eprint = {2405.18357},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xu2024faithful-Faithful Logical Reasoning via Symbolic Chain-of-Thought.pdf}
}

@article{xu2024survey,
  title = {A Survey on Robotics with Foundation Models: Toward Embodied Ai},
  author = {Xu, Zhiyuan and Wu, Kun and Wen, Junjie and Li, Jinming and Liu, Ning and Che, Zhengping and Tang, Jian},
  year = {2024},
  journal = {arXiv preprint arXiv:2402.02385},
  eprint = {2402.02385},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xu2024survey-A survey on robotics with foundation models - toward embodied ai.pdf}
}

@inproceedings{xue2021rethinking,
  title = {Rethinking {{Bi-Level Optimization}} in {{Neural Architecture Search}}: {{A Gibbs Sampling Perspective}}},
  booktitle = AAAI,
  author = {Xue, Chao and Wang, Xiaoxing and Yan, Junchi and Hu, Yonggang and Yang, Xiaokang and Sun, Kewei},
  year = {2021},
  pages = {9},
  abstract = {One-Shot architecture search, aiming to explore all possible operations jointly based on a single model, has been an active direction of Neural Architecture Search (NAS). As a wellknown one-shot solution, Differentiable Architecture Search (DARTS) performs continuous relaxation on the architecture's importance and results in a bi-level optimization problem. As many recent studies have shown, DARTS cannot always work robustly for new tasks, which is mainly due to the approximate solution of the bi-level optimization. In this paper, one-shot neural architecture search is addressed by adopting a directed probabilistic graphical model to represent the joint probability distribution over data and model. Then, neural architectures are searched for and optimized by Gibbs sampling. We rethink the bi-level optimization problem as the task of Gibbs sampling from the posterior distribution, which expresses the preferences for different models given the observed dataset. We evaluate our proposed NAS method -- GibbsNAS on the search space used in DARTS/ENAS as well as the search space of NAS-Bench-201. Experimental results on multiple search space show the efficacy and stability of our approach.},
  langid = {english},
  keywords = {differentiable,gibbs sampling,one-shot},
  annotation = {AAAI},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@xue2021rethinking-Rethinking Bi-Level Optimization in Neural Architecture Search - A Gibbs.pdf}
}

@article{yahia2023path,
  title = {Path Planning Optimization in Unmanned Aerial Vehicles Using Meta-Heuristic Algorithms: A Systematic Review},
  shorttitle = {Path Planning Optimization in Unmanned Aerial Vehicles Using Meta-Heuristic Algorithms},
  author = {Yahia, Hazha Saeed and Mohammed, Amin Salih},
  year = {2023},
  month = jan,
  journal = {Environmental Monitoring and Assessment},
  volume = {195},
  number = {1},
  pages = {30},
  issn = {0167-6369, 1573-2959},
  doi = {10.1007/s10661-022-10590-y},
  urldate = {2024-03-26},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yahia2023path-Path planning optimization in unmanned aerial vehicles using meta-heuristic.pdf}
}

@article{yan2018spatial,
  title = {Spatial {{Temporal Graph Convolutional Networks}} for {{Skeleton-Based Action Recognition}}},
  author = {Yan, Sijie and Xiong, Yuanjun and Lin, Dahua},
  year = {2018},
  month = jan,
  journal = {arXiv},
  eprint = {1801.07455},
  urldate = {2022-03-21},
  abstract = {Dynamics of human body skeletons convey significant information for human action recognition. Conventional approaches for modeling skeletons usually rely on hand-crafted parts or traversal rules, thus resulting in limited expressive power and difficulties of generalization. In this work, we propose a novel model of dynamic skeletons called SpatialTemporal Graph Convolutional Networks (ST-GCN), which moves beyond the limitations of previous methods by automatically learning both the spatial and temporal patterns from data. This formulation not only leads to greater expressive power but also stronger generalization capability. On two large datasets, Kinetics and NTU-RGBD, it achieves substantial improvements over mainstream methods.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yan2018spatial-Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action.pdf}
}

@article{yan2024dynamic,
  title = {Dynamic {{Open-Vocabulary 3D Scene Graphs}} for {{Long-term Language-Guided Mobile Manipulation}}},
  author = {Yan, Zhijie and Li, Shufei and Wang, Zuoxu and Wu, Lixiu and Wang, Han and Zhu, Jun and Chen, Lijiang and Liu, Jihong},
  year = {2024},
  journal = {arXiv preprint arXiv:2410.11989},
  eprint = {2410.11989},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yan2024dynamic-Dynamic Open-Vocabulary 3D Scene Graphs for Long-term Language-Guided Mobile.pdf}
}

@article{yang2018deep,
  title = {Deep Neural Decision Trees},
  author = {Yang, Yongxin and Morillo, Irene Garcia and Hospedales, Timothy M},
  year = {2018},
  journal = {arXiv preprint arXiv:1806.06988},
  eprint = {1806.06988},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2018deep-Deep neural decision trees.pdf}
}

@article{yang2018learning,
  title = {Learning {{Flexible}} and {{Reusable Locomotion Primitives}} for a {{Microrobot}}},
  author = {Yang, Brian and Wang, Grant and Calandra, Roberto and Contreras, Daniel and Levine, Sergey and Pister, Kristofer},
  year = {2018},
  month = jul,
  journal = RA-L,
  volume = {3},
  number = {3},
  pages = {1904--1911},
  issn = {2377-3766},
  doi = {10.1109/LRA.2018.2806083},
  abstract = {The design of gaits for robot locomotion can be a daunting process, which requires significant expert knowledge and engineering. This process is even more challenging for robots that do not have an accurate physical model, such as compliant or micro-scale robots. Data-driven gait optimization provides an automated alternative to analytical gait design. In this letter, we propose a novel approach to efficiently learn a wide range of locomotion tasks with walking robots. This approach formalizes locomotion as a contextual policy search task to collect data, and subsequently uses that data to learn multiobjective locomotion primitives that can be used for planning. As a proof-of-concept we consider a simulated hexapod modeled after a recently developed microrobot, and we thoroughly evaluate the performance of this microrobot on different tasks and gaits. Our results validate the proposed controller and learning scheme on single and multiobjective locomotion tasks. Moreover, the experimental simulations show that without any prior knowledge about the robot used (e.g., dynamics model), our approach is capable of learning locomotion primitives within 250 trials and subsequently using them to successfully navigate through a maze.},
  keywords = {Bayes methods,Learning and adaptive systems,Legged locomotion,legged robots,micro/nano robots,Optimization,Oscillators,Solid modeling,Task analysis},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2018learning-Learning Flexible and Reusable Locomotion Primitives for a Microrobot.pdf}
}

@inproceedings{yang2018mean,
  title = {Mean Field Multi-Agent Reinforcement Learning},
  booktitle = {International Conference on Machine Learning},
  author = {Yang, Yaodong and Luo, Rui and Li, Minne and Zhou, Ming and Zhang, Weinan and Wang, Jun},
  year = {2018},
  pages = {5571--5580},
  publisher = {PMLR},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2018mean-Mean field multi-agent reinforcement learning.pdf}
}

@article{yang2020multiexpert,
  title = {Multi-Expert Learning of Adaptive Legged Locomotion},
  author = {Yang, Chuanyu and Yuan, Kai and Zhu, Qiuguo and Yu, Wanming and Li, Zhibin},
  year = {2020},
  month = dec,
  journal = {Science Robotics},
  volume = {5},
  number = {49},
  pages = {eabb2174},
  issn = {2470-9476},
  doi = {10.1126/scirobotics.abb2174},
  urldate = {2022-02-28},
  abstract = {A multi-expert learning architecture generates adaptive behaviors for the versatile locomotion of quadruped robots.           ,              Achieving versatile robot locomotion requires motor skills that can adapt to previously unseen situations. We propose a multi-expert learning architecture (MELA) that learns to generate adaptive skills from a group of representative expert skills. During training, MELA is first initialized by a distinct set of pretrained experts, each in a separate deep neural network (DNN). Then, by learning the combination of these DNNs using a gating neural network (GNN), MELA can acquire more specialized experts and transitional skills across various locomotion modes. During runtime, MELA constantly blends multiple DNNs and dynamically synthesizes a new DNN to produce adaptive behaviors in response to changing situations. This approach leverages the advantages of trained expert skills and the fast online synthesis of adaptive policies to generate responsive motor skills during the changing tasks. Using one unified MELA framework, we demonstrated successful multiskill locomotion on a real quadruped robot that performed coherent trotting, steering, and fall recovery autonomously and showed the merit of multi-expert learning generating behaviors that can adapt to unseen scenarios.},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2020multiexpert-Multi-expert learning of adaptive legged locomotion.pdf}
}

@inproceedings{yang2021delving,
  title = {Delving into {{Deep Imbalanced Regression}}},
  booktitle = ICLR,
  author = {Yang, Yuzhe and Zha, Kaiwen and Chen, Ying-Cong and Wang, Hao and Katabi, Dina},
  year = {2021},
  month = may,
  urldate = {2022-04-05},
  abstract = {Real-world data often exhibit imbalanced distributions, where certain target values have significantly fewer observations. Existing techniques for dealing with imbalanced data focus on targets with categorical indices, i.e., different classes. However, many tasks involve continuous targets, where hard boundaries between classes do not exist. We define Deep Imbalanced Regression (DIR) as learning from such imbalanced data with continuous targets, dealing with potential missing data for certain target values, and generalizing to the entire target range. Motivated by the intrinsic difference between categorical and continuous label space, we propose distribution smoothing for both labels and features, which explicitly acknowledges the effects of nearby targets, and calibrates both label and learned feature distributions. We curate and benchmark large-scale DIR datasets from common real-world tasks in computer vision, natural language processing, and healthcare domains. Extensive experiments verify the superior performance of our strategies. Our work fills the gap in benchmarks and techniques for practical imbalanced regression problems. Code and data are available at: https://github.com/ YyzHarry/imbalanced-regression.},
  langid = {english},
  keywords = {inbalanced,neural network},
  annotation = {ICML},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2021delving-Delving into Deep Imbalanced Regression.pdf}
}

@article{yang2021efficient,
  title = {Efficient Hyperparameter Optimization for Physics-Based Character Animation},
  author = {Yang, Zeshi and Yin, Zhiqi},
  year = {2021},
  month = apr,
  journal = TOG,
  volume = {4},
  number = {1},
  doi = {10.1145/3451254},
  abstract = {Physics-based character animation has seen significant advances in recent years with the adoption of Deep Reinforcement Learning (DRL). However, DRL-based learning methods are usually computationally expensive and their performance crucially depends on the choice of hyperparameters. Tuning hyperparameters for these methods often requires repetitive training of control policies, which is even more computationally prohibitive. In this work, we propose a novel Curriculum-based Multi-Fidelity Bayesian Optimization framework (CMFBO) for efficient hyperparameter optimization of DRL-based character control systems. Using curriculum-based task difficulty as fidelity criterion, our method improves searching efficiency by gradually pruning search space through evaluation on easier motor skill tasks. We evaluate our method on two physics-based character control tasks: character morphology optimization and hyperparameter tuning of DeepMimic. Our algorithm significantly outperforms state-of-the-art hyperparameter optimization methods applicable for physics-based character animation. In particular, we show that hyperparameters optimized through our algorithm result in at least 5x efficiency gain comparing to author-released settings in DeepMimic.},
  keywords = {Bayesian Optimization,Curriculum Learning,Physics-based Character Animation,Reinforcement Learning},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2021efficient-Efficient hyperparameter optimization for physics-based character animation.pdf}
}

@phdthesis{yang2021manyagent,
  title = {Many-Agent Reinforcement Learning},
  author = {Yang, Yaodong},
  year = {2021},
  school = {UCL (University College London)},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2021manyagent-Many-agent reinforcement learning.pdf}
}

@article{yang2022graphblast,
  title = {{{GraphBLAST}}: {{A}} High-Performance Linear Algebra-Based Graph Framework on the {{GPU}}},
  author = {Yang, Carl and Bulu{\c c}, Ayd{\i}n and Owens, John D},
  year = {2022},
  journal = {ACM Transactions on Mathematical Software (TOMS)},
  volume = {48},
  number = {1},
  pages = {1--51},
  publisher = {ACM New York, NY},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2022graphblast-GraphBLAST - A high-performance linear algebra-based graph framework on the GPU.pdf}
}

@inproceedings{yang2023behavior,
  title = {Behavior {{Contrastive Learning}} for {{Unsupervised Skill Discovery}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Machine Learning}}},
  author = {Yang, Rushuai and Bai, Chenjia and Guo, Hongyi and Li, Siyuan and Zhao, Bin and Wang, Zhen and Liu, Peng and Li, Xuelong},
  editor = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  year = {2023},
  month = jul,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {202},
  pages = {39183--39204},
  publisher = {PMLR},
  abstract = {In reinforcement learning, unsupervised skill discovery aims to learn diverse skills without extrinsic rewards. Previous methods discover skills by maximizing the mutual information (MI) between states and skills. However, such an MI objective tends to learn simple and static skills and may hinder exploration. In this paper, we propose a novel unsupervised skill discovery method through contrastive learning among behaviors, which makes the agent produce similar behaviors for the same skill and diverse behaviors for different skills. Under mild assumptions, our objective maximizes the MI between different behaviors based on the same skill, which serves as an upper bound of the previous MI objective. Meanwhile, our method implicitly increases the state entropy to obtain better state coverage. We evaluate our method on challenging mazes and continuous control tasks. The results show that our method generates diverse and far-reaching skills, and also obtains competitive performance in downstream tasks compared to the state-of-the-art methods.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2023behavior-Behavior Contrastive Learning for Unsupervised Skill Discovery.pdf}
}

@article{yang2023llmgrounder,
  title = {Llm-Grounder: {{Open-vocabulary}} 3d Visual Grounding with Large Language Model as an Agent},
  author = {Yang, Jianing and Chen, Xuweiyi and Qian, Shengyi and Madaan, Nikhil and Iyengar, Madhavan and Fouhey, David F and Chai, Joyce},
  year = {2023},
  journal = {arXiv preprint arXiv:2309.12311},
  eprint = {2309.12311},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2023llmgrounder-Llm-grounder - Open-vocabulary 3d visual grounding with large language model as.pdf}
}

@article{yang2024guiding,
  title = {Guiding {{Long-Horizon Task}} and {{Motion Planning}} with {{Vision Language Models}}},
  author = {Yang, Zhutian and Garrett, Caelan and Fox, Dieter and {Lozano-P{\'e}rez}, Tom{\'a}s and Kaelbling, Leslie Pack},
  year = {2024},
  journal = {arXiv preprint arXiv:2410.02193},
  eprint = {2410.02193},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2024guiding-Guiding Long-Horizon Task and Motion Planning with Vision Language Models.pdf}
}

@article{yang2024hierarchical,
  title = {Hierarchical Multi-Agent Skill Discovery},
  author = {Yang, Mingyu and Yang, Yaodong and Lu, Zhenbo and Zhou, Wengang and Li, Houqiang},
  year = {2024},
  journal = {Advances in Neural Information Processing Systems},
  volume = {36},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2024hierarchical-Hierarchical multi-agent skill discovery.pdf}
}

@inproceedings{yang2025octopus,
  title = {Octopus: {{Embodied}} Vision-Language Programmer from Environmental Feedback},
  booktitle = {European {{Conference}} on {{Computer Vision}}},
  author = {Yang, Jingkang and Dong, Yuhao and Liu, Shuai and Li, Bo and Wang, Ziyue and Tan, Haoran and Jiang, Chencheng and Kang, Jiamu and Zhang, Yuanhan and Zhou, Kaiyang and others},
  year = {2025},
  pages = {20--38},
  publisher = {Springer},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yang2025octopus-Octopus - Embodied vision-language programmer from environmental feedback.pdf}
}

@misc{yao2019taking,
  title = {Taking {{Human}} out of {{Learning Applications}}: {{A Survey}} on {{Automated Machine Learning}}},
  shorttitle = {Taking {{Human}} out of {{Learning Applications}}},
  author = {Yao, Quanming and Wang, Mengshuo and Chen, Yuqiang and Dai, Wenyuan and Li, Yu-Feng and Tu, Wei-Wei and Yang, Qiang and Yu, Yang},
  year = {2019},
  month = dec,
  number = {arXiv:1810.13306},
  eprint = {1810.13306},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2022-05-24},
  abstract = {Machine learning techniques have deeply rooted in our everyday life. However, since it is knowledge- and labor-intensive to pursue good learning performance, humans are heavily involved in every aspect of machine learning. To make machine learning techniques easier to apply and reduce the demand for experienced human experts, automated machine learning (AutoML) has emerged as a hot topic with both industrial and academic interest. In this paper, we provide an up to date survey on AutoML. First, we introduce and define the AutoML problem, with inspiration from both realms of automation and machine learning. Then, we propose a general AutoML framework that not only covers most existing approaches to date, but also can guide the design for new methods.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yao2019taking-Taking Human out of Learning Applications - A Survey on Automated Machine.pdf}
}

@inproceedings{yao2023reacta,
  title = {React: {{Synergizing}} Reasoning and Acting in Language Models},
  booktitle = ICLR,
  author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  year = {2023},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yao2023reacta-React - Synergizing reasoning and acting in language models.pdf}
}

@inproceedings{yao2023tree,
  title = {Tree of {{Thoughts}}: {{Deliberate Problem Solving}} with {{Large Language Models}}},
  shorttitle = {Tree of {{Thoughts}}},
  booktitle = NeurIPS,
  author = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L. and Cao, Yuan and Narasimhan, Karthik},
  year = {2023},
  month = may,
  eprint = {2305.10601},
  primaryclass = {cs},
  urldate = {2023-10-28},
  abstract = {Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, ``Tree of Thoughts'' (ToT), which generalizes over the popular ``Chain of Thought'' approach to prompting language models, and enables exploration over coherent units of text (``thoughts'') that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\% of tasks, our method achieved a success rate of 74\%. Code repo with all prompts: https://github.com/ysymyth/tree-of-thought-llm.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yao2023tree-Tree of Thoughts - Deliberate Problem Solving with Large Language Models.pdf}
}

@inproceedings{yin2007simbicon,
  title = {{{SIMBICON}}: Simple Biped Locomotion Control},
  shorttitle = {{{SIMBICON}}},
  booktitle = SIGGRAPH,
  author = {Yin, KangKang and Loken, Kevin and {van de Panne}, Michiel},
  year = {2007},
  month = jul,
  series = {{{SIGGRAPH}} '07},
  pages = {105--es},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1275808.1276509},
  urldate = {2023-05-18},
  abstract = {Physics-based simulation and control of biped locomotion is difficult because bipeds are unstable, underactuated, high-dimensional dynamical systems. We develop a simple control strategy that can be used to generate a large variety of gaits and styles in real-time, including walking in all directions (forwards, backwards, sideways, turning), running, skipping, and hopping. Controllers can be authored using a small number of parameters, or their construction can be informed by motion capture data. The controllers are applied to 2D and 3D physically-simulated character models. Their robustness is demonstrated with respect to pushes in all directions, unexpected steps and slopes, and unexpected variations in kinematic and dynamic parameters. Direct transitions between controllers are demonstrated as well as parameterized control of changes in direction and speed. Feedback-error learning is applied to learn predictive torque models, which allows for the low-gain control that typifies many natural motions as well as producing smoother simulated motion.},
  isbn = {978-1-4503-7836-9},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yin2007simbicon-SIMBICON - simple biped locomotion control.pdf}
}

@book{yixuexinlixue,
  title = {医学心理学（第6版）.Pdf},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yixuexinlixue-医学心理学（第6版）.pdf.pdf}
}

@inproceedings{you2017learning,
  title = {Learning from {{Multiple Teacher Networks}}},
  booktitle = {Proceedings of the {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {You, Shan and Xu, Chang and Xu, Chao and Tao, Dacheng},
  year = {2017},
  series = {{{KDD}} '17},
  pages = {1285--1294},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3097983.3098135},
  abstract = {Training thin deep networks following the student-teacher learning paradigm has received intensive attention because of its excellent performance. However, to the best of our knowledge, most existing work mainly considers one single teacher network. In practice, a student may access multiple teachers, and multiple teacher networks together provide comprehensive guidance that is beneficial for training the student network. In this paper, we present a method to train a thin deep network by incorporating multiple teacher networks not only in output layer by averaging the softened outputs (dark knowledge) from different networks, but also in the intermediate layers by imposing a constraint about the dissimilarity among examples. We suggest that the relative dissimilarity between intermediate representations of different examples serves as a more flexible and appropriate guidance from teacher networks. Then triplets are utilized to encourage the consistence of these relative dissimilarity relationships between the student network and teacher networks. Moreover, we leverage a voting strategy to unify multiple relative dissimilarity information provided by multiple teacher networks, which realizes their incorporation in the intermediate layers. Extensive experimental results demonstrated that our method is capable of generating a well-performed student network, with the classification accuracy comparable or even superior to all teacher networks, yet having much fewer parameters and being much faster in running.},
  isbn = {978-1-4503-4887-4},
  keywords = {deep learning,knowledge transfer,multiple teacher networks,ObsCite,triplet loss},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@you2017learning-Learning from Multiple Teacher Networks.pdf}
}

@article{yu2018learning,
  title = {Learning Symmetric and Low-Energy Locomotion},
  author = {Yu, Wenhao and Turk, Greg and Liu, C. Karen},
  year = {2018},
  month = aug,
  journal = TOG,
  volume = {37},
  number = {4},
  pages = {1--12},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3197517.3201397},
  urldate = {2022-02-28},
  abstract = {Learning locomotion skills is a challenging problem. To generate realistic and smooth locomotion, existing methods use motion capture, finite state machines or morphology-specific knowledge to guide the motion generation algorithms. Deep reinforcement learning (DRL) is a promising approach for the automatic creation of locomotion control. Indeed, a standard benchmark for DRL is to automatically create a running controller for a biped character from a simple reward function [Duan et al. 2016]. Although several different DRL algorithms can successfully create a running controller, the resulting motions usually look nothing like a real runner. This paper takes a minimalist learning approach to the locomotion problem, without the use of motion examples, finite state machines, or morphology-specific knowledge. We introduce two modifications to the DRL approach that, when used together, produce locomotion behaviors that are symmetric, low-energy, and much closer to that of a real person. First, we introduce a new term to the loss function (not the reward function) that encourages symmetric actions. Second, we introduce a new curriculum learning method that provides modulated physical assistance to help the character with left/right balance and forward movement. The algorithm automatically computes appropriate assistance to the character and gradually relaxes this assistance, so that eventually the character learns to move entirely without help. Because our method does not make use of motion capture data, it can be applied to a variety of character morphologies. We demonstrate locomotion controllers for the lower half of a biped, a full humanoid, a quadruped, and a hexapod. Our results show that learned policies are able to produce symmetric, low-energy gaits. In addition, speed-appropriate gait patterns emerge without any guidance from motion examples or contact planning.},
  langid = {english},
  keywords = {ObsCite},
  annotation = {TOG},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yu2018learning-Learning symmetric and low-energy locomotion.pdf}
}

@inproceedings{yu2022multiembodiment,
  title = {Multi-Embodiment {{Legged Robot Control}} as a {{Sequence Modeling Problem}}},
  booktitle = ICRA,
  author = {Yu, Chen and Zhang, Weinan and Lai, Hang and Tian, Zheng and Kneip, Laurent and Wang, Jun},
  year = {2022},
  month = dec,
  eprint = {2212.09078},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2023-02-28},
  abstract = {Robots are traditionally bounded by a fixed embodiment during their operational lifetime, which limits their ability to adapt to their surroundings. Co-optimizing control and morphology of a robot, however, is often inefficient due to the complex interplay between the controller and morphology. In this paper, we propose a learning-based control method that can inherently take morphology into consideration such that once the control policy is trained in the simulator, it can be easily deployed to robots with different embodiments in the real world. In particular, we present the Embodiment-aware Transformer (EAT), an architecture that casts this control problem as conditional sequence modeling. EAT outputs the optimal actions by leveraging a causally masked Transformer. By conditioning an autoregressive model on the desired robot embodiment, past states, and actions, our EAT model can generate future actions that best fit the current robot embodiment. Experimental results show that EAT can outperform all other alternatives in embodiment-varying tasks, and succeed in an example of real-world evolution tasks: stepping down a stair through updating the morphology alone. We hope that EAT will inspire a new push toward real-world evolution across many domains, where algorithms like EAT can blaze a trail by bridging the field of evolutionary robotics and big data sequence modeling.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics,ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yu2022multiembodiment-Multi-embodiment Legged Robot Control as a Sequence Modeling Problem.pdf}
}

@inproceedings{yu2022surprising,
  title = {The {{Surprising Effectiveness}} of {{PPO}} in {{Cooperative Multi-Agent Games}}},
  booktitle = NeurIPS,
  author = {Yu, Chao and Velu, Akash and Vinitsky, Eugene and Gao, Jiaxuan and Wang, Yu and Bayen, Alexandre and Wu, Yi},
  year = {2022},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yu2022surprising-The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games.pdf}
}

@article{yu2023survey,
  title = {A Survey on Neural-Symbolic Learning Systems},
  author = {Yu, Dongran and Yang, Bo and Liu, Dayou and Wang, Hui and Pan, Shirui},
  year = {2023},
  journal = {Neural Networks},
  publisher = {Elsevier},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yu2023survey-A survey on neural-symbolic learning systems.pdf}
}

@article{yu2024enhancing,
  title = {Enhancing {{Autonomous Underwater Vehicle Decision Making}} through {{Intelligent Task Planning}} and {{Behavior Tree Optimization}}},
  author = {Yu, Dan and Wang, Hongjian and Cao, Xu and Wang, Zhao and Ren, Jingfei and Zhang, Kai},
  year = {2024},
  journal = {Journal of Marine Science and Engineering},
  volume = {12},
  number = {5},
  pages = {791},
  publisher = {MDPI},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yu2024enhancing-Enhancing Autonomous Underwater Vehicle Decision Making through Intelligent.pdf}
}

@article{yu2024manipose,
  title = {{{ManiPose}}: {{A Comprehensive Benchmark}} for {{Pose-aware Object Manipulation}} in {{Robotics}}},
  author = {Yu, Qiaojun and Hao, Ce and Wang, Junbo and Liu, Wenhai and Liu, Liu and Mu, Yao and You, Yang and Yan, Hengxu and Lu, Cewu},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.13365},
  eprint = {2403.13365},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yu2024manipose-ManiPose - A Comprehensive Benchmark for Pose-aware Object Manipulation in.pdf}
}

@inproceedings{yuan2022sornet,
  title = {{{SORNet}}: {{Spatial Object-Centric Representations}} for {{Sequential Manipulation}}},
  booktitle = {Proceedings of the 5th {{Conference}} on {{Robot Learning}}},
  author = {Yuan, Wentao and Paxton, Chris and Desingh, Karthik and Fox, Dieter},
  editor = {Faust, Aleksandra and Hsu, David and Neumann, Gerhard},
  year = {2022},
  month = nov,
  series = {Proceedings of {{Machine Learning Research}}},
  volume = {164},
  pages = {148--157},
  publisher = {PMLR},
  abstract = {Sequential manipulation tasks require a robot to perceive the state of an environment and plan a sequence of actions leading to a desired goal state, where the ability to reason about spatial relationships among object entities from raw sensor inputs is crucial. Prior works relying on explicit state estimation or end-to-end learning struggle with novel objects or new tasks. In this work, we propose SORNet (Spatial Object-Centric Representation Network), which extracts object-centric representations from RGB images conditioned on canonical views of the objects of interest. We show that the object embeddings learned by SORNet generalize zero-shot to unseen object entities on three spatial reasoning tasks: spatial relationship classification, skill precondition classification and relative direction regression, significantly outperforming baselines. Further, we present real-world robotic experiments demonstrating the usage of the learned object embeddings in task planning for sequential manipulation.},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yuan2022sornet-SORNet - Spatial Object-Centric Representations for Sequential Manipulation.pdf}
}

@inproceedings{yuan2022transform2act,
  title = {{{Transform2Act}}: {{Learning}} a {{Transform-and-Control Policy}} for {{Efficient Agent Design}}},
  booktitle = ICLR,
  author = {Yuan, Ye and Song, Yuda and Luo, Zhengyi and Sun, Wen and Kitani, Kris M.},
  year = {2022},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yuan2022transform2act-Transform2Act - Learning a Transform-and-Control Policy for Efficient Agent.pdf}
}

@inproceedings{yuan2024tasklama,
  title = {Tasklama: Probing the Complex Task Understanding of Language Models},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Yuan, Quan and Kazemi, Mehran and Xu, Xin and Noble, Isaac and Imbrasaite, Vaiva and Ramachandran, Deepak},
  year = {2024},
  volume = {38},
  pages = {19468--19476},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yuan2024tasklama-Tasklama - probing the complex task understanding of language models.pdf}
}

@article{yuanwang2022adaptive,
  title = {Adaptive Output-Feedback Tracking for Nonlinear Systems with Unknown Control Direction and Generic Inverse Dynamics},
  author = {Yuan WANG, Yungang LIU},
  year = {2022},
  journal = {SCIENCE CHINA Information Sciences},
  volume = {65},
  number = {8},
  pages = {182204-},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@yuanwang2022adaptive-Adaptive output-feedback tracking for nonlinear systems with unknown control.pdf}
}

@article{zadornextgeneration,
  title = {Toward {{Next-Generation Artificial Intelligence}}: {{Catalyzing}} the {{NeuroAI Revolution}}},
  author = {Zador, Anthony and Richards, Blake and {\"O}lveczky, Bence and Escola, Sean and Bengio, Yoshua and Botvinick, Matthew and Chklovskii, Dmitri and Churchland, Anne and Clopath, Claudia and Ganguli, Surya and Hawkins, Jeff and Koerding, Konrad and Koulakov, Alexei and LeCun, Yann and Marblestone, Adam and Olshausen, Bruno and Pouget, Alexandre and Savin, Cristina and Simoncelli, Eero and Solla, Sara and Sussillo, David and Tolias, Andreas S and Tsao, Doris},
  pages = {11},
  abstract = {Neuroscience has long been an important driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI.},
  langid = {english},
  file = {C:\Users\lenovo\Zotero\storage\5MAYV68P\Zador_Toward Next-Generation Artificial Intelligence.pdf}
}

@book{zai2020deep,
  title = {Deep Reinforcement Learning in Action},
  author = {Zai, Alexander and Brown, Brandon},
  year = {2020},
  publisher = {Manning Publications},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zai2020deep-Deep reinforcement learning in action.pdf}
}

@inproceedings{zan2023large,
  title = {Large {{Language Models Meet NL2Code}}: {{A Survey}}},
  booktitle = ACL,
  author = {Zan, Daoguang and Chen, Bei and Zhang, Fengji and Lu, Dianjie and Wu, Bingchao and Guan, Bei and Yongji, Wang and Lou, Jian-Guang},
  year = {2023},
  month = jul,
  pages = {7443--7464},
  publisher = {Association for Computational Linguistics},
  address = {Toronto, Canada},
  doi = {10.18653/v1/2023.acl-long.411},
  abstract = {The task of generating code from a natural language description, or NL2Code, is considered a pressing and significant challenge in code intelligence. Thanks to the rapid development of pre-training techniques, surging large language models are being proposed for code, sparking the advances in NL2Code. To facilitate further research and applications in this field, in this paper, we present a comprehensive survey of 27 existing large language models for NL2Code, and also review benchmarks and metrics. We provide an intuitive comparison of all existing models on the HumanEval benchmark. Through in-depth observation and analysis, we provide some insights and conclude that the key factors contributing to the success of large language models for NL2Code are ``Large Size, Premium Data, Expert Tuning''. In addition, we discuss challenges and opportunities regarding the gap between models and humans. We also create a website https://nl2code.github.io to track the latest progress through crowd-sourcing. To the best of our knowledge, this is the first survey of large language models for NL2Code, and we believe it will contribute to the ongoing development of the field.},
  keywords = {ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zan2023large-Large Language Models Meet NL2Code - A Survey.pdf}
}

@article{zardini2021codesign,
  title = {Co-{{Design}} of {{Embodied Intelligence}}: {{A Structured Approach}}},
  shorttitle = {Co-{{Design}} of {{Embodied Intelligence}}},
  author = {Zardini, Gioele and Milojevic, Dejan and Censi, Andrea and Frazzoli, Emilio},
  year = {2021},
  month = sep,
  journal = IROS,
  eprint = {2011.10756},
  pages = {7536--7543},
  doi = {10.1109/IROS51168.2021.9636513},
  urldate = {2022-05-06},
  abstract = {We consider the problem of co-designing embodied intelligence as a whole in a structured way, from hardware components such as propulsion systems and sensors to software modules such as control and perception pipelines. We propose a principled approach to formulate and solve complex embodied intelligence co-design problems, leveraging a monotone co-design theory. The methods we propose are intuitive and integrate heterogeneous engineering disciplines, allowing analytical and simulation-based modeling techniques and enabling interdisciplinarity. We illustrate through a case study how, given a set of desired behaviors, our framework is able to compute Pareto efficient solutions for the entire hardware and software stack of a self-driving vehicle.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics,Electrical Engineering and Systems Science - Systems and Control},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zardini2021codesign-Co-Design of Embodied Intelligence - A Structured Approach.pdf}
}

@article{zare2024survey,
  title = {A Survey of Imitation Learning: {{Algorithms}}, Recent Developments, and Challenges},
  author = {Zare, Maryam and Kebria, Parham M and Khosravi, Abbas and Nahavandi, Saeid},
  year = {2024},
  journal = {IEEE Transactions on Cybernetics},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zare2024survey-A survey of imitation learning - Algorithms, recent developments, and challenges.pdf}
}

@article{zeng2022socratic,
  title = {Socratic Models: {{Composing}} Zero-Shot Multimodal Reasoning with Language},
  author = {Zeng, Andy and Attarian, Maria and Ichter, Brian and Choromanski, Krzysztof and Wong, Adrian and Welker, Stefan and Tombari, Federico and Purohit, Aveek and Ryoo, Michael and Sindhwani, Vikas and others},
  year = {2022},
  journal = {arXiv preprint arXiv:2204.00598},
  eprint = {2204.00598},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zeng2022socratic-Socratic models - Composing zero-shot multimodal reasoning with language.pdf}
}

@article{zeng2023large,
  title = {Large Language Models for Robotics: {{A}} Survey},
  shorttitle = {Large Language Models for Robotics},
  author = {Zeng, Fanlong and Gan, Wensheng and Wang, Yongheng and Liu, Ning and Yu, Philip S.},
  year = {2023},
  journal = {arXiv preprint arXiv:2311.07226},
  eprint = {2311.07226},
  urldate = {2024-01-02},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zeng2023large-Large language models for robotics - A survey.pdf}
}

@inproceedings{zhang2018behavior,
  title = {Behavior Modeling for Autonomous Agents Based on Modified Evolving Behavior Trees},
  booktitle = {2018 {{IEEE}} 7th {{Data Driven Control}} and {{Learning Systems Conference}} ({{DDCLS}})},
  author = {Zhang, Qi and Xu, Kai and Jiao, Peng and Yin, Quanjun},
  year = {2018},
  pages = {1140--1145},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhang2018behavior-Behavior modeling for autonomous agents based on modified evolving behavior.pdf}
}

@article{zhang2018modeadaptive,
  title = {Mode-Adaptive Neural Networks for Quadruped Motion Control},
  author = {Zhang, He and Starke, Sebastian and Komura, Taku and Saito, Jun},
  year = {2018},
  month = aug,
  journal = TOG,
  volume = {37},
  number = {4},
  pages = {1--11},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3197517.3201366},
  urldate = {2022-02-28},
  langid = {english},
  keywords = {neural network},
  annotation = {TOG},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhang2018modeadaptive-Mode-adaptive neural networks for quadruped motion control.pdf}
}

@article{zhang2021data,
  title = {{{DATA}}: {{Differentiable ArchiTecture Approximation With Distribution Guided Sampling}}.},
  author = {Zhang, Xinbang and Chang, Jianlong and Guo, Yiwen and Meng, Gaofeng and Xiang, Shiming and Lin, Zhouchen and Pan, Chunhong},
  year = {2021},
  month = sep,
  journal = TPAMI,
  volume = {43},
  number = {9},
  pages = {2905--2920},
  address = {United States},
  issn = {1939-3539 0098-5589},
  doi = {10.1109/TPAMI.2020.3020315},
  langid = {english},
  pmid = {32866094},
  keywords = {differentiable},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\4NA3T429\\Zhang_2021_DATA.pdf;C\:\\Users\\lenovo\\Zotero\\storage\\N9QYCCEJ\\2021 - TPAMI - DATA.pptx}
}

@article{zhang2023complete,
  title = {A {{Complete Survey}} on {{Generative AI}} ({{AIGC}}): {{Is ChatGPT}} from {{GPT-4}} to {{GPT-5 All You Need}}?},
  author = {Zhang, Chaoning and Zhang, Chenshuang and Zheng, Sheng and Qiao, Yu and Li, Chenghao and Zhang, Mengchun and Dam, Sumit Kumar and Thwal, Chu Myaet and Tun, Ye Lin and Huy, Le Luang and {kim}, Donguk and Bae, Sung-Ho and Lee, Lik-Hang and Yang, Yang and Shen, Heng Tao and Kweon, In So and Hong, Choong Seon},
  year = {2023},
  journal = {arXiv}
}

@article{zhang2023proagent,
  title = {Proagent: {{Building}} Proactive Cooperative Ai with Large Language Models},
  author = {Zhang, Ceyao and Yang, Kaijie and Hu, Siyi and Wang, Zihao and Li, Guanghe and Sun, Yihang and Zhang, Cheng and Zhang, Zhaowei and Liu, Anji and Zhu, Song-Chun and others},
  year = {2023},
  journal = {CoRR},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhang2023proagent-Proagent - Building proactive cooperative ai with large language models.pdf}
}

@article{Zhang2023shenduduibixuex,
  title = {深度对比学习综述},
  author = {张, 重生 and 陈, 杰 and 李, 岐龙 and 邓, 斌权 and 王, 杰 and 陈, 承功},
  year = {2023},
  journal = {自动化学报},
  volume = {第49卷},
  number = {第1期},
  pages = {15--39},
  keywords = {;;;;},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@Zhang2023shenduduibixuex-深度对比学习综述.pdf}
}

@article{zhang2024building,
  title = {Building Cooperative Embodied Agents Modularly with Large Language Models},
  author = {Zhang, Hongxin and Du, Weihua and Shan, Jiaming and Zhou, Qinhong and Du, Yilun and Tenenbaum, Joshua B and Shu, Tianmin and Gan, Chuang},
  year = {2024},
  journal = ICLR,
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhang2024building-Building cooperative embodied agents modularly with large language models.pdf}
}

@inproceedings{zhang2024coalition,
  title = {Coalition {{Formation Game Approach}} for {{Task Allocation}} in {{Heterogeneous Multi-Robot Systems}} under {{Resource Constraints}}},
  booktitle = IROS,
  author = {Zhang, Liwang},
  year = {2024},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhang2024coalition-Coalition Formation Game Approach for Task Allocation in Heterogeneous.pdf}
}

@inproceedings{zhang2024gamma,
  title = {Gamma: {{Graspability-aware}} Mobile Manipulation Policy Learning Based on Online Grasping Pose Fusion},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Zhang, Jiazhao and Gireesh, Nandiraju and Wang, Jilong and Fang, Xiaomeng and Xu, Chaoyi and Chen, Weiguang and Dai, Liu and Wang, He},
  year = {2024},
  pages = {1399--1405},
  publisher = {IEEE}
}

@article{zhang2024llm,
  title = {{{LLM}} as a {{Mastermind}}: {{A Survey}} of {{Strategic Reasoning}} with {{Large Language Models}}},
  author = {Zhang, Yadong and Mao, Shaoguang and Ge, Tao and Wang, Xun and {de Wynter}, Adrian and Xia, Yan and Wu, Wenshan and Song, Ting and Lan, Man and Wei, Furu},
  year = {2024},
  journal = {arXiv preprint arXiv:2404.01230},
  eprint = {2404.01230},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhang2024llm-LLM as a Mastermind - A Survey of Strategic Reasoning with Large Language Models.pdf}
}

@article{zhang2024mmllms,
  title = {Mm-Llms: {{Recent}} Advances in Multimodal Large Language Models},
  author = {Zhang, Duzhen and Yu, Yahan and Li, Chenxing and Dong, Jiahua and Su, Dan and Chu, Chenhui and Yu, Dong},
  year = {2024},
  journal = {arXiv preprint arXiv:2401.13601},
  eprint = {2401.13601},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhang2024mmllms-Mm-llms - Recent advances in multimodal large language models.pdf}
}

@article{zhang2024pivotr,
  title = {{{PIVOT-R}}: {{Primitive-Driven Waypoint-Aware World Model}} for {{Robotic Manipulation}}},
  author = {Zhang, Kaidong and Ren, Pengzhen and Lin, Bingqian and Lin, Junfan and Ma, Shikui and Xu, Hang and Liang, Xiaodan},
  year = {2024},
  journal = {arXiv preprint arXiv:2410.10394},
  eprint = {2410.10394},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhang2024pivotr-PIVOT-R - Primitive-Driven Waypoint-Aware World Model for Robotic Manipulation.pdf}
}

@article{zhang2024prioritizing,
  title = {Prioritizing {{Causation}} in {{Decision Trees}}: {{A Framework}} for {{Interpretable Modeling}}},
  author = {Zhang, Songming and Chen, Xiaofeng and Ran, Xuming and Li, Zhongshan and Cao, Wenming},
  year = {2024},
  journal = {Engineering Applications of Artificial Intelligence},
  volume = {133},
  pages = {108224},
  issn = {0952-1976},
  doi = {10.1016/j.engappai.2024.108224},
  abstract = {As a popular machine learning model, decision trees classify and generalize well, but face challenges in engineering applications: 1) Sensitivity to perturbations and lack of interpretability due to correlation reliance. 2) Manual setting of stopping criterion which is unrelated to correlation strength and easily leads to over-partitioning. To address these two challenges, we first theoretically analyze what leads to sub-optimal decision trees. By incorporating causal discovery, this limitation can be attributed to the fact that trees grown with spurious correlations often fall into sub-optimal that lead to overfitting and unfair behaviors. Neglecting causality motivates us to develop a `better' tree with low Kolmogorov complexity and high generalization capability. Then we propose a causality decision tree framework, CausalDT, based on our theoretical expectation, where Hilbert-Schmidt independence criterion serves as a baseline. Unlike previous approaches that prioritize relevance, our framework determines branch nodes based on causation between features, with the significance level determining whether the tree should be expanded further. Experimental results demonstrate that our model maintains performance while reducing average tree depth by 35\% on various datasets. Furthermore, our model enhances decision fairness and interpretability.},
  keywords = {Causal discovery,Decision tree,Interpretability,Spurious correlation},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhang2024prioritizing-Prioritizing Causation in Decision Trees - A Framework for Interpretable Modeling.pdf}
}

@article{zhao2020robogrammar,
  title = {{{RoboGrammar}}: Graph Grammar for Terrain-Optimized Robot Design},
  shorttitle = {{{RoboGrammar}}},
  author = {Zhao, Allan and Xu, Jie and {Konakovi{\'c}-Lukovi{\'c}}, Mina and Hughes, Josephine and Spielberg, Andrew and Rus, Daniela and Matusik, Wojciech},
  year = {2020},
  month = dec,
  journal = TOG,
  volume = {39},
  number = {6},
  pages = {1--16},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3414685.3417831},
  urldate = {2022-02-16},
  langid = {english},
  keywords = {core,embodied intelligence,ObsCite},
  annotation = {TOG},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhao2020robogrammar-RoboGrammar - graph grammar for terrain-optimized robot design.pdf}
}

@article{zhao2023erra,
  title = {{{ERRA}}: {{An Embodied Representation}} and {{Reasoning Architecture}} for {{Long-Horizon Language-Conditioned Manipulation Tasks}}},
  author = {Zhao, Chao and Yuan, Shuai and Jiang, Chunli and Cai, Junhao and Yu, Hongyu and Wang, Michael Yu and Chen, Qifeng},
  year = {2023},
  journal = {IEEE Robotics and Automation Letters},
  volume = {8},
  number = {6},
  pages = {3230--3237},
  doi = {10.1109/LRA.2023.3265893},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhao2023erra-ERRA - An Embodied Representation and Reasoning Architecture for Long-Horizon.pdf}
}

@inproceedings{zhao2024large,
  title = {Large Language Models as Commonsense Knowledge for Large-Scale Task Planning},
  booktitle = NeurIPS,
  author = {Zhao, Zirui and Lee, Wee Sun and Hsu, David},
  year = {2024},
  volume = {36},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhao2024large-Large language models as commonsense knowledge for large-scale task planning.pdf}
}

@article{zhao2024survey,
  title = {A {{Survey}} of {{Optimization-based Task}} and {{Motion Planning}}: {{From Classical To Learning Approaches}}},
  author = {Zhao, Zhigen and Chen, Shuo and Ding, Yan and Zhou, Ziyi and Zhang, Shiqi and Xu, Danfei and Zhao, Ye},
  year = {2024},
  journal = {arXiv preprint arXiv:2404.02817},
  eprint = {2404.02817},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhao2024survey-A Survey of Optimization-based Task and Motion Planning - From Classical To.pdf}
}

@phdthesis{ZhaoDong2014yidongqunzhigan,
  title = {移动群智感知网络中数据收集与激励机制研究},
  author = {{赵东}},
  year = {2014},
  school = {北京邮电大学}
}

@article{zhen20243dvla,
  title = {3d-Vla: {{A}} 3d Vision-Language-Action Generative World Model},
  author = {Zhen, Haoyu and Qiu, Xiaowen and Chen, Peihao and Yang, Jincheng and Yan, Xin and Du, Yilun and Hong, Yining and Gan, Chuang},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.09631},
  eprint = {2403.09631},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhen20243dvla-3d-vla - A 3d vision-language-action generative world model.pdf}
}

@article{zheng2024survey,
  title = {A {{Survey}} of {{Embodied Learning}} for {{Object-Centric Robotic Manipulation}}},
  author = {Zheng, Ying and Yao, Lei and Su, Yuejiao and Zhang, Yi and Wang, Yi and Zhao, Sicheng and Zhang, Yiyi and Chau, Lap-Pui},
  year = {2024},
  journal = {arXiv preprint arXiv:2408.11537},
  eprint = {2408.11537},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zheng2024survey-A Survey of Embodied Learning for Object-Centric Robotic Manipulation.pdf}
}

@inproceedings{zhou2005beamstack,
  title = {Beam-{{Stack Search}}: {{Integrating Backtracking}} with {{Beam Search}}.},
  booktitle = {{{ICAPS}}},
  author = {Zhou, Rong and Hansen, Eric A},
  year = {2005},
  pages = {90--98},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhou2005beamstack-Beam-Stack Search - Integrating Backtracking with Beam Search.pdf}
}

@article{zhou2017generative,
  title = {Generative Neural Machine for Tree Structures},
  author = {Zhou, Ganbin and Luo, Ping and Cao, Rongyu and Xiao, Yijun and Lin, Fen and Chen, Bo and He, Qing},
  year = {2017},
  journal = {arXiv preprint arXiv:1705.00321},
  eprint = {1705.00321},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhou2017generative-Generative neural machine for tree structures.pdf}
}

@inproceedings{zhou2018treestructured,
  title = {Tree-Structured Neural Machine for Linguistics-Aware Sentence Generation},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Zhou, Ganbin and Luo, Ping and Cao, Rongyu and Xiao, Yijun and Lin, Fen and Chen, Bo and He, Qing},
  year = {2018},
  volume = {32},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhou2018treestructured-Tree-structured neural machine for linguistics-aware sentence generation.pdf}
}

@article{zhou2024codeasmonitor,
  title = {Code-as-{{Monitor}}: {{Constraint-aware Visual Programming}} for {{Reactive}} and {{Proactive Robotic Failure Detection}}},
  author = {Zhou, Enshen and Su, Qi and Chi, Cheng and Zhang, Zhizheng and Wang, Zhongyuan and Huang, Tiejun and Sheng, Lu and Wang, He},
  year = {2024},
  journal = {arXiv preprint arXiv:2412.04455},
  eprint = {2412.04455},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhou2024codeasmonitor-Code-as-Monitor - Constraint-aware Visual Programming for Reactive and Proactive.pdf}
}

@inproceedings{zhou2024isrllm,
  title = {Isr-Llm: {{Iterative}} Self-Refined Large Language Model for Long-Horizon Sequential Task Planning},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Zhou, Zhehua and Song, Jiayang and Yao, Kunpeng and Shu, Zhan and Ma, Lei},
  year = {2024},
  pages = {2081--2088},
  publisher = {IEEE},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhou2024isrllm-Isr-llm - Iterative self-refined large language model for long-horizon.pdf}
}

@article{zhou2024llmbt,
  title = {{{LLM-BT}}: {{Performing Robotic Adaptive Tasks}} Based on {{Large Language Models}} and {{Behavior Trees}}},
  author = {Zhou, Haotian and Lin, Yunhan and Yan, Longwu and Zhu, Jihong and Min, Huasong},
  year = {2024},
  journal = ICRA,
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhou2024llmbt-LLM-BT - Performing Robotic Adaptive Tasks based on Large Language Models and.pdf}
}

@article{zhou2024symbolic,
  title = {Symbolic {{Learning Enables Self-Evolving Agents}}},
  author = {Zhou, Wangchunshu and Ou, Yixin and Ding, Shengwei and Li, Long and Wu, Jialong and Wang, Tiannan and Chen, Jiamin and Wang, Shuai and Xu, Xiaohua and Zhang, Ningyu and others},
  year = {2024},
  journal = {arXiv preprint arXiv:2406.18532},
  eprint = {2406.18532},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhou2024symbolic-Symbolic Learning Enables Self-Evolving Agents.pdf}
}

@article{zhu2023ghost,
  title = {Ghost in the Minecraft: {{Generally}} Capable Agents for Open-World Enviroments via Large Language Models with Text-Based Knowledge and Memory},
  author = {Zhu, Xizhou and Chen, Yuntao and Tian, Hao and Tao, Chenxin and Su, Weijie and Yang, Chenyu and Huang, Gao and Li, Bin and Lu, Lewei and Wang, Xiaogang and others},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.17144},
  eprint = {2305.17144},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhu2023ghost-Ghost in the minecraft - Generally capable agents for open-world enviroments via.pdf}
}

@article{zhu2023large,
  title = {Large {{Language Models}} Can {{Learn Rules}}},
  author = {Zhu, Zhaocheng and Xue, Yuan and Chen, Xinyun and Zhou, Denny and Tang, Jian and Schuurmans, Dale and Dai, Hanjun},
  year = {2023},
  month = oct,
  journal = {arXiv},
  eprint = {2310.07064},
  primaryclass = {cs},
  urldate = {2023-10-28},
  abstract = {When prompted with a few examples and intermediate steps, large language models (LLMs) have demonstrated impressive performance in various reasoning tasks. However, prompting methods that rely on implicit knowledge in an LLM often hallucinate incorrect answers when the implicit knowledge is wrong or inconsistent with the task. To tackle this problem, we present Hypotheses-to-Theories (HtT), a framework that learns a rule library for reasoning with LLMs. HtT contains two stages, an induction stage and a deduction stage. In the induction stage, an LLM is first asked to generate and verify rules over a set of training examples. Rules that appear and lead to correct answers sufficiently often are collected to form a rule library. In the deduction stage, the LLM is then prompted to employ the learned rule library to perform reasoning to answer test questions. Experiments on both numerical reasoning and relational reasoning problems show that HtT improves existing prompting methods, with an absolute gain of 11-27\% in accuracy. The learned rules are also transferable to different models and to different forms of the same problem.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,ObsCite},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhu2023large-Large Language Models can Learn Rules.pdf}
}

@article{zhu2024knowagent,
  title = {{{KnowAgent}}: {{Knowledge-Augmented Planning}} for {{LLM-Based Agents}}},
  author = {Zhu, Yuqi and Qiao, Shuofei and Ou, Yixin and Deng, Shumin and Zhang, Ningyu and Lyu, Shiwei and Shen, Yue and Liang, Lei and Gu, Jinjie and Chen, Huajun},
  year = {2024},
  journal = {arXiv preprint arXiv:2403.03101},
  eprint = {2403.03101},
  archiveprefix = {arXiv},
  file = {C:\Workspace\CXL_Storage\SoftwareData\zotfile\@zhu2024knowagent-KnowAgent - Knowledge-Augmented Planning for LLM-Based Agents.pdf}
}

@inproceedings{zoph2017neural,
  title = {Neural Architecture Search with Reinforcement Learning},
  booktitle = ICLR,
  author = {Zoph, Barret and Le, Quoc V},
  year = {2017},
  pages = {16},
  abstract = {Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214.},
  langid = {english},
  keywords = {reinforcement learning},
  annotation = {ICLR},
  file = {C\:\\Users\\lenovo\\Zotero\\storage\\MJ4IFN2C\\2017 - ICLR - Neural architecture search with reinforcement learning.pptx;C\:\\Workspace\\CXL_Storage\\SoftwareData\\zotfile\\@zoph2017neural-Neural architecture search with reinforcement learning.pdf}
}
